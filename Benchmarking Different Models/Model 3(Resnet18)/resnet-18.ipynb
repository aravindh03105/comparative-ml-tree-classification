{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cec6346",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-18T21:47:12.030626Z",
     "iopub.status.busy": "2025-07-18T21:47:12.030300Z",
     "iopub.status.idle": "2025-07-18T21:53:57.413520Z",
     "shell.execute_reply": "2025-07-18T21:53:57.412513Z"
    },
    "papermill": {
     "duration": 405.388916,
     "end_time": "2025-07-18T21:53:57.415140",
     "exception": false,
     "start_time": "2025-07-18T21:47:12.026224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==1.3.2\r\n",
      "  Downloading scikit_learn-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\r\n",
      "Collecting imbalanced-learn==0.12.3\r\n",
      "  Downloading imbalanced_learn-0.12.3-py3-none-any.whl.metadata (8.3 kB)\r\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.3.2) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.3.2) (1.15.3)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.3.2) (1.5.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.3.2) (3.6.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (2024.2.0)\r\n",
      "Downloading scikit_learn-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading imbalanced_learn-0.12.3-py3-none-any.whl (258 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.3/258.3 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: scikit-learn, imbalanced-learn\r\n",
      "  Attempting uninstall: scikit-learn\r\n",
      "    Found existing installation: scikit-learn 1.2.2\r\n",
      "    Uninstalling scikit-learn-1.2.2:\r\n",
      "      Successfully uninstalled scikit-learn-1.2.2\r\n",
      "  Attempting uninstall: imbalanced-learn\r\n",
      "    Found existing installation: imbalanced-learn 0.13.0\r\n",
      "    Uninstalling imbalanced-learn-0.13.0:\r\n",
      "      Successfully uninstalled imbalanced-learn-0.13.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed imbalanced-learn-0.12.3 scikit-learn-1.3.2\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-18 21:47:23.953379: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752875244.160902      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752875244.216998      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully imported SMOTE.\n",
      "Inspecting first 2 rows of first GeoJSON file:\n",
      "\n",
      "Row 0:\n",
      "  Band B1: shape=(5, 5), first few values=[0.1118 0.1158 0.1158 0.1158 0.1158]\n",
      "  Band B2: shape=(5, 5), first few values=[0.11225 0.11335 0.11335 0.11955 0.11955]\n",
      "  Band B11: shape=(5, 5), first few values=[0.17015 0.1891  0.1891  0.1891  0.1891 ]\n",
      "  Band NDVI: shape=(5, 5), first few values=[0.27416557 0.2273243  0.2273243  0.28395182 0.28395182]\n",
      "  Band DEM: shape=(5, 5), first few values=[88. 88. 88. 88. 88.]\n",
      "  Band B2_1: shape=(), first few values=[nan]\n",
      "  Band NDVI_7: shape=(), first few values=[nan]\n",
      "\n",
      "Row 1:\n",
      "  Band B1: shape=(5, 5), first few values=[0.125 0.124 0.124 0.124 0.124]\n",
      "  Band B2: shape=(5, 5), first few values=[0.1239 0.1176 0.1176 0.1152 0.117 ]\n",
      "  Band B11: shape=(5, 5), first few values=[0.1976 0.1797 0.1797 0.1797 0.1779]\n",
      "  Band NDVI: shape=(5, 5), first few values=[0.40535372 0.36756483 0.36756483 0.36180538 0.34991294]\n",
      "  Band DEM: shape=(5, 5), first few values=[94. 94. 93. 93. 93.]\n",
      "  Band B2_1: shape=(5, 5), first few values=[0.12365 0.11975 0.11975 0.1182  0.1181 ]\n",
      "  Band NDVI_7: shape=(5, 5), first few values=[0.3888209  0.35329902 0.35329902 0.3116279  0.3292073 ]\n",
      "Processing file: needleleaf_douglas fir_douglas firmar-oct-2022.geojson, Rows: 2185\n",
      "Processing file: broadleaf_short-lived deciduous_aldermar-oct-2022.geojson, Rows: 2143\n",
      "Processing file: broadleaf_beech_european beechmar-oct-2022.geojson, Rows: 4756\n",
      "Processing file: needleleaf_larch_japanese larchmar-oct-2022.geojson, Rows: 1613\n",
      "Processing file: broadleaf_short-lived deciduous_poplarmar-oct-2022.geojson, Rows: 387\n",
      "Processing file: needleleaf_pine_scots pinemar-oct-2022.geojson, Rows: 5389\n",
      "Processing file: broadleaf_oak_english oakmar-oct-2022.geojson, Rows: 2808\n",
      "Processing file: needleleaf_larch_european larchmar-oct-2022.geojson, Rows: 1139\n",
      "Processing file: broadleaf_long-lived deciduous_sycamore maplemar-oct-2022.geojson, Rows: 2096\n",
      "Processing file: broadleaf_long-lived deciduous_european ashmar-oct-2022.geojson, Rows: 2202\n",
      "Processing file: broadleaf_short-lived deciduous_birchmar-oct-2022.geojson, Rows: 2468\n",
      "Processing file: broadleaf_long-lived deciduous_lindenmar-oct-2022.geojson, Rows: 161\n",
      "Processing file: broadleaf_oak_red oakmar-oct-2022.geojson, Rows: 1460\n",
      "Processing file: needleleaf_spruce_norway sprucemar-oct-2022.geojson, Rows: 5037\n",
      "Processing file: broadleaf_oak_sessile oakmar-oct-2022.geojson, Rows: 2115\n",
      "Processing file: needleleaf_pine_weymouth pinemar-oct-2022.geojson, Rows: 478\n",
      "Processing file: needleleaf_fir_silver firmar-oct-2022.geojson, Rows: 811\n",
      "Processing file: broadleaf_long-lived deciduous_cherrymar-oct-2022.geojson, Rows: 247\n",
      "Processing file: needleleaf_pine_black pinemar-oct-2022.geojson, Rows: 412\n",
      "\n",
      "Total samples attempted: 37907\n",
      "Valid samples processed: 37907\n",
      "\n",
      "Bands with None or missing values:\n",
      "  B2_4: 25577 times\n",
      "  B3_4: 25577 times\n",
      "  B4_4: 25577 times\n",
      "  B5_4: 25577 times\n",
      "  B6_4: 25577 times\n",
      "  B7_4: 25577 times\n",
      "  B8_4: 25577 times\n",
      "  B8A_4: 25577 times\n",
      "  B11_4: 25577 times\n",
      "  B12_4: 25577 times\n",
      "  NDVI_4: 25577 times\n",
      "  EVI_4: 25577 times\n",
      "  SAVI_4: 25577 times\n",
      "  NDWI_4: 25577 times\n",
      "  B1_4: 25569 times\n",
      "  B9_4: 25569 times\n",
      "  DEM_4: 23721 times\n",
      "  B2_7: 21786 times\n",
      "  B3_7: 21786 times\n",
      "  B4_7: 21786 times\n",
      "  B5_7: 21786 times\n",
      "  B6_7: 21786 times\n",
      "  B7_7: 21786 times\n",
      "  B8_7: 21786 times\n",
      "  B8A_7: 21786 times\n",
      "  B11_7: 21786 times\n",
      "  B12_7: 21786 times\n",
      "  NDVI_7: 21786 times\n",
      "  EVI_7: 21786 times\n",
      "  SAVI_7: 21786 times\n",
      "  NDWI_7: 21786 times\n",
      "  B1_7: 21781 times\n",
      "  B9_7: 21781 times\n",
      "  DEM_7: 20915 times\n",
      "  B2_1: 5484 times\n",
      "  B3_1: 5484 times\n",
      "  B4_1: 5484 times\n",
      "  B5_1: 5484 times\n",
      "  B6_1: 5484 times\n",
      "  B7_1: 5484 times\n",
      "  B8_1: 5484 times\n",
      "  B8A_1: 5484 times\n",
      "  B11_1: 5484 times\n",
      "  B12_1: 5484 times\n",
      "  NDVI_1: 5484 times\n",
      "  EVI_1: 5484 times\n",
      "  SAVI_1: 5484 times\n",
      "  NDWI_1: 5484 times\n",
      "  B1_1: 5465 times\n",
      "  B9_1: 5464 times\n",
      "  B2_6: 5256 times\n",
      "  B3_6: 5256 times\n",
      "  B4_6: 5256 times\n",
      "  B5_6: 5256 times\n",
      "  B6_6: 5256 times\n",
      "  B7_6: 5256 times\n",
      "  B8_6: 5256 times\n",
      "  B8A_6: 5256 times\n",
      "  B11_6: 5256 times\n",
      "  B12_6: 5256 times\n",
      "  NDVI_6: 5256 times\n",
      "  EVI_6: 5256 times\n",
      "  SAVI_6: 5256 times\n",
      "  NDWI_6: 5256 times\n",
      "  B1_6: 5255 times\n",
      "  B9_6: 5255 times\n",
      "  DEM_1: 3956 times\n",
      "  DEM_6: 1460 times\n",
      "  B1_2: 389 times\n",
      "  B2_2: 389 times\n",
      "  B3_2: 389 times\n",
      "  B4_2: 389 times\n",
      "  B5_2: 389 times\n",
      "  B6_2: 389 times\n",
      "  B7_2: 389 times\n",
      "  B8_2: 389 times\n",
      "  B8A_2: 389 times\n",
      "  B9_2: 389 times\n",
      "  B11_2: 389 times\n",
      "  B12_2: 389 times\n",
      "  NDVI_2: 389 times\n",
      "  EVI_2: 389 times\n",
      "  SAVI_2: 389 times\n",
      "  NDWI_2: 389 times\n",
      "  B2_3: 6 times\n",
      "  B3_3: 6 times\n",
      "  B4_3: 6 times\n",
      "  B5_3: 6 times\n",
      "  B6_3: 6 times\n",
      "  B7_3: 6 times\n",
      "  B8_3: 6 times\n",
      "  B8A_3: 6 times\n",
      "  B11_3: 6 times\n",
      "  B12_3: 6 times\n",
      "  NDVI_3: 6 times\n",
      "  EVI_3: 6 times\n",
      "  SAVI_3: 6 times\n",
      "  NDWI_3: 6 times\n",
      "  B1_3: 5 times\n",
      "  B9_3: 5 times\n",
      "\n",
      "Valid samples per species:\n",
      "  scots pine: 5389\n",
      "  norway spruce: 5037\n",
      "  european beech: 4756\n",
      "  english oak: 2808\n",
      "  birch: 2468\n",
      "  european ash: 2202\n",
      "  douglas fir: 2185\n",
      "  alder: 2143\n",
      "  sessile oak: 2115\n",
      "  sycamore maple: 2096\n",
      "  japanese larch: 1613\n",
      "  red oak: 1460\n",
      "  european larch: 1139\n",
      "  silver fir: 811\n",
      "  weymouth pine: 478\n",
      "  black pine: 412\n",
      "  poplar: 387\n",
      "  cherry: 247\n",
      "  linden: 161\n"
     ]
    }
   ],
   "source": [
    "# ********************************************************************************\n",
    "# IMPORTANT: BEFORE RUNNING THIS CELL, PERFORM A \"FACTORY RESET RUNTIME\" (Colab)\n",
    "# OR THE EQUIVALENT DEEPEST RESTART IN YOUR ENVIRONMENT (e.g., Kaggle Session Restart).\n",
    "# THEN, RUN THIS CELL AS THE VERY FIRST CODE IN YOUR NOTEBOOK.\n",
    "# ********************************************************************************\n",
    "!pip install -U scikit-learn==1.3.2 imbalanced-learn==0.12.3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from collections import Counter\n",
    "import ast\n",
    "import geopandas as gpd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "import gc\n",
    "\n",
    "\n",
    "# Now, the imports should work if the environment is truly clean\n",
    "try:\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    print(\"\\nSuccessfully imported SMOTE.\")\n",
    "except ImportError as e:\n",
    "    print(f\"\\nCRITICAL ERROR: Failed to import SMOTE even after aggressive reinstallation: {e}\")\n",
    "    print(\"This indicates a severe, persistent environment issue.\")\n",
    "    print(\"Please double-check that you performed a 'Factory reset runtime' (Colab) or equivalent.\")\n",
    "    exit()\n",
    "\n",
    "# 1. Inspect and Load GeoJSON Files (Modified for Zero Imputation)\n",
    "data_dir = \"/kaggle/input/mar-oct\"  # Replace with your folder path\n",
    "all_features = []\n",
    "all_labels = []\n",
    "invalid_samples = []\n",
    "invalid_bands = Counter()\n",
    "species_counts = Counter()\n",
    "\n",
    "# Updated bands list to include all relevant bands\n",
    "bands = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12', 'NDVI', 'EVI', 'SAVI', 'NDWI', 'DEM']\n",
    "months = ['', '_1', '_2', '_3', '_4', '_5', '_6', '_7']\n",
    "band_columns = [band + month for month in months for band in bands]\n",
    "\n",
    "# Inspect first file\n",
    "first_file = os.path.join(data_dir, os.listdir(data_dir)[0]) if os.listdir(data_dir) else None\n",
    "if first_file and first_file.endswith(\".geojson\"):\n",
    "    gdf = gpd.read_file(first_file)\n",
    "    print(\"Inspecting first 2 rows of first GeoJSON file:\")\n",
    "    for idx in range(min(2, len(gdf))):\n",
    "        print(f\"\\nRow {idx}:\")\n",
    "        for band in ['B1', 'B2', 'B11', 'NDVI', 'DEM', 'B2_1', 'NDVI_7']:\n",
    "            if band in gdf.columns:\n",
    "                data = gdf[band].iloc[idx]\n",
    "                try:\n",
    "                    parsed_data = ast.literal_eval(data) if isinstance(data, str) else data\n",
    "                    array = np.array(parsed_data, dtype=np.float32)\n",
    "                    print(f\"  Band {band}: shape={array.shape}, first few values={array.flatten()[:5]}\")\n",
    "                except (ValueError, SyntaxError, TypeError) as e:\n",
    "                    print(f\"  Band {band}: Error parsing/converting: {e}\")\n",
    "            else:\n",
    "                print(f\"  Band {band}: Not found in GeoJSON file\")\n",
    "\n",
    "# Load all GeoJSON files\n",
    "total_samples_attempted = 0\n",
    "for file in os.listdir(data_dir):\n",
    "    if file.endswith(\".geojson\"):\n",
    "        try:\n",
    "            gdf = gpd.read_file(os.path.join(data_dir, file))\n",
    "            print(f\"Processing file: {file}, Rows: {len(gdf)}\")\n",
    "            total_samples_attempted += len(gdf)\n",
    "            for idx, row in gdf.iterrows():\n",
    "                try:\n",
    "                    patch = []\n",
    "                    for col in band_columns:\n",
    "                        if col not in gdf.columns:\n",
    "                            invalid_bands[col] += 1\n",
    "                            array = np.zeros((5, 5), dtype=np.float32)  # Impute with zeros\n",
    "                            patch.append(array)\n",
    "                            continue\n",
    "                        data = row[col]\n",
    "                        if data is None or (isinstance(data, str) and data.lower() == 'none'):\n",
    "                            invalid_bands[col] += 1\n",
    "                            array = np.zeros((5, 5), dtype=np.float32)  # Impute with zeros\n",
    "                            patch.append(array)\n",
    "                            continue\n",
    "                        try:\n",
    "                            parsed_data = ast.literal_eval(data) if isinstance(data, str) else data\n",
    "                            array = np.array(parsed_data, dtype=np.float32).reshape(5, 5)\n",
    "                        except (ValueError, SyntaxError, TypeError) as e:\n",
    "                            invalid_bands[col] += 1\n",
    "                            array = np.zeros((5, 5), dtype=np.float32)  # Impute for parsing errors\n",
    "                            patch.append(array)\n",
    "                            continue\n",
    "                        patch.append(array)\n",
    "                    patch = np.stack(patch, axis=-1)\n",
    "                    if patch.shape != (5, 5, 136):  # Expected shape: 17 bands * 8 months\n",
    "                        raise ValueError(f\"Unexpected patch shape: {patch.shape}\")\n",
    "                    all_features.append(patch)\n",
    "                    all_labels.append(row['l3_species'])\n",
    "                    species_counts[row['l3_species']] += 1\n",
    "                except (ValueError, SyntaxError, TypeError) as e:\n",
    "                    invalid_samples.append((file, idx, str(e)))\n",
    "                    continue\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process file {file}: {e}\")\n",
    "            continue\n",
    "\n",
    "# Log invalid samples and bands\n",
    "print(f\"\\nTotal samples attempted: {total_samples_attempted}\")\n",
    "print(f\"Valid samples processed: {len(all_features)}\")\n",
    "if invalid_samples:\n",
    "    print(f\"\\nSkipped {len(invalid_samples)} invalid samples:\")\n",
    "    for file, idx, error in invalid_samples:\n",
    "        print(f\"File: {file}, Row: {idx}, Error: {error}\")\n",
    "if invalid_bands:\n",
    "    print(\"\\nBands with None or missing values:\")\n",
    "    for band, count in invalid_bands.most_common():\n",
    "        print(f\"  {band}: {count} times\")\n",
    "print(\"\\nValid samples per species:\")\n",
    "for species, count in species_counts.most_common():\n",
    "    print(f\"  {species}: {count}\")\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "if not all_features:\n",
    "    print(\"\\nError: No valid samples loaded. Using Random Forest with dummy data.\")\n",
    "    X_dummy = np.random.rand(100, 5*5*136)  # Updated for 136 channels\n",
    "    y_dummy = np.random.randint(0, 5, 100)\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_dummy, y_dummy)\n",
    "    print(\"Random Forest dummy accuracy:\", rf.score(X_dummy, y_dummy))\n",
    "    print(\"Please re-export data with updated GEE code.\")\n",
    "    exit()\n",
    "\n",
    "X = np.array(all_features, dtype=np.float32)  # Shape: (N, 5, 5, 136)\n",
    "y = np.array(all_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19613cf5",
   "metadata": {
    "papermill": {
     "duration": 0.004759,
     "end_time": "2025-07-18T21:53:57.424127",
     "exception": false,
     "start_time": "2025-07-18T21:53:57.419368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59bd5380",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T21:53:57.433033Z",
     "iopub.status.busy": "2025-07-18T21:53:57.432434Z",
     "iopub.status.idle": "2025-07-18T22:09:46.969464Z",
     "shell.execute_reply": "2025-07-18T22:09:46.968602Z"
    },
    "papermill": {
     "duration": 949.543183,
     "end_time": "2025-07-18T22:09:46.970958",
     "exception": false,
     "start_time": "2025-07-18T21:53:57.427775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data shape after SMOTE: (71668, 5, 5, 136), Number of classes: 19\n",
      "Data range: min=-383.2718, max=742.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1752875645.875785      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1752875675.188963      67 service.cc:148] XLA service 0x61211670 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1752875675.189732      67 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "I0000 00:00:1752875677.467006      67 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   8/1120\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 17ms/step - accuracy: 0.0831 - loss: 3.4725"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1752875687.833734      67 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 30ms/step - accuracy: 0.2056 - loss: 2.6242 - val_accuracy: 0.2796 - val_loss: 2.1905 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.3323 - loss: 2.0596 - val_accuracy: 0.2990 - val_loss: 2.2718 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 17ms/step - accuracy: 0.3797 - loss: 1.8894 - val_accuracy: 0.3415 - val_loss: 1.9422 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 17ms/step - accuracy: 0.4262 - loss: 1.7539 - val_accuracy: 0.3871 - val_loss: 1.8262 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.4644 - loss: 1.6359 - val_accuracy: 0.3639 - val_loss: 2.0545 - learning_rate: 1.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - accuracy: 0.5071 - loss: 1.5086 - val_accuracy: 0.4611 - val_loss: 1.6566 - learning_rate: 1.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.5351 - loss: 1.4126 - val_accuracy: 0.3957 - val_loss: 2.3007 - learning_rate: 1.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.5600 - loss: 1.3307 - val_accuracy: 0.4047 - val_loss: 2.0223 - learning_rate: 1.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.5793 - loss: 1.2760 - val_accuracy: 0.4574 - val_loss: 1.8634 - learning_rate: 1.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - accuracy: 0.5935 - loss: 1.2299 - val_accuracy: 0.4179 - val_loss: 1.8329 - learning_rate: 1.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - accuracy: 0.6078 - loss: 1.1757 - val_accuracy: 0.4603 - val_loss: 1.5898 - learning_rate: 1.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - accuracy: 0.6205 - loss: 1.1421 - val_accuracy: 0.4406 - val_loss: 2.0527 - learning_rate: 1.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.6368 - loss: 1.0937 - val_accuracy: 0.4274 - val_loss: 2.2944 - learning_rate: 1.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - accuracy: 0.6510 - loss: 1.0505 - val_accuracy: 0.4947 - val_loss: 1.5449 - learning_rate: 1.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.6588 - loss: 1.0224 - val_accuracy: 0.4221 - val_loss: 2.4455 - learning_rate: 1.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.6695 - loss: 0.9870 - val_accuracy: 0.5030 - val_loss: 1.6830 - learning_rate: 1.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - accuracy: 0.6812 - loss: 0.9587 - val_accuracy: 0.5134 - val_loss: 1.7196 - learning_rate: 1.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.6893 - loss: 0.9252 - val_accuracy: 0.4624 - val_loss: 1.9198 - learning_rate: 1.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.6938 - loss: 0.9083 - val_accuracy: 0.5004 - val_loss: 1.7277 - learning_rate: 1.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - accuracy: 0.7315 - loss: 0.7990 - val_accuracy: 0.5828 - val_loss: 1.3818 - learning_rate: 5.0000e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.7451 - loss: 0.7467 - val_accuracy: 0.5457 - val_loss: 1.6637 - learning_rate: 5.0000e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.7511 - loss: 0.7319 - val_accuracy: 0.5357 - val_loss: 1.6170 - learning_rate: 5.0000e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.7603 - loss: 0.7063 - val_accuracy: 0.5561 - val_loss: 1.6361 - learning_rate: 5.0000e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.7648 - loss: 0.6898 - val_accuracy: 0.5837 - val_loss: 1.4065 - learning_rate: 5.0000e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.7726 - loss: 0.6641 - val_accuracy: 0.5864 - val_loss: 1.4764 - learning_rate: 5.0000e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.7945 - loss: 0.6062 - val_accuracy: 0.5915 - val_loss: 1.5018 - learning_rate: 2.5000e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.8049 - loss: 0.5713 - val_accuracy: 0.6075 - val_loss: 1.3822 - learning_rate: 2.5000e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - accuracy: 0.8067 - loss: 0.5611 - val_accuracy: 0.6092 - val_loss: 1.3790 - learning_rate: 2.5000e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.8097 - loss: 0.5517 - val_accuracy: 0.5936 - val_loss: 1.5309 - learning_rate: 2.5000e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.8159 - loss: 0.5307 - val_accuracy: 0.6011 - val_loss: 1.4571 - learning_rate: 2.5000e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - accuracy: 0.8217 - loss: 0.5140 - val_accuracy: 0.5980 - val_loss: 1.5611 - learning_rate: 2.5000e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - accuracy: 0.8249 - loss: 0.5083 - val_accuracy: 0.5236 - val_loss: 1.8630 - learning_rate: 2.5000e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - accuracy: 0.8267 - loss: 0.5023 - val_accuracy: 0.5626 - val_loss: 1.7008 - learning_rate: 2.5000e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.8406 - loss: 0.4620 - val_accuracy: 0.6087 - val_loss: 1.4997 - learning_rate: 1.2500e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.8441 - loss: 0.4477 - val_accuracy: 0.6210 - val_loss: 1.4686 - learning_rate: 1.2500e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.8494 - loss: 0.4312 - val_accuracy: 0.6087 - val_loss: 1.5531 - learning_rate: 1.2500e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.8492 - loss: 0.4310 - val_accuracy: 0.6089 - val_loss: 1.5698 - learning_rate: 1.2500e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.8498 - loss: 0.4302 - val_accuracy: 0.6041 - val_loss: 1.5461 - learning_rate: 1.2500e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.8610 - loss: 0.3955 - val_accuracy: 0.6194 - val_loss: 1.5185 - learning_rate: 6.2500e-06\n",
      "Epoch 40/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.8625 - loss: 0.3914 - val_accuracy: 0.6372 - val_loss: 1.4875 - learning_rate: 6.2500e-06\n",
      "Epoch 41/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - accuracy: 0.8638 - loss: 0.3902 - val_accuracy: 0.6221 - val_loss: 1.5197 - learning_rate: 6.2500e-06\n",
      "Epoch 42/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.8683 - loss: 0.3806 - val_accuracy: 0.6247 - val_loss: 1.5728 - learning_rate: 6.2500e-06\n",
      "Epoch 43/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - accuracy: 0.8655 - loss: 0.3844 - val_accuracy: 0.6301 - val_loss: 1.5340 - learning_rate: 6.2500e-06\n",
      "Epoch 44/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.8694 - loss: 0.3725 - val_accuracy: 0.6335 - val_loss: 1.5238 - learning_rate: 3.1250e-06\n",
      "Epoch 45/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.8720 - loss: 0.3677 - val_accuracy: 0.6275 - val_loss: 1.5177 - learning_rate: 3.1250e-06\n",
      "Epoch 46/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.8727 - loss: 0.3665 - val_accuracy: 0.6236 - val_loss: 1.5542 - learning_rate: 3.1250e-06\n",
      "Epoch 47/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.8748 - loss: 0.3612 - val_accuracy: 0.6303 - val_loss: 1.5503 - learning_rate: 3.1250e-06\n",
      "Epoch 48/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.8740 - loss: 0.3598 - val_accuracy: 0.6298 - val_loss: 1.5459 - learning_rate: 3.1250e-06\n",
      "Epoch 49/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - accuracy: 0.8760 - loss: 0.3517 - val_accuracy: 0.6256 - val_loss: 1.5711 - learning_rate: 1.5625e-06\n",
      "Epoch 50/50\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - accuracy: 0.8752 - loss: 0.3576 - val_accuracy: 0.6344 - val_loss: 1.5314 - learning_rate: 1.5625e-06\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.6325 - loss: 1.6969\n",
      "\n",
      "Test Accuracy: 0.6314\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step\n",
      "\n",
      "Classification Report (Test Set):\n",
      "{\n",
      "    \"alder\": {\n",
      "        \"precision\": 0.4805194805194805,\n",
      "        \"recall\": 0.45962732919254656,\n",
      "        \"f1-score\": 0.4698412698412698,\n",
      "        \"support\": 322.0\n",
      "    },\n",
      "    \"birch\": {\n",
      "        \"precision\": 0.3852040816326531,\n",
      "        \"recall\": 0.4081081081081081,\n",
      "        \"f1-score\": 0.39632545931758534,\n",
      "        \"support\": 370.0\n",
      "    },\n",
      "    \"black pine\": {\n",
      "        \"precision\": 0.5463917525773195,\n",
      "        \"recall\": 0.8548387096774194,\n",
      "        \"f1-score\": 0.6666666666666666,\n",
      "        \"support\": 62.0\n",
      "    },\n",
      "    \"cherry\": {\n",
      "        \"precision\": 0.36363636363636365,\n",
      "        \"recall\": 0.5405405405405406,\n",
      "        \"f1-score\": 0.4347826086956522,\n",
      "        \"support\": 37.0\n",
      "    },\n",
      "    \"douglas fir\": {\n",
      "        \"precision\": 0.7613293051359517,\n",
      "        \"recall\": 0.7682926829268293,\n",
      "        \"f1-score\": 0.7647951441578148,\n",
      "        \"support\": 328.0\n",
      "    },\n",
      "    \"english oak\": {\n",
      "        \"precision\": 0.5489130434782609,\n",
      "        \"recall\": 0.47980997624703087,\n",
      "        \"f1-score\": 0.5120405576679341,\n",
      "        \"support\": 421.0\n",
      "    },\n",
      "    \"european ash\": {\n",
      "        \"precision\": 0.47586206896551725,\n",
      "        \"recall\": 0.4169184290030212,\n",
      "        \"f1-score\": 0.4444444444444445,\n",
      "        \"support\": 331.0\n",
      "    },\n",
      "    \"european beech\": {\n",
      "        \"precision\": 0.6807639836289222,\n",
      "        \"recall\": 0.6988795518207283,\n",
      "        \"f1-score\": 0.6897028334485141,\n",
      "        \"support\": 714.0\n",
      "    },\n",
      "    \"european larch\": {\n",
      "        \"precision\": 0.4854368932038835,\n",
      "        \"recall\": 0.5847953216374269,\n",
      "        \"f1-score\": 0.5305039787798408,\n",
      "        \"support\": 171.0\n",
      "    },\n",
      "    \"japanese larch\": {\n",
      "        \"precision\": 0.7339055793991416,\n",
      "        \"recall\": 0.7066115702479339,\n",
      "        \"f1-score\": 0.72,\n",
      "        \"support\": 242.0\n",
      "    },\n",
      "    \"linden\": {\n",
      "        \"precision\": 0.3548387096774194,\n",
      "        \"recall\": 0.4583333333333333,\n",
      "        \"f1-score\": 0.39999999999999997,\n",
      "        \"support\": 24.0\n",
      "    },\n",
      "    \"norway spruce\": {\n",
      "        \"precision\": 0.7456492637215528,\n",
      "        \"recall\": 0.7367724867724867,\n",
      "        \"f1-score\": 0.7411842980705257,\n",
      "        \"support\": 756.0\n",
      "    },\n",
      "    \"poplar\": {\n",
      "        \"precision\": 0.5238095238095238,\n",
      "        \"recall\": 0.5689655172413793,\n",
      "        \"f1-score\": 0.5454545454545455,\n",
      "        \"support\": 58.0\n",
      "    },\n",
      "    \"red oak\": {\n",
      "        \"precision\": 0.5877862595419847,\n",
      "        \"recall\": 0.7031963470319634,\n",
      "        \"f1-score\": 0.6403326403326404,\n",
      "        \"support\": 219.0\n",
      "    },\n",
      "    \"scots pine\": {\n",
      "        \"precision\": 0.8417721518987342,\n",
      "        \"recall\": 0.8220024721878862,\n",
      "        \"f1-score\": 0.8317698561601,\n",
      "        \"support\": 809.0\n",
      "    },\n",
      "    \"sessile oak\": {\n",
      "        \"precision\": 0.5789473684210527,\n",
      "        \"recall\": 0.5205047318611987,\n",
      "        \"f1-score\": 0.5481727574750832,\n",
      "        \"support\": 317.0\n",
      "    },\n",
      "    \"silver fir\": {\n",
      "        \"precision\": 0.636986301369863,\n",
      "        \"recall\": 0.768595041322314,\n",
      "        \"f1-score\": 0.6966292134831461,\n",
      "        \"support\": 121.0\n",
      "    },\n",
      "    \"sycamore maple\": {\n",
      "        \"precision\": 0.44981412639405205,\n",
      "        \"recall\": 0.3853503184713376,\n",
      "        \"f1-score\": 0.41509433962264153,\n",
      "        \"support\": 314.0\n",
      "    },\n",
      "    \"weymouth pine\": {\n",
      "        \"precision\": 0.7160493827160493,\n",
      "        \"recall\": 0.8169014084507042,\n",
      "        \"f1-score\": 0.7631578947368421,\n",
      "        \"support\": 71.0\n",
      "    },\n",
      "    \"accuracy\": 0.6314401266045366,\n",
      "    \"macro avg\": {\n",
      "        \"precision\": 0.5735587178804067,\n",
      "        \"recall\": 0.6157391513723256,\n",
      "        \"f1-score\": 0.590047289913434,\n",
      "        \"support\": 5687.0\n",
      "    },\n",
      "    \"weighted avg\": {\n",
      "        \"precision\": 0.632071794470547,\n",
      "        \"recall\": 0.6314401266045366,\n",
      "        \"f1-score\": 0.6301353406507951,\n",
      "        \"support\": 5687.0\n",
      "    }\n",
      "}\n",
      "Precision: 0.6321\n",
      "Recall: 0.6314\n",
      "F1-Score: 0.6301\n",
      "Saved: model3.keras, report3.json, confusion3.npy, confusion3.png, labelencoder3.pkl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, recall_score, f1_score, confusion_matrix, precision_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# 1. Encode class labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# 2. Flatten features for initial split\n",
    "X_flat = X.reshape(X.shape[0], -1)\n",
    "\n",
    "# 3. Initial train/temp split\n",
    "X_train_raw, X_temp, y_train_raw, y_temp = train_test_split(\n",
    "    X_flat, y_encoded, test_size=0.3, stratify=y_encoded, random_state=42\n",
    ")\n",
    "\n",
    "# 4. Apply SMOTE only to training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_raw, y_train_raw)\n",
    "\n",
    "# 5. Reshape back to original dimensions\n",
    "X_train_resampled = X_train_resampled.reshape(-1, 5, 5, 136)\n",
    "X_temp = X_temp.reshape(-1, 5, 5, 136)\n",
    "\n",
    "# 6. Convert to one-hot encoding\n",
    "y_train_onehot = tf.keras.utils.to_categorical(y_train_resampled)\n",
    "y_temp_onehot = tf.keras.utils.to_categorical(y_temp)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# 7. Split temp into val and test sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp_onehot, test_size=0.5, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nData shape after SMOTE: {X_train_resampled.shape}, Number of classes: {num_classes}\")\n",
    "print(f\"Data range: min={X_train_resampled.min():.4f}, max={X_train_resampled.max():.4f}\")\n",
    "\n",
    "# 8. Compute class weights from the resampled training data\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train_resampled), y=y_train_resampled)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# 9. Define ResNet-18 Model\n",
    "def residual_block(x, filters, kernel_size=3, stride=1, conv_shortcut=True):\n",
    "    \"\"\"A ResNet residual block with shortcut connection.\"\"\"\n",
    "    shortcut = x\n",
    "    if conv_shortcut:\n",
    "        shortcut = layers.Conv2D(filters, 1, strides=stride, padding='same')(shortcut)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "    \n",
    "    x = layers.Conv2D(filters, kernel_size, strides=stride, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters, kernel_size, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Add()([shortcut, x])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def build_resnet18(input_shape=(5, 5, 136), num_classes=num_classes):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Initial convolution\n",
    "    x = layers.Conv2D(64, 3, strides=1, padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # ResNet blocks (4 stages with 2 residual blocks each)\n",
    "    x = residual_block(x, 64)\n",
    "    x = residual_block(x, 64)\n",
    "    \n",
    "    x = residual_block(x, 128, stride=2, conv_shortcut=True)\n",
    "    x = residual_block(x, 128)\n",
    "    \n",
    "    x = residual_block(x, 256, stride=2, conv_shortcut=True)\n",
    "    x = residual_block(x, 256)\n",
    "    \n",
    "    x = residual_block(x, 512, stride=2, conv_shortcut=True)\n",
    "    x = residual_block(x, 512)\n",
    "    \n",
    "    # Global average pooling and dense layer\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model3 = models.Model(inputs, outputs, name='resnet18')\n",
    "    return model3\n",
    "\n",
    "model3 = build_resnet18()\n",
    "model3.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 10. Data Augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.3),\n",
    "    layers.RandomZoom(0.2),\n",
    "])\n",
    "\n",
    "# 11. Train Model\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "history = model3.fit(\n",
    "    data_augmentation(X_train_resampled), y_train_onehot,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ModelCheckpoint('best_model3.keras', save_best_only=True),\n",
    "        lr_scheduler\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 12. Evaluate Model\n",
    "test_loss, test_accuracy = model3.evaluate(X_test, y_test)\n",
    "print(f\"\\nTest Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# 13. Additional Metrics\n",
    "y_pred = model3.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "report3 = classification_report(y_test_classes, y_pred_classes, target_names=label_encoder.classes_, output_dict=True)\n",
    "print(\"\\nClassification Report (Test Set):\")\n",
    "print(json.dumps(report3, indent=4))\n",
    "print(f\"Precision: {precision_score(y_test_classes, y_pred_classes, average='weighted'):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test_classes, y_pred_classes, average='weighted'):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test_classes, y_pred_classes, average='weighted'):.4f}\")\n",
    "\n",
    "# 14. Confusion Matrix\n",
    "cm = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_, cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix (Test Set)')\n",
    "plt.savefig('confusion3.png')\n",
    "plt.close()\n",
    "\n",
    "# 15. Save Outputs\n",
    "model3.save('model3.keras')  # Better to save as .keras format for TensorFlow models\n",
    "json.dump(report3, open('report3.json', 'w'), indent=4)\n",
    "np.save('confusion3.npy', cm)\n",
    "joblib.dump(label_encoder, 'labelencoder3.pkl')\n",
    "\n",
    "print(\"Saved: model3.keras, report3.json, confusion3.npy, confusion3.png, labelencoder3.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1501912",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T22:09:48.350977Z",
     "iopub.status.busy": "2025-07-18T22:09:48.350588Z",
     "iopub.status.idle": "2025-07-18T22:11:13.253591Z",
     "shell.execute_reply": "2025-07-18T22:11:13.252463Z"
    },
    "papermill": {
     "duration": 85.623143,
     "end_time": "2025-07-18T22:11:13.254987",
     "exception": false,
     "start_time": "2025-07-18T22:09:47.631844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 19 GeoJSON files in /kaggle/input/final-test-data\n",
      "Processing file: needleleaf_douglas fir_douglas firmar-oct-2022.geojson, Rows: 506\n",
      "Processing file: broadleaf_short-lived deciduous_aldermar-oct-2022.geojson, Rows: 420\n",
      "Processing file: broadleaf_beech_european beechmar-oct-2022.geojson, Rows: 1703\n",
      "Processing file: needleleaf_larch_japanese larchmar-oct-2022.geojson, Rows: 135\n",
      "Processing file: broadleaf_short-lived deciduous_poplarmar-oct-2022.geojson, Rows: 77\n",
      "Processing file: needleleaf_pine_scots pinemar-oct-2022.geojson, Rows: 1202\n",
      "Processing file: broadleaf_oak_english oakmar-oct-2022.geojson, Rows: 645\n",
      "Processing file: needleleaf_larch_european larchmar-oct-2022.geojson, Rows: 221\n",
      "Processing file: broadleaf_long-lived deciduous_sycamore maplemar-oct-2022.geojson, Rows: 725\n",
      "Processing file: broadleaf_long-lived deciduous_european ashmar-oct-2022.geojson, Rows: 432\n",
      "Processing file: broadleaf_short-lived deciduous_birchmar-oct-2022.geojson, Rows: 353\n",
      "Processing file: broadleaf_long-lived deciduous_lindenmar-oct-2022.geojson, Rows: 51\n",
      "Processing file: broadleaf_oak_red oakmar-oct-2022.geojson, Rows: 381\n",
      "Processing file: needleleaf_spruce_norway sprucemar-oct-2022.geojson, Rows: 746\n",
      "Processing file: broadleaf_oak_sessile oakmar-oct-2022.geojson, Rows: 493\n",
      "Processing file: needleleaf_pine_weymouth pinemar-oct-2022.geojson, Rows: 22\n",
      "Processing file: needleleaf_fir_silver firmar-oct-2022.geojson, Rows: 173\n",
      "Processing file: broadleaf_long-lived deciduous_cherrymar-oct-2022.geojson, Rows: 57\n",
      "Processing file: needleleaf_pine_black pinemar-oct-2022.geojson, Rows: 9\n",
      "\n",
      "Total samples attempted: 8351\n",
      "Valid samples processed: 8351\n",
      "\n",
      "Bands with missing/None/parsing issues in test data:\n",
      "  B1_4: 6893 times\n",
      "  B2_4: 6893 times\n",
      "  B3_4: 6893 times\n",
      "  B4_4: 6893 times\n",
      "  B5_4: 6893 times\n",
      "  B6_4: 6893 times\n",
      "  B7_4: 6893 times\n",
      "  B8_4: 6893 times\n",
      "  B8A_4: 6893 times\n",
      "  B9_4: 6893 times\n",
      "  B11_4: 6893 times\n",
      "  B12_4: 6893 times\n",
      "  NDVI_4: 6893 times\n",
      "  EVI_4: 6893 times\n",
      "  SAVI_4: 6893 times\n",
      "  NDWI_4: 6893 times\n",
      "  DEM_4: 6759 times\n",
      "  B2_7: 4589 times\n",
      "  B3_7: 4589 times\n",
      "  B4_7: 4589 times\n",
      "  B5_7: 4589 times\n",
      "  B6_7: 4589 times\n",
      "  B7_7: 4589 times\n",
      "  B8_7: 4589 times\n",
      "  B8A_7: 4589 times\n",
      "  B11_7: 4589 times\n",
      "  B12_7: 4589 times\n",
      "  NDVI_7: 4589 times\n",
      "  EVI_7: 4589 times\n",
      "  SAVI_7: 4589 times\n",
      "  NDWI_7: 4589 times\n",
      "  B1_7: 4585 times\n",
      "  B9_7: 4585 times\n",
      "  DEM_7: 4147 times\n",
      "  B2_1: 3744 times\n",
      "  B3_1: 3744 times\n",
      "  B4_1: 3744 times\n",
      "  B5_1: 3744 times\n",
      "  B6_1: 3744 times\n",
      "  B7_1: 3744 times\n",
      "  B8_1: 3744 times\n",
      "  B8A_1: 3744 times\n",
      "  B11_1: 3744 times\n",
      "  B12_1: 3744 times\n",
      "  NDVI_1: 3744 times\n",
      "  EVI_1: 3744 times\n",
      "  SAVI_1: 3744 times\n",
      "  NDWI_1: 3744 times\n",
      "  B1_1: 3743 times\n",
      "  B9_1: 3743 times\n",
      "  DEM_1: 3423 times\n",
      "  B2_6: 645 times\n",
      "  B3_6: 645 times\n",
      "  B4_6: 645 times\n",
      "  B5_6: 645 times\n",
      "  B6_6: 645 times\n",
      "  B7_6: 645 times\n",
      "  B8_6: 645 times\n",
      "  B8A_6: 645 times\n",
      "  B11_6: 645 times\n",
      "  B12_6: 645 times\n",
      "  NDVI_6: 645 times\n",
      "  EVI_6: 645 times\n",
      "  SAVI_6: 645 times\n",
      "  NDWI_6: 645 times\n",
      "  B1_6: 644 times\n",
      "  B9_6: 644 times\n",
      "\n",
      "Training class distribution:\n",
      "sycamore maple    3772\n",
      "red oak           3772\n",
      "english oak       3772\n",
      "european beech    3772\n",
      "silver fir        3772\n",
      "norway spruce     3772\n",
      "linden            3772\n",
      "scots pine        3772\n",
      "european larch    3772\n",
      "japanese larch    3772\n",
      "european ash      3772\n",
      "sessile oak       3772\n",
      "cherry            3772\n",
      "birch             3772\n",
      "black pine        3772\n",
      "douglas fir       3772\n",
      "alder             3772\n",
      "poplar            3772\n",
      "weymouth pine     3772\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test class distribution:\n",
      "european beech    1703\n",
      "scots pine        1202\n",
      "norway spruce      746\n",
      "sycamore maple     725\n",
      "english oak        645\n",
      "douglas fir        506\n",
      "sessile oak        493\n",
      "european ash       432\n",
      "alder              420\n",
      "red oak            381\n",
      "birch              353\n",
      "european larch     221\n",
      "silver fir         173\n",
      "japanese larch     135\n",
      "poplar              77\n",
      "cherry              57\n",
      "linden              51\n",
      "weymouth pine       22\n",
      "black pine           9\n",
      "Name: count, dtype: int64\n",
      "Classes missing in test data: set()\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step\n",
      "\n",
      "Final Test Data Accuracy: 0.4154\n",
      "\n",
      "Classification Report for Final Test Data:\n",
      "{\n",
      "    \"alder\": {\n",
      "        \"precision\": 0.24177949709864605,\n",
      "        \"recall\": 0.2976190476190476,\n",
      "        \"f1-score\": 0.2668089647812167,\n",
      "        \"support\": 420.0\n",
      "    },\n",
      "    \"birch\": {\n",
      "        \"precision\": 0.12464589235127478,\n",
      "        \"recall\": 0.12464589235127478,\n",
      "        \"f1-score\": 0.12464589235127478,\n",
      "        \"support\": 353.0\n",
      "    },\n",
      "    \"black pine\": {\n",
      "        \"precision\": 0.0,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1-score\": 0.0,\n",
      "        \"support\": 9.0\n",
      "    },\n",
      "    \"cherry\": {\n",
      "        \"precision\": 0.01694915254237288,\n",
      "        \"recall\": 0.017543859649122806,\n",
      "        \"f1-score\": 0.017241379310344827,\n",
      "        \"support\": 57.0\n",
      "    },\n",
      "    \"douglas fir\": {\n",
      "        \"precision\": 0.4691046658259773,\n",
      "        \"recall\": 0.7351778656126482,\n",
      "        \"f1-score\": 0.5727482678983834,\n",
      "        \"support\": 506.0\n",
      "    },\n",
      "    \"english oak\": {\n",
      "        \"precision\": 0.1628498727735369,\n",
      "        \"recall\": 0.19844961240310077,\n",
      "        \"f1-score\": 0.17889587700908458,\n",
      "        \"support\": 645.0\n",
      "    },\n",
      "    \"european ash\": {\n",
      "        \"precision\": 0.19718309859154928,\n",
      "        \"recall\": 0.25925925925925924,\n",
      "        \"f1-score\": 0.22399999999999998,\n",
      "        \"support\": 432.0\n",
      "    },\n",
      "    \"european beech\": {\n",
      "        \"precision\": 0.615686274509804,\n",
      "        \"recall\": 0.553141514973576,\n",
      "        \"f1-score\": 0.5827404887101763,\n",
      "        \"support\": 1703.0\n",
      "    },\n",
      "    \"european larch\": {\n",
      "        \"precision\": 0.1715686274509804,\n",
      "        \"recall\": 0.3167420814479638,\n",
      "        \"f1-score\": 0.22257551669316375,\n",
      "        \"support\": 221.0\n",
      "    },\n",
      "    \"japanese larch\": {\n",
      "        \"precision\": 0.33121019108280253,\n",
      "        \"recall\": 0.7703703703703704,\n",
      "        \"f1-score\": 0.46325167037861914,\n",
      "        \"support\": 135.0\n",
      "    },\n",
      "    \"linden\": {\n",
      "        \"precision\": 0.0,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1-score\": 0.0,\n",
      "        \"support\": 51.0\n",
      "    },\n",
      "    \"norway spruce\": {\n",
      "        \"precision\": 0.6767830045523521,\n",
      "        \"recall\": 0.5978552278820375,\n",
      "        \"f1-score\": 0.6348754448398577,\n",
      "        \"support\": 746.0\n",
      "    },\n",
      "    \"poplar\": {\n",
      "        \"precision\": 0.08333333333333333,\n",
      "        \"recall\": 0.07792207792207792,\n",
      "        \"f1-score\": 0.08053691275167785,\n",
      "        \"support\": 77.0\n",
      "    },\n",
      "    \"red oak\": {\n",
      "        \"precision\": 0.3402061855670103,\n",
      "        \"recall\": 0.25984251968503935,\n",
      "        \"f1-score\": 0.29464285714285715,\n",
      "        \"support\": 381.0\n",
      "    },\n",
      "    \"scots pine\": {\n",
      "        \"precision\": 0.7704517704517705,\n",
      "        \"recall\": 0.5249584026622296,\n",
      "        \"f1-score\": 0.624443344878773,\n",
      "        \"support\": 1202.0\n",
      "    },\n",
      "    \"sessile oak\": {\n",
      "        \"precision\": 0.3025210084033613,\n",
      "        \"recall\": 0.21906693711967545,\n",
      "        \"f1-score\": 0.25411764705882356,\n",
      "        \"support\": 493.0\n",
      "    },\n",
      "    \"silver fir\": {\n",
      "        \"precision\": 0.512,\n",
      "        \"recall\": 0.3699421965317919,\n",
      "        \"f1-score\": 0.4295302013422818,\n",
      "        \"support\": 173.0\n",
      "    },\n",
      "    \"sycamore maple\": {\n",
      "        \"precision\": 0.37300177619893427,\n",
      "        \"recall\": 0.2896551724137931,\n",
      "        \"f1-score\": 0.32608695652173914,\n",
      "        \"support\": 725.0\n",
      "    },\n",
      "    \"weymouth pine\": {\n",
      "        \"precision\": 0.058823529411764705,\n",
      "        \"recall\": 0.3181818181818182,\n",
      "        \"f1-score\": 0.09929078014184396,\n",
      "        \"support\": 22.0\n",
      "    },\n",
      "    \"accuracy\": 0.41539935337085376,\n",
      "    \"macro avg\": {\n",
      "        \"precision\": 0.2867419936918668,\n",
      "        \"recall\": 0.3121249397939383,\n",
      "        \"f1-score\": 0.28402274746369044,\n",
      "        \"support\": 8351.0\n",
      "    },\n",
      "    \"weighted avg\": {\n",
      "        \"precision\": 0.4528419496166611,\n",
      "        \"recall\": 0.41539935337085376,\n",
      "        \"f1-score\": 0.4243789514718835,\n",
      "        \"support\": 8351.0\n",
      "    }\n",
      "}\n",
      "Precision (Final Test): 0.4528\n",
      "Recall (Final Test): 0.4154\n",
      "F1-Score (Final Test): 0.4244\n",
      "\n",
      "Total Number of Test Points: 8351\n",
      "Saved: report_final.json, confusion_final.npy, confusion_final.png\n"
     ]
    }
   ],
   "source": [
    "# 16. Evaluate Model on Final Test Data\n",
    "import os\n",
    "import ast\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from collections import Counter\n",
    "\n",
    "test_data_dir = \"/kaggle/input/final-test-data\"\n",
    "test_features = []\n",
    "test_labels = []\n",
    "test_invalid_samples = []\n",
    "test_invalid_bands = Counter()\n",
    "total_samples_attempted = 0  # Track total samples processed\n",
    "\n",
    "# Check if directory exists and list files\n",
    "if not os.path.exists(test_data_dir):\n",
    "    print(f\"\\nError: Test data directory {test_data_dir} does not exist.\")\n",
    "    exit()\n",
    "geojson_files = [f for f in os.listdir(test_data_dir) if f.endswith(\".geojson\")]\n",
    "print(f\"\\nFound {len(geojson_files)} GeoJSON files in {test_data_dir}\")\n",
    "\n",
    "# Load all GeoJSON files from test data directory\n",
    "for file in geojson_files:\n",
    "    try:\n",
    "        file_path = os.path.join(test_data_dir, file)\n",
    "        gdf = gpd.read_file(file_path)\n",
    "        print(f\"Processing file: {file}, Rows: {len(gdf)}\")\n",
    "        total_samples_attempted += len(gdf)  # Count all rows in the file\n",
    "        for idx, row in gdf.iterrows():\n",
    "            try:\n",
    "                patch = []\n",
    "                for col in band_columns:\n",
    "                    if col not in gdf.columns:\n",
    "                        test_invalid_bands[col] += 1\n",
    "                        array = np.zeros((5, 5), dtype=np.float32)  # Impute with zeros\n",
    "                        patch.append(array)\n",
    "                        continue\n",
    "                    data = row[col]\n",
    "                    if data is None or (isinstance(data, str) and data.lower() == 'none'):\n",
    "                        test_invalid_bands[col] += 1\n",
    "                        array = np.zeros((5, 5), dtype=np.float32)  # Impute with zeros\n",
    "                        patch.append(array)\n",
    "                        continue\n",
    "                    try:\n",
    "                        parsed_data = ast.literal_eval(data) if isinstance(data, str) else data\n",
    "                        array = np.array(parsed_data, dtype=np.float32).reshape(5, 5)\n",
    "                    except (ValueError, SyntaxError, TypeError) as e:\n",
    "                        test_invalid_bands[col] += 1\n",
    "                        array = np.zeros((5, 5), dtype=np.float32)  # Impute for parsing errors\n",
    "                        patch.append(array)\n",
    "                        continue\n",
    "                    patch.append(array)\n",
    "                patch = np.stack(patch, axis=-1)\n",
    "                if patch.shape != (5, 5, 136):  # Expected shape: 17 bands * 8 months\n",
    "                    raise ValueError(f\"Unexpected patch shape: {patch.shape}\")\n",
    "                test_features.append(patch)\n",
    "                test_labels.append(row['l3_species'])\n",
    "            except (ValueError, SyntaxError, TypeError) as e:\n",
    "                test_invalid_samples.append((file, idx, str(e)))\n",
    "                continue\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process file {file}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Log invalid samples and bands\n",
    "print(f\"\\nTotal samples attempted: {total_samples_attempted}\")\n",
    "print(f\"Valid samples processed: {len(test_features)}\")\n",
    "if test_invalid_samples:\n",
    "    print(f\"\\nSkipped {len(test_invalid_samples)} invalid test samples:\")\n",
    "    for file, idx, error in test_invalid_samples:\n",
    "        print(f\"File: {file}, Row: {idx}, Error: {error}\")\n",
    "if test_invalid_bands:\n",
    "    print(\"\\nBands with missing/None/parsing issues in test data:\")\n",
    "    for band, count in test_invalid_bands.most_common():\n",
    "        print(f\"  {band}: {count} times\")\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "if not test_features:\n",
    "    print(\"\\nError: No valid test samples loaded. Cannot evaluate model.\")\n",
    "    exit()\n",
    "\n",
    "X_test_final = np.array(test_features, dtype=np.float32)  # Shape: (N, 5, 5, 136)\n",
    "y_test_final = np.array(test_labels)\n",
    "\n",
    "# Preprocess test data\n",
    "try:\n",
    "    y_test_final_encoded = label_encoder.transform(y_test_final)  # Use same LabelEncoder\n",
    "except ValueError as e:\n",
    "    print(f\"Error in label encoding: {e}\")\n",
    "    unknown_labels = set(y_test_final) - set(label_encoder.classes_)\n",
    "    print(f\"Unknown labels in test data: {unknown_labels}\")\n",
    "    exit()\n",
    "\n",
    "# Convert to one-hot encoding for neural network\n",
    "y_test_final_onehot = tf.keras.utils.to_categorical(y_test_final_encoded, num_classes=num_classes)\n",
    "\n",
    "# Diagnostic: Compare class distributions\n",
    "print(\"\\nTraining class distribution:\")\n",
    "print(pd.Series(label_encoder.inverse_transform(y_train_resampled)).value_counts())\n",
    "print(\"\\nTest class distribution:\")\n",
    "print(pd.Series(y_test_final).value_counts())\n",
    "missing_classes = set(label_encoder.classes_) - set(y_test_final)\n",
    "print(f\"Classes missing in test data: {missing_classes}\")\n",
    "\n",
    "# Evaluate model on test data\n",
    "y_pred_final = model3.predict(X_test_final)\n",
    "y_pred_final_classes = np.argmax(y_pred_final, axis=1)\n",
    "test_accuracy_final = (y_pred_final_classes == y_test_final_encoded).mean()\n",
    "print(f\"\\nFinal Test Data Accuracy: {test_accuracy_final:.4f}\")\n",
    "\n",
    "# Get unique labels in test data to avoid mismatch\n",
    "unique_test_labels = np.unique(y_test_final_encoded)\n",
    "unique_test_label_names = label_encoder.inverse_transform(unique_test_labels)\n",
    "\n",
    "# Additional metrics for test data\n",
    "report_final = classification_report(\n",
    "    y_test_final_encoded,\n",
    "    y_pred_final_classes,\n",
    "    labels=unique_test_labels,\n",
    "    target_names=unique_test_label_names,\n",
    "    output_dict=True\n",
    ")\n",
    "print(\"\\nClassification Report for Final Test Data:\")\n",
    "print(json.dumps(report_final, indent=4))\n",
    "print(f\"Precision (Final Test): {precision_score(y_test_final_encoded, y_pred_final_classes, average='weighted'):.4f}\")\n",
    "print(f\"Recall (Final Test): {recall_score(y_test_final_encoded, y_pred_final_classes, average='weighted'):.4f}\")\n",
    "print(f\"F1-Score (Final Test): {f1_score(y_test_final_encoded, y_pred_final_classes, average='weighted'):.4f}\")\n",
    "\n",
    "# Confusion matrix for test data\n",
    "cm_final = confusion_matrix(y_test_final_encoded, y_pred_final_classes, labels=unique_test_labels)\n",
    "plt.figure(figsize=(10, 8), dpi=100)\n",
    "sns.heatmap(cm_final, annot=True, fmt='d', xticklabels=unique_test_label_names, yticklabels=unique_test_label_names, cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix for Final Test Data')\n",
    "plt.savefig('confusion_final.png', dpi=100)\n",
    "plt.close()\n",
    "\n",
    "# Total number of test points\n",
    "print(f\"\\nTotal Number of Test Points: {len(y_test_final)}\")\n",
    "\n",
    "# Save outputs for test data\n",
    "json.dump(report_final, open('report_final.json', 'w'), indent=4)\n",
    "np.save('confusion_final.npy', cm_final)\n",
    "print(\"Saved: report_final.json, confusion_final.npy, confusion_final.png\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7762517,
     "sourceId": 12315204,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7871256,
     "sourceId": 12475667,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1450.204375,
   "end_time": "2025-07-18T22:11:17.793248",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-18T21:47:07.588873",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
