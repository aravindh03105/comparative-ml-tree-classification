{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42591c80",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-17T14:37:26.273791Z",
     "iopub.status.busy": "2025-07-17T14:37:26.273535Z",
     "iopub.status.idle": "2025-07-17T14:43:22.859212Z",
     "shell.execute_reply": "2025-07-17T14:43:22.857912Z"
    },
    "papermill": {
     "duration": 356.590592,
     "end_time": "2025-07-17T14:43:22.860726",
     "exception": false,
     "start_time": "2025-07-17T14:37:26.270134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==1.3.2\r\n",
      "  Downloading scikit_learn-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\r\n",
      "Collecting imbalanced-learn==0.12.3\r\n",
      "  Downloading imbalanced_learn-0.12.3-py3-none-any.whl.metadata (8.3 kB)\r\n",
      "Requirement already satisfied: xgboost==2.0.3 in /usr/local/lib/python3.11/dist-packages (2.0.3)\r\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.3.2) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.3.2) (1.15.3)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.3.2) (1.5.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.3.2) (3.6.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (2024.2.0)\r\n",
      "Downloading scikit_learn-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading imbalanced_learn-0.12.3-py3-none-any.whl (258 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.3/258.3 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: scikit-learn, imbalanced-learn\r\n",
      "  Attempting uninstall: scikit-learn\r\n",
      "    Found existing installation: scikit-learn 1.2.2\r\n",
      "    Uninstalling scikit-learn-1.2.2:\r\n",
      "      Successfully uninstalled scikit-learn-1.2.2\r\n",
      "  Attempting uninstall: imbalanced-learn\r\n",
      "    Found existing installation: imbalanced-learn 0.13.0\r\n",
      "    Uninstalling imbalanced-learn-0.13.0:\r\n",
      "      Successfully uninstalled imbalanced-learn-0.13.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed imbalanced-learn-0.12.3 scikit-learn-1.3.2\r\n",
      "\n",
      "Successfully imported SMOTE.\n",
      "Inspecting first 2 rows of first GeoJSON file:\n",
      "\n",
      "Row 0:\n",
      "  Band B1: shape=(5, 5), first few values=[0.1118 0.1158 0.1158 0.1158 0.1158]\n",
      "  Band B2: shape=(5, 5), first few values=[0.11225 0.11335 0.11335 0.11955 0.11955]\n",
      "  Band B11: shape=(5, 5), first few values=[0.17015 0.1891  0.1891  0.1891  0.1891 ]\n",
      "  Band NDVI: shape=(5, 5), first few values=[0.27416557 0.2273243  0.2273243  0.28395182 0.28395182]\n",
      "  Band DEM: shape=(5, 5), first few values=[88. 88. 88. 88. 88.]\n",
      "  Band B2_1: shape=(), first few values=[nan]\n",
      "  Band NDVI_7: shape=(), first few values=[nan]\n",
      "\n",
      "Row 1:\n",
      "  Band B1: shape=(5, 5), first few values=[0.125 0.124 0.124 0.124 0.124]\n",
      "  Band B2: shape=(5, 5), first few values=[0.1239 0.1176 0.1176 0.1152 0.117 ]\n",
      "  Band B11: shape=(5, 5), first few values=[0.1976 0.1797 0.1797 0.1797 0.1779]\n",
      "  Band NDVI: shape=(5, 5), first few values=[0.40535372 0.36756483 0.36756483 0.36180538 0.34991294]\n",
      "  Band DEM: shape=(5, 5), first few values=[94. 94. 93. 93. 93.]\n",
      "  Band B2_1: shape=(5, 5), first few values=[0.12365 0.11975 0.11975 0.1182  0.1181 ]\n",
      "  Band NDVI_7: shape=(5, 5), first few values=[0.3888209  0.35329902 0.35329902 0.3116279  0.3292073 ]\n",
      "Processing file: needleleaf_douglas fir_douglas firmar-oct-2022.geojson, Rows: 2185\n",
      "Processing file: broadleaf_short-lived deciduous_aldermar-oct-2022.geojson, Rows: 2143\n",
      "Processing file: broadleaf_beech_european beechmar-oct-2022.geojson, Rows: 4756\n",
      "Processing file: needleleaf_larch_japanese larchmar-oct-2022.geojson, Rows: 1613\n",
      "Processing file: broadleaf_short-lived deciduous_poplarmar-oct-2022.geojson, Rows: 387\n",
      "Processing file: needleleaf_pine_scots pinemar-oct-2022.geojson, Rows: 5389\n",
      "Processing file: broadleaf_oak_english oakmar-oct-2022.geojson, Rows: 2808\n",
      "Processing file: needleleaf_larch_european larchmar-oct-2022.geojson, Rows: 1139\n",
      "Processing file: broadleaf_long-lived deciduous_sycamore maplemar-oct-2022.geojson, Rows: 2096\n",
      "Processing file: broadleaf_long-lived deciduous_european ashmar-oct-2022.geojson, Rows: 2202\n",
      "Processing file: broadleaf_short-lived deciduous_birchmar-oct-2022.geojson, Rows: 2468\n",
      "Processing file: broadleaf_long-lived deciduous_lindenmar-oct-2022.geojson, Rows: 161\n",
      "Processing file: broadleaf_oak_red oakmar-oct-2022.geojson, Rows: 1460\n",
      "Processing file: needleleaf_spruce_norway sprucemar-oct-2022.geojson, Rows: 5037\n",
      "Processing file: broadleaf_oak_sessile oakmar-oct-2022.geojson, Rows: 2115\n",
      "Processing file: needleleaf_pine_weymouth pinemar-oct-2022.geojson, Rows: 478\n",
      "Processing file: needleleaf_fir_silver firmar-oct-2022.geojson, Rows: 811\n",
      "Processing file: broadleaf_long-lived deciduous_cherrymar-oct-2022.geojson, Rows: 247\n",
      "Processing file: needleleaf_pine_black pinemar-oct-2022.geojson, Rows: 412\n",
      "\n",
      "Total samples attempted: 37907\n",
      "Valid samples processed: 37907\n",
      "\n",
      "Bands with None or missing values:\n",
      "  B2_4: 25577 times\n",
      "  B3_4: 25577 times\n",
      "  B4_4: 25577 times\n",
      "  B5_4: 25577 times\n",
      "  B6_4: 25577 times\n",
      "  B7_4: 25577 times\n",
      "  B8_4: 25577 times\n",
      "  B8A_4: 25577 times\n",
      "  B11_4: 25577 times\n",
      "  B12_4: 25577 times\n",
      "  NDVI_4: 25577 times\n",
      "  EVI_4: 25577 times\n",
      "  SAVI_4: 25577 times\n",
      "  NDWI_4: 25577 times\n",
      "  B1_4: 25569 times\n",
      "  B9_4: 25569 times\n",
      "  DEM_4: 23721 times\n",
      "  B2_7: 21786 times\n",
      "  B3_7: 21786 times\n",
      "  B4_7: 21786 times\n",
      "  B5_7: 21786 times\n",
      "  B6_7: 21786 times\n",
      "  B7_7: 21786 times\n",
      "  B8_7: 21786 times\n",
      "  B8A_7: 21786 times\n",
      "  B11_7: 21786 times\n",
      "  B12_7: 21786 times\n",
      "  NDVI_7: 21786 times\n",
      "  EVI_7: 21786 times\n",
      "  SAVI_7: 21786 times\n",
      "  NDWI_7: 21786 times\n",
      "  B1_7: 21781 times\n",
      "  B9_7: 21781 times\n",
      "  DEM_7: 20915 times\n",
      "  B2_1: 5484 times\n",
      "  B3_1: 5484 times\n",
      "  B4_1: 5484 times\n",
      "  B5_1: 5484 times\n",
      "  B6_1: 5484 times\n",
      "  B7_1: 5484 times\n",
      "  B8_1: 5484 times\n",
      "  B8A_1: 5484 times\n",
      "  B11_1: 5484 times\n",
      "  B12_1: 5484 times\n",
      "  NDVI_1: 5484 times\n",
      "  EVI_1: 5484 times\n",
      "  SAVI_1: 5484 times\n",
      "  NDWI_1: 5484 times\n",
      "  B1_1: 5465 times\n",
      "  B9_1: 5464 times\n",
      "  B2_6: 5256 times\n",
      "  B3_6: 5256 times\n",
      "  B4_6: 5256 times\n",
      "  B5_6: 5256 times\n",
      "  B6_6: 5256 times\n",
      "  B7_6: 5256 times\n",
      "  B8_6: 5256 times\n",
      "  B8A_6: 5256 times\n",
      "  B11_6: 5256 times\n",
      "  B12_6: 5256 times\n",
      "  NDVI_6: 5256 times\n",
      "  EVI_6: 5256 times\n",
      "  SAVI_6: 5256 times\n",
      "  NDWI_6: 5256 times\n",
      "  B1_6: 5255 times\n",
      "  B9_6: 5255 times\n",
      "  DEM_1: 3956 times\n",
      "  DEM_6: 1460 times\n",
      "  B1_2: 389 times\n",
      "  B2_2: 389 times\n",
      "  B3_2: 389 times\n",
      "  B4_2: 389 times\n",
      "  B5_2: 389 times\n",
      "  B6_2: 389 times\n",
      "  B7_2: 389 times\n",
      "  B8_2: 389 times\n",
      "  B8A_2: 389 times\n",
      "  B9_2: 389 times\n",
      "  B11_2: 389 times\n",
      "  B12_2: 389 times\n",
      "  NDVI_2: 389 times\n",
      "  EVI_2: 389 times\n",
      "  SAVI_2: 389 times\n",
      "  NDWI_2: 389 times\n",
      "  B2_3: 6 times\n",
      "  B3_3: 6 times\n",
      "  B4_3: 6 times\n",
      "  B5_3: 6 times\n",
      "  B6_3: 6 times\n",
      "  B7_3: 6 times\n",
      "  B8_3: 6 times\n",
      "  B8A_3: 6 times\n",
      "  B11_3: 6 times\n",
      "  B12_3: 6 times\n",
      "  NDVI_3: 6 times\n",
      "  EVI_3: 6 times\n",
      "  SAVI_3: 6 times\n",
      "  NDWI_3: 6 times\n",
      "  B1_3: 5 times\n",
      "  B9_3: 5 times\n",
      "\n",
      "Valid samples per species:\n",
      "  scots pine: 5389\n",
      "  norway spruce: 5037\n",
      "  european beech: 4756\n",
      "  english oak: 2808\n",
      "  birch: 2468\n",
      "  european ash: 2202\n",
      "  douglas fir: 2185\n",
      "  alder: 2143\n",
      "  sessile oak: 2115\n",
      "  sycamore maple: 2096\n",
      "  japanese larch: 1613\n",
      "  red oak: 1460\n",
      "  european larch: 1139\n",
      "  silver fir: 811\n",
      "  weymouth pine: 478\n",
      "  black pine: 412\n",
      "  poplar: 387\n",
      "  cherry: 247\n",
      "  linden: 161\n"
     ]
    }
   ],
   "source": [
    "# ********************************************************************************\n",
    "# IMPORTANT: BEFORE RUNNING THIS CELL, PERFORM A \"FACTORY RESET RUNTIME\" (Colab)\n",
    "# OR THE EQUIVALENT DEEPEST RESTART IN YOUR ENVIRONMENT (e.g., Kaggle Session Restart).\n",
    "# THEN, RUN THIS CELL AS THE VERY FIRST CODE IN YOUR NOTEBOOK.\n",
    "# ********************************************************************************\n",
    "!pip install -U scikit-learn==1.3.2 imbalanced-learn==0.12.3 xgboost==2.0.3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "import ast\n",
    "import geopandas as gpd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import json\n",
    "import xgboost as xgb\n",
    "import gc\n",
    "\n",
    "# Now, the imports should work if the environment is truly clean\n",
    "try:\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    print(\"\\nSuccessfully imported SMOTE.\")\n",
    "except ImportError as e:\n",
    "    print(f\"\\nCRITICAL ERROR: Failed to import SMOTE even after aggressive reinstallation: {e}\")\n",
    "    print(\"This indicates a severe, persistent environment issue.\")\n",
    "    print(\"Please double-check that you performed a 'Factory reset runtime' (Colab) or equivalent.\")\n",
    "    exit()\n",
    "\n",
    "# 1. Inspect and Load GeoJSON Files (Modified for Zero Imputation)\n",
    "data_dir = \"/kaggle/input/mar-oct\"  # Replace with your folder path\n",
    "all_features = []\n",
    "all_labels = []\n",
    "invalid_samples = []\n",
    "invalid_bands = Counter()\n",
    "species_counts = Counter()\n",
    "\n",
    "# Updated bands list to include all relevant bands\n",
    "bands = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12', 'NDVI', 'EVI', 'SAVI', 'NDWI', 'DEM']\n",
    "months = ['', '_1', '_2', '_3', '_4', '_5', '_6', '_7']\n",
    "band_columns = [band + month for month in months for band in bands]\n",
    "\n",
    "# Inspect first file\n",
    "first_file = os.path.join(data_dir, os.listdir(data_dir)[0]) if os.listdir(data_dir) else None\n",
    "if first_file and first_file.endswith(\".geojson\"):\n",
    "    gdf = gpd.read_file(first_file)\n",
    "    print(\"Inspecting first 2 rows of first GeoJSON file:\")\n",
    "    for idx in range(min(2, len(gdf))):\n",
    "        print(f\"\\nRow {idx}:\")\n",
    "        for band in ['B1', 'B2', 'B11', 'NDVI', 'DEM', 'B2_1', 'NDVI_7']:\n",
    "            if band in gdf.columns:\n",
    "                data = gdf[band].iloc[idx]\n",
    "                try:\n",
    "                    parsed_data = ast.literal_eval(data) if isinstance(data, str) else data\n",
    "                    array = np.array(parsed_data, dtype=np.float32)\n",
    "                    print(f\"  Band {band}: shape={array.shape}, first few values={array.flatten()[:5]}\")\n",
    "                except (ValueError, SyntaxError, TypeError) as e:\n",
    "                    print(f\"  Band {band}: Error parsing/converting: {e}\")\n",
    "            else:\n",
    "                print(f\"  Band {band}: Not found in GeoJSON file\")\n",
    "\n",
    "# Load all GeoJSON files\n",
    "total_samples_attempted = 0\n",
    "for file in os.listdir(data_dir):\n",
    "    if file.endswith(\".geojson\"):\n",
    "        try:\n",
    "            gdf = gpd.read_file(os.path.join(data_dir, file))\n",
    "            print(f\"Processing file: {file}, Rows: {len(gdf)}\")\n",
    "            total_samples_attempted += len(gdf)\n",
    "            for idx, row in gdf.iterrows():\n",
    "                try:\n",
    "                    patch = []\n",
    "                    for col in band_columns:\n",
    "                        if col not in gdf.columns:\n",
    "                            invalid_bands[col] += 1\n",
    "                            array = np.zeros((5, 5), dtype=np.float32)  # Impute with zeros\n",
    "                            patch.append(array)\n",
    "                            continue\n",
    "                        data = row[col]\n",
    "                        if data is None or (isinstance(data, str) and data.lower() == 'none'):\n",
    "                            invalid_bands[col] += 1\n",
    "                            array = np.zeros((5, 5), dtype=np.float32)  # Impute with zeros\n",
    "                            patch.append(array)\n",
    "                            continue\n",
    "                        try:\n",
    "                            parsed_data = ast.literal_eval(data) if isinstance(data, str) else data\n",
    "                            array = np.array(parsed_data, dtype=np.float32).reshape(5, 5)\n",
    "                        except (ValueError, SyntaxError, TypeError) as e:\n",
    "                            invalid_bands[col] += 1\n",
    "                            array = np.zeros((5, 5), dtype=np.float32)  # Impute for parsing errors\n",
    "                            patch.append(array)\n",
    "                            continue\n",
    "                        patch.append(array)\n",
    "                    patch = np.stack(patch, axis=-1)\n",
    "                    if patch.shape != (5, 5, 136):  # Expected shape: 17 bands * 8 months\n",
    "                        raise ValueError(f\"Unexpected patch shape: {patch.shape}\")\n",
    "                    all_features.append(patch)\n",
    "                    all_labels.append(row['l3_species'])\n",
    "                    species_counts[row['l3_species']] += 1\n",
    "                except (ValueError, SyntaxError, TypeError) as e:\n",
    "                    invalid_samples.append((file, idx, str(e)))\n",
    "                    continue\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process file {file}: {e}\")\n",
    "            continue\n",
    "\n",
    "# Log invalid samples and bands\n",
    "print(f\"\\nTotal samples attempted: {total_samples_attempted}\")\n",
    "print(f\"Valid samples processed: {len(all_features)}\")\n",
    "if invalid_samples:\n",
    "    print(f\"\\nSkipped {len(invalid_samples)} invalid samples:\")\n",
    "    for file, idx, error in invalid_samples:\n",
    "        print(f\"File: {file}, Row: {idx}, Error: {error}\")\n",
    "if invalid_bands:\n",
    "    print(\"\\nBands with None or missing values:\")\n",
    "    for band, count in invalid_bands.most_common():\n",
    "        print(f\"  {band}: {count} times\")\n",
    "print(\"\\nValid samples per species:\")\n",
    "for species, count in species_counts.most_common():\n",
    "    print(f\"  {species}: {count}\")\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "if not all_features:\n",
    "    print(\"\\nError: No valid samples loaded. Using Random Forest with dummy data.\")\n",
    "    X_dummy = np.random.rand(100, 5*5*136)  # Updated for 136 channels\n",
    "    y_dummy = np.random.randint(0, 5, 100)\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_dummy, y_dummy)\n",
    "    print(\"Random Forest dummy accuracy:\", rf.score(X_dummy, y_dummy))\n",
    "    print(\"Please re-export data with updated GEE code.\")\n",
    "    exit()\n",
    "\n",
    "X = np.array(all_features, dtype=np.float32)  # Shape: (N, 5, 5, 136)\n",
    "y = np.array(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "245d7e1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T14:43:22.868833Z",
     "iopub.status.busy": "2025-07-17T14:43:22.868595Z",
     "iopub.status.idle": "2025-07-17T14:47:12.463050Z",
     "shell.execute_reply": "2025-07-17T14:47:12.462155Z"
    },
    "papermill": {
     "duration": 229.600154,
     "end_time": "2025-07-17T14:47:12.464583",
     "exception": false,
     "start_time": "2025-07-17T14:43:22.864429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set after SMOTE: (71668, 3400), Classes: 19\n",
      "Data range after scaling: min=-220.6690, max=229.0108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:2.62985\n",
      "[1]\tvalidation_0-mlogloss:2.44005\n",
      "[2]\tvalidation_0-mlogloss:2.29696\n",
      "[3]\tvalidation_0-mlogloss:2.18091\n",
      "[4]\tvalidation_0-mlogloss:2.08492\n",
      "[5]\tvalidation_0-mlogloss:2.00165\n",
      "[6]\tvalidation_0-mlogloss:1.92759\n",
      "[7]\tvalidation_0-mlogloss:1.86227\n",
      "[8]\tvalidation_0-mlogloss:1.80609\n",
      "[9]\tvalidation_0-mlogloss:1.75312\n",
      "[10]\tvalidation_0-mlogloss:1.70640\n",
      "[11]\tvalidation_0-mlogloss:1.66339\n",
      "[12]\tvalidation_0-mlogloss:1.62333\n",
      "[13]\tvalidation_0-mlogloss:1.58793\n",
      "[14]\tvalidation_0-mlogloss:1.55441\n",
      "[15]\tvalidation_0-mlogloss:1.52292\n",
      "[16]\tvalidation_0-mlogloss:1.49406\n",
      "[17]\tvalidation_0-mlogloss:1.46715\n",
      "[18]\tvalidation_0-mlogloss:1.44264\n",
      "[19]\tvalidation_0-mlogloss:1.41944\n",
      "[20]\tvalidation_0-mlogloss:1.39646\n",
      "[21]\tvalidation_0-mlogloss:1.37581\n",
      "[22]\tvalidation_0-mlogloss:1.35615\n",
      "[23]\tvalidation_0-mlogloss:1.33703\n",
      "[24]\tvalidation_0-mlogloss:1.31882\n",
      "[25]\tvalidation_0-mlogloss:1.30268\n",
      "[26]\tvalidation_0-mlogloss:1.28725\n",
      "[27]\tvalidation_0-mlogloss:1.27212\n",
      "[28]\tvalidation_0-mlogloss:1.25884\n",
      "[29]\tvalidation_0-mlogloss:1.24516\n",
      "[30]\tvalidation_0-mlogloss:1.23270\n",
      "[31]\tvalidation_0-mlogloss:1.22125\n",
      "[32]\tvalidation_0-mlogloss:1.20975\n",
      "[33]\tvalidation_0-mlogloss:1.19924\n",
      "[34]\tvalidation_0-mlogloss:1.18797\n",
      "[35]\tvalidation_0-mlogloss:1.17816\n",
      "[36]\tvalidation_0-mlogloss:1.16884\n",
      "[37]\tvalidation_0-mlogloss:1.15990\n",
      "[38]\tvalidation_0-mlogloss:1.15115\n",
      "[39]\tvalidation_0-mlogloss:1.14278\n",
      "[40]\tvalidation_0-mlogloss:1.13474\n",
      "[41]\tvalidation_0-mlogloss:1.12749\n",
      "[42]\tvalidation_0-mlogloss:1.12052\n",
      "[43]\tvalidation_0-mlogloss:1.11457\n",
      "[44]\tvalidation_0-mlogloss:1.10726\n",
      "[45]\tvalidation_0-mlogloss:1.10057\n",
      "[46]\tvalidation_0-mlogloss:1.09429\n",
      "[47]\tvalidation_0-mlogloss:1.08860\n",
      "[48]\tvalidation_0-mlogloss:1.08281\n",
      "[49]\tvalidation_0-mlogloss:1.07773\n",
      "[50]\tvalidation_0-mlogloss:1.07251\n",
      "[51]\tvalidation_0-mlogloss:1.06731\n",
      "[52]\tvalidation_0-mlogloss:1.06265\n",
      "[53]\tvalidation_0-mlogloss:1.05780\n",
      "[54]\tvalidation_0-mlogloss:1.05270\n",
      "[55]\tvalidation_0-mlogloss:1.04806\n",
      "[56]\tvalidation_0-mlogloss:1.04355\n",
      "[57]\tvalidation_0-mlogloss:1.03887\n",
      "[58]\tvalidation_0-mlogloss:1.03472\n",
      "[59]\tvalidation_0-mlogloss:1.03118\n",
      "[60]\tvalidation_0-mlogloss:1.02766\n",
      "[61]\tvalidation_0-mlogloss:1.02396\n",
      "[62]\tvalidation_0-mlogloss:1.02049\n",
      "[63]\tvalidation_0-mlogloss:1.01691\n",
      "[64]\tvalidation_0-mlogloss:1.01359\n",
      "[65]\tvalidation_0-mlogloss:1.01024\n",
      "[66]\tvalidation_0-mlogloss:1.00653\n",
      "[67]\tvalidation_0-mlogloss:1.00335\n",
      "[68]\tvalidation_0-mlogloss:1.00014\n",
      "[69]\tvalidation_0-mlogloss:0.99742\n",
      "[70]\tvalidation_0-mlogloss:0.99458\n",
      "[71]\tvalidation_0-mlogloss:0.99195\n",
      "[72]\tvalidation_0-mlogloss:0.98950\n",
      "[73]\tvalidation_0-mlogloss:0.98653\n",
      "[74]\tvalidation_0-mlogloss:0.98442\n",
      "[75]\tvalidation_0-mlogloss:0.98163\n",
      "[76]\tvalidation_0-mlogloss:0.97931\n",
      "[77]\tvalidation_0-mlogloss:0.97660\n",
      "[78]\tvalidation_0-mlogloss:0.97413\n",
      "[79]\tvalidation_0-mlogloss:0.97169\n",
      "[80]\tvalidation_0-mlogloss:0.96943\n",
      "[81]\tvalidation_0-mlogloss:0.96749\n",
      "[82]\tvalidation_0-mlogloss:0.96529\n",
      "[83]\tvalidation_0-mlogloss:0.96318\n",
      "[84]\tvalidation_0-mlogloss:0.96078\n",
      "[85]\tvalidation_0-mlogloss:0.95890\n",
      "[86]\tvalidation_0-mlogloss:0.95680\n",
      "[87]\tvalidation_0-mlogloss:0.95499\n",
      "[88]\tvalidation_0-mlogloss:0.95324\n",
      "[89]\tvalidation_0-mlogloss:0.95144\n",
      "[90]\tvalidation_0-mlogloss:0.95011\n",
      "[91]\tvalidation_0-mlogloss:0.94844\n",
      "[92]\tvalidation_0-mlogloss:0.94640\n",
      "[93]\tvalidation_0-mlogloss:0.94437\n",
      "[94]\tvalidation_0-mlogloss:0.94300\n",
      "[95]\tvalidation_0-mlogloss:0.94107\n",
      "[96]\tvalidation_0-mlogloss:0.93964\n",
      "[97]\tvalidation_0-mlogloss:0.93764\n",
      "[98]\tvalidation_0-mlogloss:0.93602\n",
      "[99]\tvalidation_0-mlogloss:0.93477\n",
      "[100]\tvalidation_0-mlogloss:0.93324\n",
      "[101]\tvalidation_0-mlogloss:0.93212\n",
      "[102]\tvalidation_0-mlogloss:0.93092\n",
      "[103]\tvalidation_0-mlogloss:0.92978\n",
      "[104]\tvalidation_0-mlogloss:0.92893\n",
      "[105]\tvalidation_0-mlogloss:0.92776\n",
      "[106]\tvalidation_0-mlogloss:0.92687\n",
      "[107]\tvalidation_0-mlogloss:0.92581\n",
      "[108]\tvalidation_0-mlogloss:0.92510\n",
      "[109]\tvalidation_0-mlogloss:0.92406\n",
      "[110]\tvalidation_0-mlogloss:0.92283\n",
      "[111]\tvalidation_0-mlogloss:0.92172\n",
      "[112]\tvalidation_0-mlogloss:0.92021\n",
      "[113]\tvalidation_0-mlogloss:0.91922\n",
      "[114]\tvalidation_0-mlogloss:0.91851\n",
      "[115]\tvalidation_0-mlogloss:0.91781\n",
      "[116]\tvalidation_0-mlogloss:0.91664\n",
      "[117]\tvalidation_0-mlogloss:0.91598\n",
      "[118]\tvalidation_0-mlogloss:0.91486\n",
      "[119]\tvalidation_0-mlogloss:0.91420\n",
      "[120]\tvalidation_0-mlogloss:0.91314\n",
      "[121]\tvalidation_0-mlogloss:0.91221\n",
      "[122]\tvalidation_0-mlogloss:0.91126\n",
      "[123]\tvalidation_0-mlogloss:0.91082\n",
      "[124]\tvalidation_0-mlogloss:0.90986\n",
      "[125]\tvalidation_0-mlogloss:0.90910\n",
      "[126]\tvalidation_0-mlogloss:0.90847\n",
      "[127]\tvalidation_0-mlogloss:0.90753\n",
      "[128]\tvalidation_0-mlogloss:0.90648\n",
      "[129]\tvalidation_0-mlogloss:0.90577\n",
      "[130]\tvalidation_0-mlogloss:0.90538\n",
      "[131]\tvalidation_0-mlogloss:0.90472\n",
      "[132]\tvalidation_0-mlogloss:0.90371\n",
      "[133]\tvalidation_0-mlogloss:0.90304\n",
      "[134]\tvalidation_0-mlogloss:0.90259\n",
      "[135]\tvalidation_0-mlogloss:0.90212\n",
      "[136]\tvalidation_0-mlogloss:0.90194\n",
      "[137]\tvalidation_0-mlogloss:0.90162\n",
      "[138]\tvalidation_0-mlogloss:0.90085\n",
      "[139]\tvalidation_0-mlogloss:0.90002\n",
      "[140]\tvalidation_0-mlogloss:0.89941\n",
      "[141]\tvalidation_0-mlogloss:0.89898\n",
      "[142]\tvalidation_0-mlogloss:0.89838\n",
      "[143]\tvalidation_0-mlogloss:0.89796\n",
      "[144]\tvalidation_0-mlogloss:0.89759\n",
      "[145]\tvalidation_0-mlogloss:0.89676\n",
      "[146]\tvalidation_0-mlogloss:0.89609\n",
      "[147]\tvalidation_0-mlogloss:0.89547\n",
      "[148]\tvalidation_0-mlogloss:0.89489\n",
      "[149]\tvalidation_0-mlogloss:0.89429\n",
      "[150]\tvalidation_0-mlogloss:0.89354\n",
      "[151]\tvalidation_0-mlogloss:0.89303\n",
      "[152]\tvalidation_0-mlogloss:0.89251\n",
      "[153]\tvalidation_0-mlogloss:0.89188\n",
      "[154]\tvalidation_0-mlogloss:0.89179\n",
      "[155]\tvalidation_0-mlogloss:0.89128\n",
      "[156]\tvalidation_0-mlogloss:0.89081\n",
      "[157]\tvalidation_0-mlogloss:0.89031\n",
      "[158]\tvalidation_0-mlogloss:0.88966\n",
      "[159]\tvalidation_0-mlogloss:0.88914\n",
      "[160]\tvalidation_0-mlogloss:0.88879\n",
      "[161]\tvalidation_0-mlogloss:0.88810\n",
      "[162]\tvalidation_0-mlogloss:0.88765\n",
      "[163]\tvalidation_0-mlogloss:0.88692\n",
      "[164]\tvalidation_0-mlogloss:0.88656\n",
      "[165]\tvalidation_0-mlogloss:0.88625\n",
      "[166]\tvalidation_0-mlogloss:0.88561\n",
      "[167]\tvalidation_0-mlogloss:0.88539\n",
      "[168]\tvalidation_0-mlogloss:0.88498\n",
      "[169]\tvalidation_0-mlogloss:0.88438\n",
      "[170]\tvalidation_0-mlogloss:0.88409\n",
      "[171]\tvalidation_0-mlogloss:0.88362\n",
      "[172]\tvalidation_0-mlogloss:0.88347\n",
      "[173]\tvalidation_0-mlogloss:0.88302\n",
      "[174]\tvalidation_0-mlogloss:0.88261\n",
      "[175]\tvalidation_0-mlogloss:0.88246\n",
      "[176]\tvalidation_0-mlogloss:0.88229\n",
      "[177]\tvalidation_0-mlogloss:0.88215\n",
      "[178]\tvalidation_0-mlogloss:0.88166\n",
      "[179]\tvalidation_0-mlogloss:0.88150\n",
      "[180]\tvalidation_0-mlogloss:0.88102\n",
      "[181]\tvalidation_0-mlogloss:0.88095\n",
      "[182]\tvalidation_0-mlogloss:0.88027\n",
      "[183]\tvalidation_0-mlogloss:0.87986\n",
      "[184]\tvalidation_0-mlogloss:0.87993\n",
      "[185]\tvalidation_0-mlogloss:0.87960\n",
      "[186]\tvalidation_0-mlogloss:0.87939\n",
      "[187]\tvalidation_0-mlogloss:0.87950\n",
      "[188]\tvalidation_0-mlogloss:0.87928\n",
      "[189]\tvalidation_0-mlogloss:0.87897\n",
      "[190]\tvalidation_0-mlogloss:0.87880\n",
      "[191]\tvalidation_0-mlogloss:0.87861\n",
      "[192]\tvalidation_0-mlogloss:0.87876\n",
      "[193]\tvalidation_0-mlogloss:0.87844\n",
      "[194]\tvalidation_0-mlogloss:0.87832\n",
      "[195]\tvalidation_0-mlogloss:0.87783\n",
      "[196]\tvalidation_0-mlogloss:0.87771\n",
      "[197]\tvalidation_0-mlogloss:0.87742\n",
      "[198]\tvalidation_0-mlogloss:0.87752\n",
      "[199]\tvalidation_0-mlogloss:0.87744\n",
      "[200]\tvalidation_0-mlogloss:0.87733\n",
      "[201]\tvalidation_0-mlogloss:0.87740\n",
      "[202]\tvalidation_0-mlogloss:0.87748\n",
      "[203]\tvalidation_0-mlogloss:0.87742\n",
      "[204]\tvalidation_0-mlogloss:0.87722\n",
      "[205]\tvalidation_0-mlogloss:0.87733\n",
      "[206]\tvalidation_0-mlogloss:0.87756\n",
      "[207]\tvalidation_0-mlogloss:0.87741\n",
      "[208]\tvalidation_0-mlogloss:0.87678\n",
      "[209]\tvalidation_0-mlogloss:0.87669\n",
      "[210]\tvalidation_0-mlogloss:0.87642\n",
      "[211]\tvalidation_0-mlogloss:0.87612\n",
      "[212]\tvalidation_0-mlogloss:0.87587\n",
      "[213]\tvalidation_0-mlogloss:0.87573\n",
      "[214]\tvalidation_0-mlogloss:0.87560\n",
      "[215]\tvalidation_0-mlogloss:0.87563\n",
      "[216]\tvalidation_0-mlogloss:0.87575\n",
      "[217]\tvalidation_0-mlogloss:0.87576\n",
      "[218]\tvalidation_0-mlogloss:0.87607\n",
      "[219]\tvalidation_0-mlogloss:0.87585\n",
      "[220]\tvalidation_0-mlogloss:0.87573\n",
      "[221]\tvalidation_0-mlogloss:0.87565\n",
      "[222]\tvalidation_0-mlogloss:0.87581\n",
      "[223]\tvalidation_0-mlogloss:0.87582\n",
      "[224]\tvalidation_0-mlogloss:0.87584\n",
      "[225]\tvalidation_0-mlogloss:0.87599\n",
      "[226]\tvalidation_0-mlogloss:0.87605\n",
      "[227]\tvalidation_0-mlogloss:0.87599\n",
      "[228]\tvalidation_0-mlogloss:0.87573\n",
      "[229]\tvalidation_0-mlogloss:0.87584\n",
      "[230]\tvalidation_0-mlogloss:0.87584\n",
      "[231]\tvalidation_0-mlogloss:0.87580\n",
      "[232]\tvalidation_0-mlogloss:0.87576\n",
      "[233]\tvalidation_0-mlogloss:0.87584\n",
      "[234]\tvalidation_0-mlogloss:0.87605\n",
      "[235]\tvalidation_0-mlogloss:0.87622\n",
      "[236]\tvalidation_0-mlogloss:0.87608\n",
      "[237]\tvalidation_0-mlogloss:0.87623\n",
      "[238]\tvalidation_0-mlogloss:0.87581\n",
      "[239]\tvalidation_0-mlogloss:0.87592\n",
      "[240]\tvalidation_0-mlogloss:0.87576\n",
      "[241]\tvalidation_0-mlogloss:0.87594\n",
      "[242]\tvalidation_0-mlogloss:0.87585\n",
      "[243]\tvalidation_0-mlogloss:0.87611\n",
      "[244]\tvalidation_0-mlogloss:0.87622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [14:47:10] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.7169\n",
      "\n",
      "Classification Report:\n",
      "{\n",
      "    \"alder\": {\n",
      "        \"precision\": 0.6146788990825688,\n",
      "        \"recall\": 0.6242236024844721,\n",
      "        \"f1-score\": 0.6194144838212635,\n",
      "        \"support\": 322.0\n",
      "    },\n",
      "    \"birch\": {\n",
      "        \"precision\": 0.5254691689008043,\n",
      "        \"recall\": 0.5297297297297298,\n",
      "        \"f1-score\": 0.5275908479138627,\n",
      "        \"support\": 370.0\n",
      "    },\n",
      "    \"black pine\": {\n",
      "        \"precision\": 0.6923076923076923,\n",
      "        \"recall\": 0.5806451612903226,\n",
      "        \"f1-score\": 0.631578947368421,\n",
      "        \"support\": 62.0\n",
      "    },\n",
      "    \"cherry\": {\n",
      "        \"precision\": 0.75,\n",
      "        \"recall\": 0.4864864864864865,\n",
      "        \"f1-score\": 0.5901639344262296,\n",
      "        \"support\": 37.0\n",
      "    },\n",
      "    \"douglas fir\": {\n",
      "        \"precision\": 0.8412698412698413,\n",
      "        \"recall\": 0.8079268292682927,\n",
      "        \"f1-score\": 0.8242612752721619,\n",
      "        \"support\": 328.0\n",
      "    },\n",
      "    \"english oak\": {\n",
      "        \"precision\": 0.6707616707616708,\n",
      "        \"recall\": 0.6484560570071259,\n",
      "        \"f1-score\": 0.6594202898550725,\n",
      "        \"support\": 421.0\n",
      "    },\n",
      "    \"european ash\": {\n",
      "        \"precision\": 0.6038338658146964,\n",
      "        \"recall\": 0.5727272727272728,\n",
      "        \"f1-score\": 0.5878693623639191,\n",
      "        \"support\": 330.0\n",
      "    },\n",
      "    \"european beech\": {\n",
      "        \"precision\": 0.7520215633423181,\n",
      "        \"recall\": 0.7815126050420168,\n",
      "        \"f1-score\": 0.7664835164835164,\n",
      "        \"support\": 714.0\n",
      "    },\n",
      "    \"european larch\": {\n",
      "        \"precision\": 0.6196319018404908,\n",
      "        \"recall\": 0.5906432748538012,\n",
      "        \"f1-score\": 0.6047904191616766,\n",
      "        \"support\": 171.0\n",
      "    },\n",
      "    \"japanese larch\": {\n",
      "        \"precision\": 0.8962264150943396,\n",
      "        \"recall\": 0.7851239669421488,\n",
      "        \"f1-score\": 0.8370044052863437,\n",
      "        \"support\": 242.0\n",
      "    },\n",
      "    \"linden\": {\n",
      "        \"precision\": 0.9230769230769231,\n",
      "        \"recall\": 0.5,\n",
      "        \"f1-score\": 0.6486486486486487,\n",
      "        \"support\": 24.0\n",
      "    },\n",
      "    \"norway spruce\": {\n",
      "        \"precision\": 0.7433414043583535,\n",
      "        \"recall\": 0.8121693121693122,\n",
      "        \"f1-score\": 0.7762326169405815,\n",
      "        \"support\": 756.0\n",
      "    },\n",
      "    \"poplar\": {\n",
      "        \"precision\": 0.7714285714285715,\n",
      "        \"recall\": 0.46551724137931033,\n",
      "        \"f1-score\": 0.5806451612903226,\n",
      "        \"support\": 58.0\n",
      "    },\n",
      "    \"red oak\": {\n",
      "        \"precision\": 0.7692307692307693,\n",
      "        \"recall\": 0.730593607305936,\n",
      "        \"f1-score\": 0.7494145199063232,\n",
      "        \"support\": 219.0\n",
      "    },\n",
      "    \"scots pine\": {\n",
      "        \"precision\": 0.8533653846153846,\n",
      "        \"recall\": 0.8787128712871287,\n",
      "        \"f1-score\": 0.8658536585365854,\n",
      "        \"support\": 808.0\n",
      "    },\n",
      "    \"sessile oak\": {\n",
      "        \"precision\": 0.66996699669967,\n",
      "        \"recall\": 0.6403785488958991,\n",
      "        \"f1-score\": 0.6548387096774193,\n",
      "        \"support\": 317.0\n",
      "    },\n",
      "    \"silver fir\": {\n",
      "        \"precision\": 0.7355371900826446,\n",
      "        \"recall\": 0.7295081967213115,\n",
      "        \"f1-score\": 0.7325102880658436,\n",
      "        \"support\": 122.0\n",
      "    },\n",
      "    \"sycamore maple\": {\n",
      "        \"precision\": 0.49572649572649574,\n",
      "        \"recall\": 0.554140127388535,\n",
      "        \"f1-score\": 0.5233082706766917,\n",
      "        \"support\": 314.0\n",
      "    },\n",
      "    \"weymouth pine\": {\n",
      "        \"precision\": 0.8714285714285714,\n",
      "        \"recall\": 0.8472222222222222,\n",
      "        \"f1-score\": 0.8591549295774648,\n",
      "        \"support\": 72.0\n",
      "    },\n",
      "    \"accuracy\": 0.7168981888517671,\n",
      "    \"macro avg\": {\n",
      "        \"precision\": 0.726279122371674,\n",
      "        \"recall\": 0.661353532273754,\n",
      "        \"f1-score\": 0.6862728571195972,\n",
      "        \"support\": 5687.0\n",
      "    },\n",
      "    \"weighted avg\": {\n",
      "        \"precision\": 0.7187906615136618,\n",
      "        \"recall\": 0.7168981888517671,\n",
      "        \"f1-score\": 0.7163362907636847,\n",
      "        \"support\": 5687.0\n",
      "    }\n",
      "}\n",
      "Recall: 0.7169\n",
      "F1-Score: 0.7163\n",
      "Saved: model6.pkl, report6.json, confusion6.npy, confusion6.png, labelencoder6.pkl, scaler6.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Encode Labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# 3. Train-Test-Validation Split (Before SMOTE!)\n",
    "X_flat = X.reshape(X.shape[0], -1)  # Flatten for ML\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_flat, y_encoded, test_size=0.15, random_state=42, stratify=y_encoded)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.1765, random_state=42, stratify=y_train)\n",
    "\n",
    "# 4. Apply SMOTE **only to training set**\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 5. Scale features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\nTraining set after SMOTE: {X_train_scaled.shape}, Classes: {len(np.unique(y_train_resampled))}\")\n",
    "print(f\"Data range after scaling: min={X_train_scaled.min():.4f}, max={X_train_scaled.max():.4f}\")\n",
    "\n",
    "# 6. Compute Class Weights for resampled training data\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train_resampled), y=y_train_resampled)\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "# Create sample weights array for training samples\n",
    "sample_weights = np.array([class_weight_dict[label] for label in y_train_resampled])\n",
    "\n",
    "# Clear memory\n",
    "gc.collect()\n",
    "\n",
    "# 7. Define and Train XGBoost Model\n",
    "model5 = xgb.XGBClassifier(\n",
    "    objective='multi:softmax',\n",
    "    num_class=len(np.unique(y_encoded)),\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=500,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    device='cuda',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model5.fit(\n",
    "    X_train_scaled, y_train_resampled,\n",
    "    sample_weight=sample_weights,\n",
    "    eval_set=[(X_val_scaled, y_val)],\n",
    "    eval_metric='mlogloss',\n",
    "    early_stopping_rounds=30,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Clear memory\n",
    "gc.collect()\n",
    "\n",
    "# 8. Evaluate Model\n",
    "y_pred = model5.predict(X_test_scaled)\n",
    "test_accuracy = (y_pred == y_test).mean()\n",
    "print(f\"\\nTest Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# 9. Additional Metrics\n",
    "report5 = classification_report(y_test, y_pred, target_names=label_encoder.classes_, output_dict=True)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(json.dumps(report5, indent=4))\n",
    "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "\n",
    "# 10. Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 8), dpi=100)\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_, cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('confusion6.png', dpi=100)\n",
    "plt.close()\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "# 11. Save Outputs\n",
    "joblib.dump(model5, 'model6.pkl')\n",
    "json.dump(report5, open('report6.json', 'w'), indent=4)\n",
    "np.save('confusion6.npy', cm)\n",
    "joblib.dump(label_encoder, 'labelencoder6.pkl')\n",
    "joblib.dump(scaler, 'scaler6.pkl')\n",
    "\n",
    "print(\"Saved: model6.pkl, report6.json, confusion6.npy, confusion6.png, labelencoder6.pkl, scaler6.pkl\")\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0918f78c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T14:47:12.494749Z",
     "iopub.status.busy": "2025-07-17T14:47:12.494482Z",
     "iopub.status.idle": "2025-07-17T14:48:23.915617Z",
     "shell.execute_reply": "2025-07-17T14:48:23.914738Z"
    },
    "papermill": {
     "duration": 71.43773,
     "end_time": "2025-07-17T14:48:23.916870",
     "exception": false,
     "start_time": "2025-07-17T14:47:12.479140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 19 GeoJSON files in /kaggle/input/final-test-data\n",
      "Processing file: needleleaf_douglas fir_douglas firmar-oct-2022.geojson, Rows: 506\n",
      "Processing file: broadleaf_short-lived deciduous_aldermar-oct-2022.geojson, Rows: 420\n",
      "Processing file: broadleaf_beech_european beechmar-oct-2022.geojson, Rows: 1703\n",
      "Processing file: needleleaf_larch_japanese larchmar-oct-2022.geojson, Rows: 135\n",
      "Processing file: broadleaf_short-lived deciduous_poplarmar-oct-2022.geojson, Rows: 77\n",
      "Processing file: needleleaf_pine_scots pinemar-oct-2022.geojson, Rows: 1202\n",
      "Processing file: broadleaf_oak_english oakmar-oct-2022.geojson, Rows: 645\n",
      "Processing file: needleleaf_larch_european larchmar-oct-2022.geojson, Rows: 221\n",
      "Processing file: broadleaf_long-lived deciduous_sycamore maplemar-oct-2022.geojson, Rows: 725\n",
      "Processing file: broadleaf_long-lived deciduous_european ashmar-oct-2022.geojson, Rows: 432\n",
      "Processing file: broadleaf_short-lived deciduous_birchmar-oct-2022.geojson, Rows: 353\n",
      "Processing file: broadleaf_long-lived deciduous_lindenmar-oct-2022.geojson, Rows: 51\n",
      "Processing file: broadleaf_oak_red oakmar-oct-2022.geojson, Rows: 381\n",
      "Processing file: needleleaf_spruce_norway sprucemar-oct-2022.geojson, Rows: 746\n",
      "Processing file: broadleaf_oak_sessile oakmar-oct-2022.geojson, Rows: 493\n",
      "Processing file: needleleaf_pine_weymouth pinemar-oct-2022.geojson, Rows: 22\n",
      "Processing file: needleleaf_fir_silver firmar-oct-2022.geojson, Rows: 173\n",
      "Processing file: broadleaf_long-lived deciduous_cherrymar-oct-2022.geojson, Rows: 57\n",
      "Processing file: needleleaf_pine_black pinemar-oct-2022.geojson, Rows: 9\n",
      "\n",
      "Total samples attempted: 8351\n",
      "Valid samples processed: 8351\n",
      "\n",
      "Bands with missing/None/parsing issues in test data:\n",
      "  B1_4: 6893 times\n",
      "  B2_4: 6893 times\n",
      "  B3_4: 6893 times\n",
      "  B4_4: 6893 times\n",
      "  B5_4: 6893 times\n",
      "  B6_4: 6893 times\n",
      "  B7_4: 6893 times\n",
      "  B8_4: 6893 times\n",
      "  B8A_4: 6893 times\n",
      "  B9_4: 6893 times\n",
      "  B11_4: 6893 times\n",
      "  B12_4: 6893 times\n",
      "  NDVI_4: 6893 times\n",
      "  EVI_4: 6893 times\n",
      "  SAVI_4: 6893 times\n",
      "  NDWI_4: 6893 times\n",
      "  DEM_4: 6759 times\n",
      "  B2_7: 4589 times\n",
      "  B3_7: 4589 times\n",
      "  B4_7: 4589 times\n",
      "  B5_7: 4589 times\n",
      "  B6_7: 4589 times\n",
      "  B7_7: 4589 times\n",
      "  B8_7: 4589 times\n",
      "  B8A_7: 4589 times\n",
      "  B11_7: 4589 times\n",
      "  B12_7: 4589 times\n",
      "  NDVI_7: 4589 times\n",
      "  EVI_7: 4589 times\n",
      "  SAVI_7: 4589 times\n",
      "  NDWI_7: 4589 times\n",
      "  B1_7: 4585 times\n",
      "  B9_7: 4585 times\n",
      "  DEM_7: 4147 times\n",
      "  B2_1: 3744 times\n",
      "  B3_1: 3744 times\n",
      "  B4_1: 3744 times\n",
      "  B5_1: 3744 times\n",
      "  B6_1: 3744 times\n",
      "  B7_1: 3744 times\n",
      "  B8_1: 3744 times\n",
      "  B8A_1: 3744 times\n",
      "  B11_1: 3744 times\n",
      "  B12_1: 3744 times\n",
      "  NDVI_1: 3744 times\n",
      "  EVI_1: 3744 times\n",
      "  SAVI_1: 3744 times\n",
      "  NDWI_1: 3744 times\n",
      "  B1_1: 3743 times\n",
      "  B9_1: 3743 times\n",
      "  DEM_1: 3423 times\n",
      "  B2_6: 645 times\n",
      "  B3_6: 645 times\n",
      "  B4_6: 645 times\n",
      "  B5_6: 645 times\n",
      "  B6_6: 645 times\n",
      "  B7_6: 645 times\n",
      "  B8_6: 645 times\n",
      "  B8A_6: 645 times\n",
      "  B11_6: 645 times\n",
      "  B12_6: 645 times\n",
      "  NDVI_6: 645 times\n",
      "  EVI_6: 645 times\n",
      "  SAVI_6: 645 times\n",
      "  NDWI_6: 645 times\n",
      "  B1_6: 644 times\n",
      "  B9_6: 644 times\n",
      "\n",
      "Training class distribution:\n",
      "english oak       3772\n",
      "scots pine        3772\n",
      "sessile oak       3772\n",
      "red oak           3772\n",
      "douglas fir       3772\n",
      "european ash      3772\n",
      "linden            3772\n",
      "norway spruce     3772\n",
      "silver fir        3772\n",
      "european larch    3772\n",
      "european beech    3772\n",
      "birch             3772\n",
      "sycamore maple    3772\n",
      "black pine        3772\n",
      "alder             3772\n",
      "japanese larch    3772\n",
      "weymouth pine     3772\n",
      "poplar            3772\n",
      "cherry            3772\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test class distribution:\n",
      "european beech    1703\n",
      "scots pine        1202\n",
      "norway spruce      746\n",
      "sycamore maple     725\n",
      "english oak        645\n",
      "douglas fir        506\n",
      "sessile oak        493\n",
      "european ash       432\n",
      "alder              420\n",
      "red oak            381\n",
      "birch              353\n",
      "european larch     221\n",
      "silver fir         173\n",
      "japanese larch     135\n",
      "poplar              77\n",
      "cherry              57\n",
      "linden              51\n",
      "weymouth pine       22\n",
      "black pine           9\n",
      "Name: count, dtype: int64\n",
      "Classes missing in test data: set()\n",
      "\n",
      "Training feature stats (after scaling):\n",
      "Mean: -0.0000, Std: 1.0000\n",
      "\n",
      "Test feature stats (after scaling):\n",
      "Mean: -0.1260, Std: 1.1043\n",
      "\n",
      "Final Test Data Accuracy: 0.6645\n",
      "\n",
      "Classification Report for Final Test Data:\n",
      "{\n",
      "    \"alder\": {\n",
      "        \"precision\": 0.6775510204081633,\n",
      "        \"recall\": 0.3952380952380952,\n",
      "        \"f1-score\": 0.49924812030075183,\n",
      "        \"support\": 420.0\n",
      "    },\n",
      "    \"birch\": {\n",
      "        \"precision\": 0.2802653399668325,\n",
      "        \"recall\": 0.47875354107648727,\n",
      "        \"f1-score\": 0.35355648535564854,\n",
      "        \"support\": 353.0\n",
      "    },\n",
      "    \"black pine\": {\n",
      "        \"precision\": 0.0,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1-score\": 0.0,\n",
      "        \"support\": 9.0\n",
      "    },\n",
      "    \"cherry\": {\n",
      "        \"precision\": 0.42857142857142855,\n",
      "        \"recall\": 0.05263157894736842,\n",
      "        \"f1-score\": 0.09375,\n",
      "        \"support\": 57.0\n",
      "    },\n",
      "    \"douglas fir\": {\n",
      "        \"precision\": 0.8675496688741722,\n",
      "        \"recall\": 0.7766798418972332,\n",
      "        \"f1-score\": 0.8196037539103233,\n",
      "        \"support\": 506.0\n",
      "    },\n",
      "    \"english oak\": {\n",
      "        \"precision\": 0.5055900621118012,\n",
      "        \"recall\": 0.6310077519379845,\n",
      "        \"f1-score\": 0.5613793103448276,\n",
      "        \"support\": 645.0\n",
      "    },\n",
      "    \"european ash\": {\n",
      "        \"precision\": 0.3689839572192513,\n",
      "        \"recall\": 0.4791666666666667,\n",
      "        \"f1-score\": 0.4169184290030211,\n",
      "        \"support\": 432.0\n",
      "    },\n",
      "    \"european beech\": {\n",
      "        \"precision\": 0.8323952470293934,\n",
      "        \"recall\": 0.7815619495008808,\n",
      "        \"f1-score\": 0.8061780738946094,\n",
      "        \"support\": 1703.0\n",
      "    },\n",
      "    \"european larch\": {\n",
      "        \"precision\": 0.543778801843318,\n",
      "        \"recall\": 0.5339366515837104,\n",
      "        \"f1-score\": 0.5388127853881278,\n",
      "        \"support\": 221.0\n",
      "    },\n",
      "    \"japanese larch\": {\n",
      "        \"precision\": 0.5149700598802395,\n",
      "        \"recall\": 0.6370370370370371,\n",
      "        \"f1-score\": 0.5695364238410595,\n",
      "        \"support\": 135.0\n",
      "    },\n",
      "    \"linden\": {\n",
      "        \"precision\": 0.6666666666666666,\n",
      "        \"recall\": 0.0392156862745098,\n",
      "        \"f1-score\": 0.07407407407407407,\n",
      "        \"support\": 51.0\n",
      "    },\n",
      "    \"norway spruce\": {\n",
      "        \"precision\": 0.7935064935064935,\n",
      "        \"recall\": 0.8190348525469169,\n",
      "        \"f1-score\": 0.8060686015831134,\n",
      "        \"support\": 746.0\n",
      "    },\n",
      "    \"poplar\": {\n",
      "        \"precision\": 0.631578947368421,\n",
      "        \"recall\": 0.3116883116883117,\n",
      "        \"f1-score\": 0.41739130434782606,\n",
      "        \"support\": 77.0\n",
      "    },\n",
      "    \"red oak\": {\n",
      "        \"precision\": 0.8452380952380952,\n",
      "        \"recall\": 0.5590551181102362,\n",
      "        \"f1-score\": 0.6729857819905214,\n",
      "        \"support\": 381.0\n",
      "    },\n",
      "    \"scots pine\": {\n",
      "        \"precision\": 0.8702928870292888,\n",
      "        \"recall\": 0.8652246256239601,\n",
      "        \"f1-score\": 0.8677513558614935,\n",
      "        \"support\": 1202.0\n",
      "    },\n",
      "    \"sessile oak\": {\n",
      "        \"precision\": 0.4699828473413379,\n",
      "        \"recall\": 0.5557809330628803,\n",
      "        \"f1-score\": 0.5092936802973979,\n",
      "        \"support\": 493.0\n",
      "    },\n",
      "    \"silver fir\": {\n",
      "        \"precision\": 0.7771084337349398,\n",
      "        \"recall\": 0.7456647398843931,\n",
      "        \"f1-score\": 0.7610619469026549,\n",
      "        \"support\": 173.0\n",
      "    },\n",
      "    \"sycamore maple\": {\n",
      "        \"precision\": 0.5489614243323442,\n",
      "        \"recall\": 0.5103448275862069,\n",
      "        \"f1-score\": 0.5289492494639028,\n",
      "        \"support\": 725.0\n",
      "    },\n",
      "    \"weymouth pine\": {\n",
      "        \"precision\": 0.5,\n",
      "        \"recall\": 0.2727272727272727,\n",
      "        \"f1-score\": 0.3529411764705882,\n",
      "        \"support\": 22.0\n",
      "    },\n",
      "    \"accuracy\": 0.6644713207999042,\n",
      "    \"macro avg\": {\n",
      "        \"precision\": 0.5854205990064308,\n",
      "        \"recall\": 0.4970920779679028,\n",
      "        \"f1-score\": 0.5078684501594706,\n",
      "        \"support\": 8351.0\n",
      "    },\n",
      "    \"weighted avg\": {\n",
      "        \"precision\": 0.6894430797552652,\n",
      "        \"recall\": 0.6644713207999042,\n",
      "        \"f1-score\": 0.6677433635601685,\n",
      "        \"support\": 8351.0\n",
      "    }\n",
      "}\n",
      "Recall (Final Test): 0.6645\n",
      "F1-Score (Final Test): 0.6677\n",
      "\n",
      "Total Number of Test Points: 8351\n",
      "Saved: report_final.json, confusion_final.npy, confusion_final.png\n"
     ]
    }
   ],
   "source": [
    "# 9. Evaluate Model on Final Test Data\n",
    "test_data_dir = \"/kaggle/input/final-test-data\"\n",
    "test_features = []\n",
    "test_labels = []\n",
    "test_invalid_samples = []\n",
    "test_invalid_bands = Counter()\n",
    "total_samples_attempted = 0  # Track total samples processed\n",
    "\n",
    "# Check if directory exists and list files\n",
    "if not os.path.exists(test_data_dir):\n",
    "    print(f\"\\nError: Test data directory {test_data_dir} does not exist.\")\n",
    "    exit()\n",
    "geojson_files = [f for f in os.listdir(test_data_dir) if f.endswith(\".geojson\")]\n",
    "print(f\"\\nFound {len(geojson_files)} GeoJSON files in {test_data_dir}\")\n",
    "\n",
    "# Load all GeoJSON files from test data directory\n",
    "for file in geojson_files:\n",
    "    try:\n",
    "        file_path = os.path.join(test_data_dir, file)\n",
    "        gdf = gpd.read_file(file_path)\n",
    "        print(f\"Processing file: {file}, Rows: {len(gdf)}\")\n",
    "        total_samples_attempted += len(gdf)  # Count all rows in the file\n",
    "        for idx, row in gdf.iterrows():\n",
    "            try:\n",
    "                patch = []\n",
    "                for col in band_columns:\n",
    "                    if col not in gdf.columns:\n",
    "                        test_invalid_bands[col] += 1\n",
    "                        array = np.zeros((5, 5), dtype=np.float32)  # Impute with zeros\n",
    "                        patch.append(array)\n",
    "                        continue\n",
    "                    data = row[col]\n",
    "                    if data is None or (isinstance(data, str) and data.lower() == 'none'):\n",
    "                        test_invalid_bands[col] += 1\n",
    "                        array = np.zeros((5, 5), dtype=np.float32)  # Impute with zeros\n",
    "                        patch.append(array)\n",
    "                        continue\n",
    "                    try:\n",
    "                        parsed_data = ast.literal_eval(data) if isinstance(data, str) else data\n",
    "                        array = np.array(parsed_data, dtype=np.float32).reshape(5, 5)\n",
    "                    except (ValueError, SyntaxError, TypeError) as e:\n",
    "                        test_invalid_bands[col] += 1\n",
    "                        array = np.zeros((5, 5), dtype=np.float32)  # Impute for parsing errors\n",
    "                        patch.append(array)\n",
    "                        continue\n",
    "                    patch.append(array)\n",
    "                patch = np.stack(patch, axis=-1)\n",
    "                if patch.shape != (5, 5, 136):  # Expected shape: 17 bands * 8 months\n",
    "                    raise ValueError(f\"Unexpected patch shape: {patch.shape}\")\n",
    "                test_features.append(patch)\n",
    "                test_labels.append(row['l3_species'])\n",
    "            except (ValueError, SyntaxError, TypeError) as e:\n",
    "                test_invalid_samples.append((file, idx, str(e)))\n",
    "                continue\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process file {file}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Log invalid samples and bands\n",
    "print(f\"\\nTotal samples attempted: {total_samples_attempted}\")\n",
    "print(f\"Valid samples processed: {len(test_features)}\")\n",
    "if test_invalid_samples:\n",
    "    print(f\"\\nSkipped {len(test_invalid_samples)} invalid test samples:\")\n",
    "    for file, idx, error in test_invalid_samples:\n",
    "        print(f\"File: {file}, Row: {idx}, Error: {error}\")\n",
    "if test_invalid_bands:\n",
    "    print(\"\\nBands with missing/None/parsing issues in test data:\")\n",
    "    for band, count in test_invalid_bands.most_common():\n",
    "        print(f\"  {band}: {count} times\")\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "if not test_features:\n",
    "    print(\"\\nError: No valid test samples loaded. Cannot evaluate model.\")\n",
    "    exit()\n",
    "\n",
    "X_test_final = np.array(test_features, dtype=np.float32)  # Shape: (N, 5, 5, 136)\n",
    "y_test_final = np.array(test_labels)\n",
    "\n",
    "# Preprocess test data\n",
    "try:\n",
    "    y_test_final_encoded = label_encoder.transform(y_test_final)  # Use same LabelEncoder\n",
    "except ValueError as e:\n",
    "    print(f\"Error in label encoding: {e}\")\n",
    "    unknown_labels = set(y_test_final) - set(label_encoder.classes_)\n",
    "    print(f\"Unknown labels in test data: {unknown_labels}\")\n",
    "    exit()\n",
    "X_test_final_flat = X_test_final.reshape(X_test_final.shape[0], -1)  # Flatten for prediction\n",
    "X_test_final_scaled = scaler.transform(X_test_final_flat)  # Use same StandardScaler\n",
    "\n",
    "# Diagnostic: Compare class distributions\n",
    "print(\"\\nTraining class distribution:\")\n",
    "print(pd.Series(label_encoder.inverse_transform(y_train_resampled)).value_counts())\n",
    "print(\"\\nTest class distribution:\")\n",
    "print(pd.Series(y_test_final).value_counts())\n",
    "missing_classes = set(label_encoder.classes_) - set(y_test_final)\n",
    "print(f\"Classes missing in test data: {missing_classes}\")\n",
    "\n",
    "# Diagnostic: Compare feature distributions\n",
    "print(\"\\nTraining feature stats (after scaling):\")\n",
    "print(f\"Mean: {X_train_scaled.mean():.4f}, Std: {X_train_scaled.std():.4f}\")\n",
    "\n",
    "print(\"\\nTest feature stats (after scaling):\")\n",
    "print(f\"Mean: {X_test_final_scaled.mean():.4f}, Std: {X_test_final_scaled.std():.4f}\")\n",
    "\n",
    "\n",
    "# Evaluate model on test data\n",
    "y_pred_final = model5.predict(X_test_final_scaled)\n",
    "test_accuracy_final = (y_pred_final == y_test_final_encoded).mean()\n",
    "print(f\"\\nFinal Test Data Accuracy: {test_accuracy_final:.4f}\")\n",
    "\n",
    "# Get unique labels in test data to avoid mismatch\n",
    "unique_test_labels = np.unique(y_test_final_encoded)\n",
    "unique_test_label_names = label_encoder.inverse_transform(unique_test_labels)\n",
    "\n",
    "# Additional metrics for test data\n",
    "report_final = classification_report(\n",
    "    y_test_final_encoded,\n",
    "    y_pred_final,\n",
    "    labels=unique_test_labels,\n",
    "    target_names=unique_test_label_names,\n",
    "    output_dict=True\n",
    ")\n",
    "print(\"\\nClassification Report for Final Test Data:\")\n",
    "print(json.dumps(report_final, indent=4))\n",
    "print(f\"Recall (Final Test): {recall_score(y_test_final_encoded, y_pred_final, average='weighted'):.4f}\")\n",
    "print(f\"F1-Score (Final Test): {f1_score(y_test_final_encoded, y_pred_final, average='weighted'):.4f}\")\n",
    "\n",
    "# Confusion matrix for test data\n",
    "cm_final = confusion_matrix(y_test_final_encoded, y_pred_final, labels=unique_test_labels)\n",
    "plt.figure(figsize=(10, 8), dpi=100)\n",
    "sns.heatmap(cm_final, annot=True, fmt='d', xticklabels=unique_test_label_names, yticklabels=unique_test_label_names, cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix for Final Test Data')\n",
    "plt.savefig('confusion_final.png', dpi=100)\n",
    "plt.close()\n",
    "\n",
    "# Total number of test points\n",
    "print(f\"\\nTotal Number of Test Points: {len(y_test_final)}\")\n",
    "\n",
    "# Save outputs for test data\n",
    "json.dump(report_final, open('report_final.json', 'w'), indent=4)\n",
    "np.save('confusion_final.npy', cm_final)\n",
    "print(\"Saved: report_final.json, confusion_final.npy, confusion_final.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7762517,
     "sourceId": 12315204,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7871256,
     "sourceId": 12475667,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 662.897957,
   "end_time": "2025-07-17T14:48:25.051788",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-17T14:37:22.153831",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
