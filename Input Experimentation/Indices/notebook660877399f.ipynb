{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12289010,"sourceType":"datasetVersion","datasetId":7744979}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras import layers, models\nimport geopandas as gpd\nimport ast\nimport os\nimport json\n\n# 1. Inspect and Load GeoJSON Files\ndata_dir = \"/kaggle/input/treesatai-indices\"  # Path to new data\nall_features = []\nall_labels = []\ninvalid_samples = []\n\n# Updated list of bands based on inspection\nbands = ['ARVI', 'B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12', 'DEM', 'EVI', 'EVI2', 'NDVI', 'NDWI']\nmonths = ['', '_1', '_2', '_3', '_4', '_5', '_6', '_7']\nband_columns = [band + month for month in months for band in bands]  # 18 bands × 8 months = 144 channels\n\n# Inspect first file for debugging\nfirst_file = os.path.join(data_dir, os.listdir(data_dir)[0]) if os.listdir(data_dir) else None\nif first_file and first_file.endswith(\".geojson\"):\n    gdf = gpd.read_file(first_file)\n    print(\"Inspecting first 2 rows of first GeoJSON file:\")\n    for idx in range(min(2, len(gdf))):\n        print(f\"\\nRow {idx}:\")\n        for band in ['ARVI', 'B1', 'B11', 'NDVI', 'B2_1', 'NDVI_7']:  # Sample of new and old bands\n            data = gdf[band].iloc[idx]\n            print(f\"  Band {band}: type={type(data)}, raw_value={str(data)[:100]}...\")\n            try:\n                if isinstance(data, (list, np.ndarray)):\n                    array = np.array(data, dtype=np.float32)\n                elif isinstance(data, str):\n                    try:\n                        array = np.array(json.loads(data), dtype=np.float32)\n                    except json.JSONDecodeError:\n                        array = np.array(ast.literal_eval(data), dtype=np.float32)\n                elif isinstance(data, (float, np.float32, np.float64)):\n                    array = np.full((5, 5), data, dtype=np.float32)\n                else:\n                    raise ValueError(f\"Unexpected data type for band {band}: {type(data)}\")\n                if array.shape != (5, 5):\n                    raise ValueError(f\"Band {band} has shape {array.shape}, expects (5, 5)\")\n                print(f\"  Band {band}: shape={array.shape}, first few values={array.flatten()[:5]}\")\n            except Exception as e:\n                print(f\"  Band {band}: Error processing data: {e}\")\n\n# Load all GeoJSON files\nfor file in os.listdir(data_dir):\n    if file.endswith(\".geojson\"):\n        gdf = gpd.read_file(os.path.join(data_dir, file))\n        for idx, row in gdf.iterrows():\n            try:\n                patches = []\n                for col in band_columns:\n                    if col not in gdf.columns:\n                        raise ValueError(f\"Column {col} not found in {file}\")\n                    val = row[col]\n                    if isinstance(val, (list, np.ndarray)):\n                        arr = np.array(val, dtype=np.float32).reshape(5, 5)\n                    elif isinstance(val, str):\n                        try:\n                            arr = np.array(json.loads(val), dtype=np.float32).reshape(5, 5)\n                        except json.JSONDecodeError:\n                            arr = np.array(ast.literal_eval(val), dtype=np.float32).reshape(5, 5)\n                    elif isinstance(val, (float, np.float32, np.float64)):\n                        arr = np.full((5, 5), val, dtype=np.float32)\n                    else:\n                        raise ValueError(f\"Unexpected data type for band {col}: {type(val)}\")\n                    patches.append(arr)\n\n                patch = np.stack(patches, axis=-1)\n                if patch.shape != (5, 5, 144):  # Updated to 18 bands × 8 months = 144 channels\n                    raise ValueError(f\"Unexpected patch shape: {patch.shape}, expected (5, 5, 144)\")\n                all_features.append(patch)\n                all_labels.append(row['l3_species'])\n            except Exception as e:\n                invalid_samples.append((file, idx, str(e)))\n                continue\n\n# Log invalid samples\nif invalid_samples:\n    print(f\"\\nSkipped {len(invalid_samples)} invalid samples:\")\n    for file, idx, error in invalid_samples[:5]:\n        print(f\"File: {file}, Row: {idx}, Error: {error}\")\n    if invalid_samples:\n        print(f\"First invalid sample raw data (ARVI): {str(gdf.iloc[invalid_samples[0][1]]['ARVI'])[:100]}...\")\n\n# Convert to NumPy arrays\nif not all_features:\n    raise ValueError(\"No valid samples loaded. Check GeoJSON files or GEE export.\")\nX = np.array(all_features, dtype=np.float32)  # Shape: (num_samples, 5, 5, 144)\ny = np.array(all_labels)\n\nprint(f\"Loaded {len(all_features)} valid samples with shape {X.shape}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-26T08:43:57.378030Z","iopub.execute_input":"2025-06-26T08:43:57.378298Z","iopub.status.idle":"2025-06-26T08:48:46.935771Z","shell.execute_reply.started":"2025-06-26T08:43:57.378274Z","shell.execute_reply":"2025-06-26T08:48:46.935024Z"}},"outputs":[{"name":"stderr","text":"2025-06-26 08:43:58.030099: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1750927438.052920    5299 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1750927438.059769    5299 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Inspecting first 2 rows of first GeoJSON file:\n\nRow 0:\n  Band ARVI: type=<class 'numpy.float64'>, raw_value=0.41744154691696167...\n  Band ARVI: shape=(5, 5), first few values=[0.41744155 0.41744155 0.41744155 0.41744155 0.41744155]\n  Band B1: type=<class 'numpy.float64'>, raw_value=0.12300000339746475...\n  Band B1: shape=(5, 5), first few values=[0.123 0.123 0.123 0.123 0.123]\n  Band B11: type=<class 'numpy.float64'>, raw_value=0.18479999899864197...\n  Band B11: shape=(5, 5), first few values=[0.1848 0.1848 0.1848 0.1848 0.1848]\n  Band NDVI: type=<class 'numpy.float64'>, raw_value=0.42132997512817383...\n  Band NDVI: shape=(5, 5), first few values=[0.42132998 0.42132998 0.42132998 0.42132998 0.42132998]\n  Band B2_1: type=<class 'numpy.float64'>, raw_value=0.11259999871253967...\n  Band B2_1: shape=(5, 5), first few values=[0.1126 0.1126 0.1126 0.1126 0.1126]\n  Band NDVI_7: type=<class 'numpy.float64'>, raw_value=0.3798370659351349...\n  Band NDVI_7: shape=(5, 5), first few values=[0.37983707 0.37983707 0.37983707 0.37983707 0.37983707]\n\nRow 1:\n  Band ARVI: type=<class 'numpy.float64'>, raw_value=0.16849634051322937...\n  Band ARVI: shape=(5, 5), first few values=[0.16849634 0.16849634 0.16849634 0.16849634 0.16849634]\n  Band B1: type=<class 'numpy.float64'>, raw_value=0.14994999766349792...\n  Band B1: shape=(5, 5), first few values=[0.14995 0.14995 0.14995 0.14995 0.14995]\n  Band B11: type=<class 'numpy.float64'>, raw_value=0.38510000705718994...\n  Band B11: shape=(5, 5), first few values=[0.3851 0.3851 0.3851 0.3851 0.3851]\n  Band NDVI: type=<class 'numpy.float64'>, raw_value=0.2599557340145111...\n  Band NDVI: shape=(5, 5), first few values=[0.25995573 0.25995573 0.25995573 0.25995573 0.25995573]\n  Band B2_1: type=<class 'numpy.float64'>, raw_value=0.15575000643730164...\n  Band B2_1: shape=(5, 5), first few values=[0.15575 0.15575 0.15575 0.15575 0.15575]\n  Band NDVI_7: type=<class 'numpy.float64'>, raw_value=0.3259807527065277...\n  Band NDVI_7: shape=(5, 5), first few values=[0.32598075 0.32598075 0.32598075 0.32598075 0.32598075]\n\nSkipped 5199 invalid samples:\nFile: needleleaf_pine_weymouth pine.geojson, Row: 57, Error: Unexpected data type for band ARVI_4: <class 'NoneType'>\nFile: needleleaf_pine_weymouth pine.geojson, Row: 84, Error: Unexpected data type for band ARVI_4: <class 'NoneType'>\nFile: needleleaf_pine_weymouth pine.geojson, Row: 97, Error: Unexpected data type for band ARVI_4: <class 'NoneType'>\nFile: needleleaf_pine_weymouth pine.geojson, Row: 125, Error: Unexpected data type for band ARVI_4: <class 'NoneType'>\nFile: needleleaf_pine_weymouth pine.geojson, Row: 139, Error: Unexpected data type for band ARVI_1: <class 'NoneType'>\nFirst invalid sample raw data (ARVI): 0.18817108869552612...\nLoaded 32708 valid samples with shape (32708, 5, 5, 144)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras import layers, models\nimport geopandas as gpd\nimport os\nimport json\nimport joblib\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\n# 2. Handle NaN Values\nprint(\"\\nChecking for NaN values...\")\nnan_mask = np.any(np.isnan(X), axis=(1, 2, 3))\nnan_count = np.sum(nan_mask)\nprint(f\"Found {nan_count} samples with NaN values\")\nif nan_count > 0:\n    print(f\"Removing {nan_count} samples with NaN values\")\n    valid_mask = ~nan_mask\n    X = X[valid_mask]\n    y = y[valid_mask]\n    print(f\"New data shape after removing NaN: {X.shape}\")\n\n# 3. Normalize Data\nprint(\"\\nNormalizing data...\")\nX_min = np.nanmin(X, axis=(0, 1, 2), keepdims=True)\nX_max = np.nanmax(X, axis=(0, 1, 2), keepdims=True)\nX = (X - X_min) / (X_max - X_min + 1e-6)  # Min-max normalization to [0, 1]\nprint(f\"Data range after normalization: min={np.nanmin(X):.4f}, max={np.nanmax(X):.4f}\")\n\n# 4. Preprocess Labels\nlabel_encoder = LabelEncoder()\ny_encoded = label_encoder.fit_transform(y)\ny_onehot = tf.keras.utils.to_categorical(y_encoded)\nnum_classes = len(label_encoder.classes_)\nprint(f\"\\nData shape: {X.shape}, Number of classes: {num_classes}\")\n\n# 5. Define Feature Combinations\nspectral_bands = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12']  # 12 bands\nveg_indices = ['ARVI', 'EVI', 'EVI2', 'NDVI', 'NDWI', 'RENDVI', 'SAVI', 'NBR']  # 8 bands\ndem_band = ['DEM']  # 1 band\n\n# Create and verify channel indices\nspectral_indices = [i for i, col in enumerate(band_columns) if any(col.startswith(band) for band in spectral_bands)]\nveg_indices_indices = [i for i, col in enumerate(band_columns) if any(col.startswith(band) for band in veg_indices)]\ndem_indices = [i for i, col in enumerate(band_columns) if col.startswith('DEM')]\n\n# Debug channel indices\nprint(\"\\nDebugging channel indices:\")\nprint(f\"Spectral indices ({len(spectral_indices)}): {[band_columns[i] for i in spectral_indices]}\")\nprint(f\"Vegetation indices ({len(veg_indices_indices)}): {[band_columns[i] for i in veg_indices_indices]}\")\nprint(f\"DEM indices ({len(dem_indices)}): {[band_columns[i] for i in dem_indices]}\")\nprint(f\"Spectral + Veg indices ({len(spectral_indices + veg_indices_indices)}): {[band_columns[i] for i in spectral_indices + veg_indices_indices]}\")\n\n# Verify expected channel counts\nexpected_veg_channels = 8 * len(months)  # 8 bands × 8 months\nif len(veg_indices_indices) != expected_veg_channels:\n    print(f\"Warning: Expected {expected_veg_channels} vegetation indices channels, got {len(veg_indices_indices)}\")\n    missing_veg_bands = [band for band in veg_indices if not any(col.startswith(band) for col in band_columns)]\n    print(f\"Missing vegetation indices: {missing_veg_bands}\")\n\nfeature_combinations = {\n    'spectral': (spectral_indices, 96, 'Spectral Bands Only'),\n    'spectral_veg': (spectral_indices + veg_indices_indices, 96 + len(veg_indices_indices), 'Spectral + Vegetation Indices'),\n    'spectral_dem': (spectral_indices + dem_indices, 96 + 8, 'Spectral + DEM'),\n    'all_features': (list(range(144)), 144, 'Spectral + Vegetation Indices + DEM')\n}\n\n# 6. Define CNN Model\ndef build_cnn(input_shape, num_classes):\n    model = models.Sequential([\n        layers.Input(shape=input_shape),\n        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n        layers.BatchNormalization(),\n        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D((2, 2)),\n        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n        layers.BatchNormalization(),\n        layers.Flatten(),\n        layers.Dense(128, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax')\n    ])\n    return model\n\n# 7. Data Augmentation\ndata_augmentation = tf.keras.Sequential([\n    layers.RandomFlip(\"horizontal_and_vertical\"),\n    layers.RandomRotation(0.2),\n])\n\n# 8. Train and Evaluate for Each Feature Combination\nresults = {}\nfor combo_name, (indices, num_channels, description) in feature_combinations.items():\n    print(f\"\\nTraining model with {description} ({num_channels} channels)\")\n    \n    # Select feature subset\n    X_subset = X[:, :, :, indices]\n    print(f\"Subset shape: {X_subset.shape}\")\n    \n    # Verify no NaN in subset\n    if np.any(np.isnan(X_subset)):\n        print(f\"Warning: NaN values found in {description} subset\")\n    \n    # Train-test-validation split\n    X_train, X_test, y_train, y_test = train_test_split(X_subset, y_onehot, test_size=0.15, random_state=42, stratify=y_onehot)\n    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1765, random_state=42, stratify=y_train)\n    \n    # Build and compile model\n    model = build_cnn(input_shape=(5, 5, num_channels), num_classes=num_classes)\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    \n    # Train model\n    history = model.fit(\n        data_augmentation(X_train), y_train,\n        validation_data=(X_val, y_val),\n        epochs=50,\n        batch_size=32,\n        callbacks=[\n            tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n            tf.keras.callbacks.ModelCheckpoint(f'best_model_{combo_name}.keras', save_best_only=True)\n        ],\n        verbose=1\n    )\n    \n    # Evaluate model\n    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n    print(f\"{description} Test Accuracy: {test_accuracy:.4f}\")\n    \n    # Confusion matrix\n    y_pred = model.predict(X_test)\n    y_pred_classes = np.argmax(y_pred, axis=1)\n    y_test_classes = np.argmax(y_test, axis=1)\n    cm = confusion_matrix(y_test_classes, y_pred_classes)\n    \n    # Plot confusion matrix\n    plt.figure(figsize=(12, 10))\n    sns.heatmap(cm, annot=True, fmt='d', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title(f'Confusion Matrix: {description}')\n    plt.savefig(f'confusion_matrix_{combo_name}.png')\n    plt.close()\n    \n    # Store results\n    results[combo_name] = {\n        'description': description,\n        'test_accuracy': test_accuracy,\n        'test_loss': test_loss,\n        'history': history.history\n    }\n\n# 9. Compare Results\nprint(\"\\nSummary of Results:\")\nfor combo_name, result in results.items():\n    print(f\"{result['description']}: Test Accuracy = {result['test_accuracy']:.4f}, Test Loss = {result['test_loss']:.4f}\")\n\n# Plot accuracy comparison\nplt.figure(figsize=(10, 6))\naccuracies = [results[combo]['test_accuracy'] for combo in results]\ncombo_names = [results[combo]['description'] for combo in results]\nplt.bar(combo_names, accuracies)\nplt.xlabel('Feature Combination')\nplt.ylabel('Test Accuracy')\nplt.title('Test Accuracy by Feature Combination')\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.savefig('accuracy_comparison.png')\nplt.close()\n\n# 10. Save Label Encoder and Results\njoblib.dump(label_encoder, 'label_encoder.pkl')\nwith open('results_summary.json', 'w') as f:\n    json.dump({k: {kk: vv for kk, vv in v.items() if kk != 'history'} for k, v in results.items()}, f, indent=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T08:51:10.761490Z","iopub.execute_input":"2025-06-26T08:51:10.762028Z","iopub.status.idle":"2025-06-26T08:56:53.984953Z","shell.execute_reply.started":"2025-06-26T08:51:10.762005Z","shell.execute_reply":"2025-06-26T08:56:53.984311Z"}},"outputs":[{"name":"stdout","text":"\nChecking for NaN values...\nFound 6440 samples with NaN values\nRemoving 6440 samples with NaN values\nNew data shape after removing NaN: (26268, 5, 5, 144)\n\nNormalizing data...\nData range after normalization: min=0.0000, max=1.0000\n\nData shape: (26268, 5, 5, 144), Number of classes: 19\n\nDebugging channel indices:\nSpectral indices (96): ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12', 'B1_1', 'B2_1', 'B3_1', 'B4_1', 'B5_1', 'B6_1', 'B7_1', 'B8_1', 'B8A_1', 'B9_1', 'B11_1', 'B12_1', 'B1_2', 'B2_2', 'B3_2', 'B4_2', 'B5_2', 'B6_2', 'B7_2', 'B8_2', 'B8A_2', 'B9_2', 'B11_2', 'B12_2', 'B1_3', 'B2_3', 'B3_3', 'B4_3', 'B5_3', 'B6_3', 'B7_3', 'B8_3', 'B8A_3', 'B9_3', 'B11_3', 'B12_3', 'B1_4', 'B2_4', 'B3_4', 'B4_4', 'B5_4', 'B6_4', 'B7_4', 'B8_4', 'B8A_4', 'B9_4', 'B11_4', 'B12_4', 'B1_5', 'B2_5', 'B3_5', 'B4_5', 'B5_5', 'B6_5', 'B7_5', 'B8_5', 'B8A_5', 'B9_5', 'B11_5', 'B12_5', 'B1_6', 'B2_6', 'B3_6', 'B4_6', 'B5_6', 'B6_6', 'B7_6', 'B8_6', 'B8A_6', 'B9_6', 'B11_6', 'B12_6', 'B1_7', 'B2_7', 'B3_7', 'B4_7', 'B5_7', 'B6_7', 'B7_7', 'B8_7', 'B8A_7', 'B9_7', 'B11_7', 'B12_7']\nVegetation indices (40): ['ARVI', 'EVI', 'EVI2', 'NDVI', 'NDWI', 'ARVI_1', 'EVI_1', 'EVI2_1', 'NDVI_1', 'NDWI_1', 'ARVI_2', 'EVI_2', 'EVI2_2', 'NDVI_2', 'NDWI_2', 'ARVI_3', 'EVI_3', 'EVI2_3', 'NDVI_3', 'NDWI_3', 'ARVI_4', 'EVI_4', 'EVI2_4', 'NDVI_4', 'NDWI_4', 'ARVI_5', 'EVI_5', 'EVI2_5', 'NDVI_5', 'NDWI_5', 'ARVI_6', 'EVI_6', 'EVI2_6', 'NDVI_6', 'NDWI_6', 'ARVI_7', 'EVI_7', 'EVI2_7', 'NDVI_7', 'NDWI_7']\nDEM indices (8): ['DEM', 'DEM_1', 'DEM_2', 'DEM_3', 'DEM_4', 'DEM_5', 'DEM_6', 'DEM_7']\nSpectral + Veg indices (136): ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12', 'B1_1', 'B2_1', 'B3_1', 'B4_1', 'B5_1', 'B6_1', 'B7_1', 'B8_1', 'B8A_1', 'B9_1', 'B11_1', 'B12_1', 'B1_2', 'B2_2', 'B3_2', 'B4_2', 'B5_2', 'B6_2', 'B7_2', 'B8_2', 'B8A_2', 'B9_2', 'B11_2', 'B12_2', 'B1_3', 'B2_3', 'B3_3', 'B4_3', 'B5_3', 'B6_3', 'B7_3', 'B8_3', 'B8A_3', 'B9_3', 'B11_3', 'B12_3', 'B1_4', 'B2_4', 'B3_4', 'B4_4', 'B5_4', 'B6_4', 'B7_4', 'B8_4', 'B8A_4', 'B9_4', 'B11_4', 'B12_4', 'B1_5', 'B2_5', 'B3_5', 'B4_5', 'B5_5', 'B6_5', 'B7_5', 'B8_5', 'B8A_5', 'B9_5', 'B11_5', 'B12_5', 'B1_6', 'B2_6', 'B3_6', 'B4_6', 'B5_6', 'B6_6', 'B7_6', 'B8_6', 'B8A_6', 'B9_6', 'B11_6', 'B12_6', 'B1_7', 'B2_7', 'B3_7', 'B4_7', 'B5_7', 'B6_7', 'B7_7', 'B8_7', 'B8A_7', 'B9_7', 'B11_7', 'B12_7', 'ARVI', 'EVI', 'EVI2', 'NDVI', 'NDWI', 'ARVI_1', 'EVI_1', 'EVI2_1', 'NDVI_1', 'NDWI_1', 'ARVI_2', 'EVI_2', 'EVI2_2', 'NDVI_2', 'NDWI_2', 'ARVI_3', 'EVI_3', 'EVI2_3', 'NDVI_3', 'NDWI_3', 'ARVI_4', 'EVI_4', 'EVI2_4', 'NDVI_4', 'NDWI_4', 'ARVI_5', 'EVI_5', 'EVI2_5', 'NDVI_5', 'NDWI_5', 'ARVI_6', 'EVI_6', 'EVI2_6', 'NDVI_6', 'NDWI_6', 'ARVI_7', 'EVI_7', 'EVI2_7', 'NDVI_7', 'NDWI_7']\nWarning: Expected 64 vegetation indices channels, got 40\nMissing vegetation indices: ['RENDVI', 'SAVI', 'NBR']\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1750927872.043730    5299 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"\nTraining model with Spectral Bands Only (96 channels)\nSubset shape: (26268, 5, 5, 96)\nEpoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1750927878.982372    5356 service.cc:148] XLA service 0x50839e90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1750927878.982412    5356 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1750927879.309970    5356 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 54/575\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2301 - loss: 2.8254","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1750927881.482130    5356 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.3243 - loss: 2.2517 - val_accuracy: 0.3250 - val_loss: 2.1333\nEpoch 2/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4589 - loss: 1.7446 - val_accuracy: 0.2626 - val_loss: 2.4773\nEpoch 3/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5208 - loss: 1.5736 - val_accuracy: 0.3169 - val_loss: 3.0453\nEpoch 4/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5468 - loss: 1.4854 - val_accuracy: 0.2981 - val_loss: 2.7997\nEpoch 5/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5726 - loss: 1.4191 - val_accuracy: 0.2261 - val_loss: 4.0776\nEpoch 6/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5806 - loss: 1.3687 - val_accuracy: 0.4035 - val_loss: 2.0866\nEpoch 7/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6065 - loss: 1.2933 - val_accuracy: 0.3806 - val_loss: 2.0001\nEpoch 8/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6141 - loss: 1.2548 - val_accuracy: 0.4857 - val_loss: 1.6301\nEpoch 9/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6340 - loss: 1.2037 - val_accuracy: 0.5821 - val_loss: 1.4442\nEpoch 10/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6485 - loss: 1.1309 - val_accuracy: 0.4600 - val_loss: 1.8109\nEpoch 11/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6753 - loss: 1.0398 - val_accuracy: 0.4286 - val_loss: 2.0738\nEpoch 12/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7005 - loss: 0.9459 - val_accuracy: 0.4793 - val_loss: 2.2840\nEpoch 13/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7156 - loss: 0.9040 - val_accuracy: 0.4831 - val_loss: 1.9267\nEpoch 14/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7350 - loss: 0.8311 - val_accuracy: 0.6034 - val_loss: 1.2263\nEpoch 15/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7392 - loss: 0.7985 - val_accuracy: 0.3842 - val_loss: 2.6173\nEpoch 16/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7436 - loss: 0.7942 - val_accuracy: 0.4268 - val_loss: 2.2396\nEpoch 17/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7511 - loss: 0.7648 - val_accuracy: 0.5826 - val_loss: 1.3115\nEpoch 18/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.7362 - val_accuracy: 0.5143 - val_loss: 1.7487\nEpoch 19/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7660 - loss: 0.7229 - val_accuracy: 0.4788 - val_loss: 1.9689\nEpoch 20/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7539 - loss: 0.7479 - val_accuracy: 0.6338 - val_loss: 1.2090\nEpoch 21/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7529 - loss: 0.7427 - val_accuracy: 0.6658 - val_loss: 1.1341\nEpoch 22/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7665 - loss: 0.7187 - val_accuracy: 0.5722 - val_loss: 1.4086\nEpoch 23/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7695 - loss: 0.6793 - val_accuracy: 0.4466 - val_loss: 2.2198\nEpoch 24/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7676 - loss: 0.6921 - val_accuracy: 0.6151 - val_loss: 1.4614\nEpoch 25/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7728 - loss: 0.6699 - val_accuracy: 0.5887 - val_loss: 1.3901\nEpoch 26/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7802 - loss: 0.6513 - val_accuracy: 0.6440 - val_loss: 1.3709\nEpoch 27/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7789 - loss: 0.6503 - val_accuracy: 0.5384 - val_loss: 1.8625\nEpoch 28/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7853 - loss: 0.6444 - val_accuracy: 0.6082 - val_loss: 1.5417\nEpoch 29/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7845 - loss: 0.6349 - val_accuracy: 0.5227 - val_loss: 2.1361\nEpoch 30/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7946 - loss: 0.6165 - val_accuracy: 0.6450 - val_loss: 1.2927\nEpoch 31/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7857 - loss: 0.6411 - val_accuracy: 0.6889 - val_loss: 1.0418\nEpoch 32/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7950 - loss: 0.5968 - val_accuracy: 0.6384 - val_loss: 1.3650\nEpoch 33/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7902 - loss: 0.6100 - val_accuracy: 0.6448 - val_loss: 1.5191\nEpoch 34/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8001 - loss: 0.5779 - val_accuracy: 0.5100 - val_loss: 1.7845\nEpoch 35/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8036 - loss: 0.5670 - val_accuracy: 0.5037 - val_loss: 2.3530\nEpoch 36/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7990 - loss: 0.5821 - val_accuracy: 0.6897 - val_loss: 1.0170\nEpoch 37/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8040 - loss: 0.5665 - val_accuracy: 0.6706 - val_loss: 1.4390\nEpoch 38/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8064 - loss: 0.5600 - val_accuracy: 0.7024 - val_loss: 1.0765\nEpoch 39/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8084 - loss: 0.5477 - val_accuracy: 0.7120 - val_loss: 0.9947\nEpoch 40/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8161 - loss: 0.5304 - val_accuracy: 0.6828 - val_loss: 1.2152\nEpoch 41/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8132 - loss: 0.5410 - val_accuracy: 0.6511 - val_loss: 1.3875\nEpoch 42/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8144 - loss: 0.5351 - val_accuracy: 0.6044 - val_loss: 1.4174\nEpoch 43/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8192 - loss: 0.5219 - val_accuracy: 0.4238 - val_loss: 2.8828\nEpoch 44/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8264 - loss: 0.5012 - val_accuracy: 0.6437 - val_loss: 1.5804\nEpoch 45/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8271 - loss: 0.5047 - val_accuracy: 0.6273 - val_loss: 1.6012\nEpoch 46/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8256 - loss: 0.4935 - val_accuracy: 0.6481 - val_loss: 1.7167\nEpoch 47/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8301 - loss: 0.4862 - val_accuracy: 0.6874 - val_loss: 1.2645\nEpoch 48/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8239 - loss: 0.4909 - val_accuracy: 0.5856 - val_loss: 2.3997\nEpoch 49/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8322 - loss: 0.4791 - val_accuracy: 0.5643 - val_loss: 2.4948\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6997 - loss: 1.0515\nSpectral Bands Only Test Accuracy: 0.7062\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n\nTraining model with Spectral + Vegetation Indices (136 channels)\nSubset shape: (26268, 5, 5, 136)\nEpoch 1/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.3337 - loss: 2.1856 - val_accuracy: 0.2766 - val_loss: 2.4086\nEpoch 2/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4672 - loss: 1.7516 - val_accuracy: 0.2449 - val_loss: 2.8533\nEpoch 3/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5176 - loss: 1.5959 - val_accuracy: 0.3453 - val_loss: 2.7216\nEpoch 4/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5526 - loss: 1.4724 - val_accuracy: 0.2550 - val_loss: 3.1104\nEpoch 5/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5635 - loss: 1.4324 - val_accuracy: 0.3588 - val_loss: 2.9811\nEpoch 6/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5809 - loss: 1.3668 - val_accuracy: 0.2537 - val_loss: 4.3568\nEpoch 7/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5924 - loss: 1.3157 - val_accuracy: 0.4182 - val_loss: 1.8083\nEpoch 8/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6157 - loss: 1.2549 - val_accuracy: 0.2197 - val_loss: 3.4741\nEpoch 9/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6539 - loss: 1.1174 - val_accuracy: 0.5049 - val_loss: 2.1584\nEpoch 10/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6891 - loss: 0.9892 - val_accuracy: 0.5202 - val_loss: 1.5484\nEpoch 11/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7035 - loss: 0.9387 - val_accuracy: 0.5707 - val_loss: 1.4712\nEpoch 12/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7181 - loss: 0.8851 - val_accuracy: 0.6029 - val_loss: 1.2401\nEpoch 13/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7320 - loss: 0.8311 - val_accuracy: 0.6191 - val_loss: 1.1491\nEpoch 14/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7343 - loss: 0.8084 - val_accuracy: 0.5702 - val_loss: 1.3099\nEpoch 15/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7414 - loss: 0.7914 - val_accuracy: 0.2847 - val_loss: 5.2199\nEpoch 16/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7489 - loss: 0.7771 - val_accuracy: 0.4103 - val_loss: 2.3462\nEpoch 17/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7419 - loss: 0.7728 - val_accuracy: 0.5762 - val_loss: 1.3374\nEpoch 18/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7604 - loss: 0.7523 - val_accuracy: 0.4770 - val_loss: 2.6008\nEpoch 19/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7736 - loss: 0.7019 - val_accuracy: 0.6260 - val_loss: 1.4183\nEpoch 20/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7640 - loss: 0.7064 - val_accuracy: 0.4232 - val_loss: 2.4662\nEpoch 21/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7698 - loss: 0.6894 - val_accuracy: 0.7077 - val_loss: 1.0256\nEpoch 22/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7761 - loss: 0.6770 - val_accuracy: 0.5664 - val_loss: 1.6095\nEpoch 23/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7743 - loss: 0.6809 - val_accuracy: 0.6255 - val_loss: 1.1561\nEpoch 24/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7763 - loss: 0.6626 - val_accuracy: 0.6105 - val_loss: 1.1413\nEpoch 25/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7852 - loss: 0.6480 - val_accuracy: 0.4811 - val_loss: 2.0436\nEpoch 26/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7812 - loss: 0.6557 - val_accuracy: 0.5785 - val_loss: 1.6207\nEpoch 27/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7858 - loss: 0.6362 - val_accuracy: 0.6108 - val_loss: 1.2009\nEpoch 28/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7933 - loss: 0.6200 - val_accuracy: 0.5900 - val_loss: 1.5081\nEpoch 29/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7877 - loss: 0.6218 - val_accuracy: 0.4973 - val_loss: 1.8557\nEpoch 30/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7841 - loss: 0.6278 - val_accuracy: 0.6016 - val_loss: 1.3185\nEpoch 31/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7954 - loss: 0.6001 - val_accuracy: 0.5582 - val_loss: 1.9877\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6991 - loss: 1.1090\nSpectral + Vegetation Indices Test Accuracy: 0.7016\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n\nTraining model with Spectral + DEM (104 channels)\nSubset shape: (26268, 5, 5, 104)\nEpoch 1/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.3525 - loss: 2.1602 - val_accuracy: 0.3068 - val_loss: 3.0156\nEpoch 2/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4796 - loss: 1.6885 - val_accuracy: 0.4839 - val_loss: 1.6692\nEpoch 3/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5302 - loss: 1.5252 - val_accuracy: 0.5016 - val_loss: 1.6733\nEpoch 4/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5565 - loss: 1.4462 - val_accuracy: 0.4928 - val_loss: 1.8762\nEpoch 5/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5713 - loss: 1.3912 - val_accuracy: 0.3557 - val_loss: 2.2435\nEpoch 6/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5725 - loss: 1.3711 - val_accuracy: 0.5072 - val_loss: 1.5518\nEpoch 7/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5782 - loss: 1.3597 - val_accuracy: 0.4796 - val_loss: 1.9228\nEpoch 8/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5856 - loss: 1.3134 - val_accuracy: 0.4225 - val_loss: 1.8380\nEpoch 9/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6098 - loss: 1.2547 - val_accuracy: 0.5207 - val_loss: 1.5797\nEpoch 10/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6294 - loss: 1.1815 - val_accuracy: 0.4892 - val_loss: 1.5544\nEpoch 11/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6435 - loss: 1.1230 - val_accuracy: 0.6181 - val_loss: 1.2039\nEpoch 12/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6785 - loss: 1.0110 - val_accuracy: 0.5445 - val_loss: 1.4314\nEpoch 13/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6930 - loss: 0.9481 - val_accuracy: 0.6719 - val_loss: 0.9761\nEpoch 14/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7155 - loss: 0.8922 - val_accuracy: 0.5727 - val_loss: 1.2919\nEpoch 15/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7167 - loss: 0.8779 - val_accuracy: 0.6265 - val_loss: 1.1053\nEpoch 16/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7268 - loss: 0.8368 - val_accuracy: 0.5849 - val_loss: 1.3379\nEpoch 17/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7370 - loss: 0.7997 - val_accuracy: 0.5491 - val_loss: 1.6223\nEpoch 18/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7349 - loss: 0.8135 - val_accuracy: 0.6562 - val_loss: 1.0806\nEpoch 19/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7358 - loss: 0.7967 - val_accuracy: 0.6503 - val_loss: 1.1546\nEpoch 20/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7533 - loss: 0.7530 - val_accuracy: 0.4600 - val_loss: 2.2063\nEpoch 21/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7522 - loss: 0.7539 - val_accuracy: 0.5798 - val_loss: 1.3489\nEpoch 22/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7537 - loss: 0.7395 - val_accuracy: 0.7310 - val_loss: 0.8200\nEpoch 23/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7526 - loss: 0.7412 - val_accuracy: 0.7257 - val_loss: 0.8298\nEpoch 24/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7547 - loss: 0.7280 - val_accuracy: 0.7300 - val_loss: 0.8001\nEpoch 25/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7715 - loss: 0.6923 - val_accuracy: 0.5582 - val_loss: 1.3400\nEpoch 26/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7675 - loss: 0.6860 - val_accuracy: 0.6800 - val_loss: 1.0015\nEpoch 27/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7685 - loss: 0.6873 - val_accuracy: 0.5592 - val_loss: 1.4843\nEpoch 28/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7761 - loss: 0.6697 - val_accuracy: 0.7257 - val_loss: 0.9001\nEpoch 29/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7732 - loss: 0.6735 - val_accuracy: 0.6270 - val_loss: 1.4668\nEpoch 30/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7775 - loss: 0.6591 - val_accuracy: 0.7260 - val_loss: 0.8589\nEpoch 31/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7815 - loss: 0.6455 - val_accuracy: 0.6125 - val_loss: 1.2596\nEpoch 32/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7844 - loss: 0.6368 - val_accuracy: 0.6854 - val_loss: 1.0649\nEpoch 33/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7832 - loss: 0.6326 - val_accuracy: 0.5674 - val_loss: 1.8782\nEpoch 34/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7891 - loss: 0.6173 - val_accuracy: 0.6161 - val_loss: 1.3813\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7142 - loss: 0.7920\nSpectral + DEM Test Accuracy: 0.7272\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n\nTraining model with Spectral + Vegetation Indices + DEM (144 channels)\nSubset shape: (26268, 5, 5, 144)\nEpoch 1/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.3400 - loss: 2.1762 - val_accuracy: 0.2928 - val_loss: 2.5983\nEpoch 2/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4885 - loss: 1.6792 - val_accuracy: 0.2329 - val_loss: 5.1344\nEpoch 3/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5320 - loss: 1.5422 - val_accuracy: 0.4633 - val_loss: 1.6861\nEpoch 4/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5582 - loss: 1.4145 - val_accuracy: 0.5268 - val_loss: 1.5341\nEpoch 5/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5727 - loss: 1.3764 - val_accuracy: 0.2903 - val_loss: 3.5689\nEpoch 6/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5805 - loss: 1.3355 - val_accuracy: 0.4806 - val_loss: 1.6911\nEpoch 7/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5950 - loss: 1.2923 - val_accuracy: 0.4801 - val_loss: 1.6322\nEpoch 8/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6170 - loss: 1.2439 - val_accuracy: 0.4572 - val_loss: 1.6429\nEpoch 9/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6266 - loss: 1.1943 - val_accuracy: 0.5595 - val_loss: 1.3965\nEpoch 10/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6277 - loss: 1.1743 - val_accuracy: 0.5481 - val_loss: 1.4879\nEpoch 11/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6416 - loss: 1.1331 - val_accuracy: 0.5410 - val_loss: 1.4167\nEpoch 12/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6677 - loss: 1.0717 - val_accuracy: 0.5227 - val_loss: 1.7542\nEpoch 13/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6955 - loss: 0.9829 - val_accuracy: 0.5197 - val_loss: 1.5602\nEpoch 14/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7171 - loss: 0.8836 - val_accuracy: 0.6273 - val_loss: 1.2230\nEpoch 15/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7157 - loss: 0.8646 - val_accuracy: 0.4961 - val_loss: 2.1985\nEpoch 16/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7384 - loss: 0.7962 - val_accuracy: 0.6562 - val_loss: 1.0910\nEpoch 17/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7502 - loss: 0.7773 - val_accuracy: 0.6686 - val_loss: 1.0816\nEpoch 18/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7577 - loss: 0.7627 - val_accuracy: 0.5732 - val_loss: 1.7571\nEpoch 19/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7648 - loss: 0.7247 - val_accuracy: 0.6572 - val_loss: 1.0907\nEpoch 20/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7773 - loss: 0.6929 - val_accuracy: 0.6559 - val_loss: 1.1747\nEpoch 21/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7709 - loss: 0.6917 - val_accuracy: 0.6826 - val_loss: 1.0380\nEpoch 22/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7797 - loss: 0.6653 - val_accuracy: 0.5808 - val_loss: 1.5289\nEpoch 23/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7845 - loss: 0.6491 - val_accuracy: 0.6828 - val_loss: 1.1123\nEpoch 24/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7746 - loss: 0.6629 - val_accuracy: 0.5422 - val_loss: 1.7813\nEpoch 25/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7843 - loss: 0.6421 - val_accuracy: 0.7077 - val_loss: 0.9190\nEpoch 26/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7921 - loss: 0.6194 - val_accuracy: 0.5113 - val_loss: 1.8594\nEpoch 27/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7941 - loss: 0.6159 - val_accuracy: 0.4994 - val_loss: 1.9548\nEpoch 28/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7915 - loss: 0.6216 - val_accuracy: 0.6950 - val_loss: 1.0927\nEpoch 29/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7955 - loss: 0.5984 - val_accuracy: 0.6960 - val_loss: 0.9986\nEpoch 30/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7989 - loss: 0.5846 - val_accuracy: 0.6597 - val_loss: 1.4022\nEpoch 31/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8089 - loss: 0.5689 - val_accuracy: 0.5443 - val_loss: 2.2635\nEpoch 32/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8067 - loss: 0.5604 - val_accuracy: 0.7044 - val_loss: 0.9380\nEpoch 33/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8052 - loss: 0.5668 - val_accuracy: 0.6953 - val_loss: 1.0219\nEpoch 34/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8108 - loss: 0.5453 - val_accuracy: 0.5699 - val_loss: 1.8584\nEpoch 35/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8095 - loss: 0.5525 - val_accuracy: 0.6762 - val_loss: 1.0538\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6979 - loss: 0.9950\nSpectral + Vegetation Indices + DEM Test Accuracy: 0.6940\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n\nSummary of Results:\nSpectral Bands Only: Test Accuracy = 0.7062, Test Loss = 1.0451\nSpectral + Vegetation Indices: Test Accuracy = 0.7016, Test Loss = 1.0728\nSpectral + DEM: Test Accuracy = 0.7272, Test Loss = 0.7810\nSpectral + Vegetation Indices + DEM: Test Accuracy = 0.6940, Test Loss = 0.9815\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.metrics import precision_recall_fscore_support, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport json\n\n# 11. Compute Additional Metrics\nextended_results = {}\nfor combo_name, (indices, num_channels, description) in feature_combinations.items():\n    print(f\"\\nComputing additional metrics for {description} ({num_channels} channels)\")\n    \n    # Load the best model\n    model = models.load_model(f'best_model_{combo_name}.keras')\n    \n    # Get test data for this combination\n    X_subset = X[:, :, :, indices]\n    X_train, X_test, y_train, y_test = train_test_split(X_subset, y_onehot, test_size=0.15, random_state=42, stratify=y_onehot)\n    \n    # Predict on test set\n    y_pred = model.predict(X_test)\n    y_pred_classes = np.argmax(y_pred, axis=1)\n    y_test_classes = np.argmax(y_test, axis=1)\n    \n    # Compute precision, recall, F1-score (macro-averaged)\n    precision, recall, f1, _ = precision_recall_fscore_support(y_test_classes, y_pred_classes, average='macro')\n    \n    # Compute per-class accuracy from confusion matrix\n    cm = confusion_matrix(y_test_classes, y_pred_classes)\n    per_class_accuracy = cm.diagonal() / cm.sum(axis=1)\n    per_class_accuracy_dict = {label_encoder.classes_[i]: acc for i, acc in enumerate(per_class_accuracy)}\n    \n    # Store extended results\n    extended_results[combo_name] = {\n        'description': description,\n        'test_accuracy': results[combo_name]['test_accuracy'],\n        'test_loss': results[combo_name]['test_loss'],\n        'precision': precision,\n        'recall': recall,\n        'f1_score': f1,\n        'per_class_accuracy': per_class_accuracy_dict\n    }\n    \n    # Print metrics\n    print(f\"{description}:\")\n    print(f\"  Test Accuracy: {extended_results[combo_name]['test_accuracy']:.4f}\")\n    print(f\"  Test Loss: {extended_results[combo_name]['test_loss']:.4f}\")\n    print(f\"  Precision (macro): {precision:.4f}\")\n    print(f\"  Recall (macro): {recall:.4f}\")\n    print(f\"  F1-Score (macro): {f1:.4f}\")\n    print(f\"  Per-Class Accuracy: {per_class_accuracy_dict}\")\n\n# 12. Summarize Metrics in a Table\nmetrics_df = pd.DataFrame({\n    'Feature Combination': [extended_results[combo]['description'] for combo in extended_results],\n    'Test Accuracy': [extended_results[combo]['test_accuracy'] for combo in extended_results],\n    'Test Loss': [extended_results[combo]['test_loss'] for combo in extended_results],\n    'Precision': [extended_results[combo]['precision'] for combo in extended_results],\n    'Recall': [extended_results[combo]['recall'] for combo in extended_results],\n    'F1-Score': [extended_results[combo]['f1_score'] for combo in extended_results]\n})\nprint(\"\\nMetrics Summary Table:\")\nprint(metrics_df.to_string(index=False))\n\n# Save metrics table to CSV\nmetrics_df.to_csv('metrics_summary.csv', index=False)\n\n# 13. Plot Per-Class Accuracies\nplt.figure(figsize=(12, 8))\nfor combo_name, result in extended_results.items():\n    per_class_acc = result['per_class_accuracy']\n    plt.plot(list(per_class_acc.keys()), list(per_class_acc.values()), marker='o', label=result['description'])\nplt.xlabel('Class')\nplt.ylabel('Per-Class Accuracy')\nplt.title('Per-Class Accuracy by Feature Combination')\nplt.legend()\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.savefig('per_class_accuracy.png')\nplt.close()\n\n# 14. Save Extended Results\nwith open('extended_results_summary.json', 'w') as f:\n    json.dump({k: {kk: vv for kk, vv in v.items() if kk != 'history'} for k, v in extended_results.items()}, f, indent=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T08:57:22.370649Z","iopub.execute_input":"2025-06-26T08:57:22.370952Z","iopub.status.idle":"2025-06-26T08:57:33.264424Z","shell.execute_reply.started":"2025-06-26T08:57:22.370929Z","shell.execute_reply":"2025-06-26T08:57:33.263626Z"}},"outputs":[{"name":"stdout","text":"\nComputing additional metrics for Spectral Bands Only (96 channels)\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\nSpectral Bands Only:\n  Test Accuracy: 0.7062\n  Test Loss: 1.0451\n  Precision (macro): 0.7076\n  Recall (macro): 0.5595\n  F1-Score (macro): 0.5479\n  Per-Class Accuracy: {'alder': 0.825531914893617, 'birch': 0.7418032786885246, 'black pine': 0.23404255319148937, 'cherry': 0.043478260869565216, 'douglas fir': 0.7108433734939759, 'english oak': 0.8167202572347267, 'european ash': 0.5, 'european beech': 0.890625, 'european larch': 0.5641025641025641, 'japanese larch': 0.9090909090909091, 'linden': 0.05263157894736842, 'norway spruce': 0.8412017167381974, 'poplar': 0.06818181818181818, 'red oak': 0.33532934131736525, 'scots pine': 0.809076682316119, 'sessile oak': 0.7574257425742574, 'silver fir': 0.5866666666666667, 'sycamore maple': 0.07920792079207921, 'weymouth pine': 0.8636363636363636}\n\nComputing additional metrics for Spectral + Vegetation Indices (136 channels)\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\nSpectral + Vegetation Indices:\n  Test Accuracy: 0.7016\n  Test Loss: 1.0728\n  Precision (macro): 0.6379\n  Recall (macro): 0.5307\n  F1-Score (macro): 0.5302\n  Per-Class Accuracy: {'alder': 0.40425531914893614, 'birch': 0.5327868852459017, 'black pine': 0.23404255319148937, 'cherry': 0.0, 'douglas fir': 0.8554216867469879, 'english oak': 0.8231511254019293, 'european ash': 0.26126126126126126, 'european beech': 0.8928571428571429, 'european larch': 0.17094017094017094, 'japanese larch': 0.5272727272727272, 'linden': 0.0, 'norway spruce': 0.8433476394849786, 'poplar': 0.06818181818181818, 'red oak': 0.8383233532934131, 'scots pine': 0.9045383411580594, 'sessile oak': 0.8366336633663366, 'silver fir': 0.5733333333333334, 'sycamore maple': 0.6039603960396039, 'weymouth pine': 0.7121212121212122}\n\nComputing additional metrics for Spectral + DEM (104 channels)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\nSpectral + DEM:\n  Test Accuracy: 0.7272\n  Test Loss: 0.7810\n  Precision (macro): 0.6598\n  Recall (macro): 0.5745\n  F1-Score (macro): 0.5860\n  Per-Class Accuracy: {'alder': 0.6127659574468085, 'birch': 0.4262295081967213, 'black pine': 0.3404255319148936, 'cherry': 0.043478260869565216, 'douglas fir': 0.8433734939759037, 'english oak': 0.8520900321543409, 'european ash': 0.6666666666666666, 'european beech': 0.8928571428571429, 'european larch': 0.717948717948718, 'japanese larch': 0.703030303030303, 'linden': 0.0, 'norway spruce': 0.9377682403433476, 'poplar': 0.1590909090909091, 'red oak': 0.592814371257485, 'scots pine': 0.8591549295774648, 'sessile oak': 0.6534653465346535, 'silver fir': 0.7866666666666666, 'sycamore maple': 0.297029702970297, 'weymouth pine': 0.5303030303030303}\n\nComputing additional metrics for Spectral + Vegetation Indices + DEM (144 channels)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\nSpectral + Vegetation Indices + DEM:\n  Test Accuracy: 0.6940\n  Test Loss: 0.9815\n  Precision (macro): 0.6980\n  Recall (macro): 0.5995\n  F1-Score (macro): 0.5870\n  Per-Class Accuracy: {'alder': 0.7148936170212766, 'birch': 0.6680327868852459, 'black pine': 0.19148936170212766, 'cherry': 0.08695652173913043, 'douglas fir': 0.5863453815261044, 'english oak': 0.8778135048231511, 'european ash': 0.3333333333333333, 'european beech': 0.8348214285714286, 'european larch': 0.38461538461538464, 'japanese larch': 0.8181818181818182, 'linden': 0.05263157894736842, 'norway spruce': 0.6759656652360515, 'poplar': 0.5227272727272727, 'red oak': 0.6107784431137725, 'scots pine': 0.7464788732394366, 'sessile oak': 0.905940594059406, 'silver fir': 0.8666666666666667, 'sycamore maple': 0.5891089108910891, 'weymouth pine': 0.9242424242424242}\n\nMetrics Summary Table:\n                Feature Combination  Test Accuracy  Test Loss  Precision   Recall  F1-Score\n                Spectral Bands Only       0.706166   1.045080   0.707609 0.559452  0.547914\n      Spectral + Vegetation Indices       0.701599   1.072763   0.637879 0.530654  0.530169\n                     Spectral + DEM       0.727227   0.781049   0.659822 0.574482  0.586047\nSpectral + Vegetation Indices + DEM       0.693986   0.981466   0.697977 0.599528  0.587020\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras import layers, models\nimport joblib\nfrom sklearn.metrics import precision_recall_fscore_support, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport json\n\n# 2. Handle NaN Values\nprint(\"\\nChecking for NaN values...\")\nnan_mask = np.any(np.isnan(X), axis=(1, 2, 3))\nnan_count = np.sum(nan_mask)\nprint(f\"Found {nan_count} samples with NaN values\")\nif nan_count > 0:\n    print(f\"Removing {nan_count} samples with NaN values\")\n    valid_mask = ~nan_mask\n    X = X[valid_mask]\n    y = y[valid_mask]\n    print(f\"New data shape after removing NaN: {X.shape}\")\n\n# 3. Normalize Data\nprint(\"\\nNormalizing data...\")\nX_min = np.nanmin(X, axis=(0, 1, 2), keepdims=True)\nX_max = np.nanmax(X, axis=(0, 1, 2), keepdims=True)\nX = (X - X_min) / (X_max - X_min + 1e-6)  # Min-max normalization to [0, 1]\nprint(f\"Data range after normalization: min={np.nanmin(X):.4f}, max={np.nanmax(X):.4f}\")\n\n# 4. Preprocess Labels\nlabel_encoder = LabelEncoder()\ny_encoded = label_encoder.fit_transform(y)\ny_onehot = tf.keras.utils.to_categorical(y_encoded)\nnum_classes = len(label_encoder.classes_)\nprint(f\"\\nData shape: {X.shape}, Number of classes: {num_classes}\")\n\n# 5. Define Feature Combination (Spectral + Selected Indices + DEM)\nbands = ['ARVI', 'B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12', 'DEM', 'EVI', 'EVI2', 'NDVI', 'NDWI']\nmonths = ['', '_1', '_2', '_3', '_4', '_5', '_6', '_7']\nband_columns = [band + month for month in months for band in bands]  # 18 bands × 8 months = 144 channels\n\nspectral_bands = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12']  # 12 bands\nveg_indices = ['NDVI', 'EVI', 'SAVI', 'NDWI']  # 4 important indices\ndem_band = ['DEM']  # 1 band\n\n# Create and verify channel indices\nspectral_indices = [i for i, col in enumerate(band_columns) if any(col.startswith(band) for band in spectral_bands)]  # 12 × 8 = 96 channels\nveg_indices_indices = [i for i, col in enumerate(band_columns) if any(col.startswith(band) for band in veg_indices)]  # 4 × 8 = 32 channels\ndem_indices = [i for i, col in enumerate(band_columns) if col.startswith('DEM')]  # 1 × 8 = 8 channels\n\n# Combine for single feature set\nfeature_indices = spectral_indices + veg_indices_indices + dem_indices\nnum_channels = 96 + 32 + 8  # 136 channels\ndescription = 'Spectral + Selected Indices + DEM'\n\n# Debug channel indices\nprint(\"\\nDebugging channel indices:\")\nprint(f\"Spectral indices ({len(spectral_indices)}): {[band_columns[i] for i in spectral_indices]}\")\nprint(f\"Vegetation indices ({len(veg_indices_indices)}): {[band_columns[i] for i in veg_indices_indices]}\")\nprint(f\"DEM indices ({len(dem_indices)}): {[band_columns[i] for i in dem_indices]}\")\nprint(f\"Combined indices ({len(feature_indices)}): {[band_columns[i] for i in feature_indices]}\")\n\n# Verify expected channel counts\nexpected_veg_channels = 4 * len(months)  # 4 bands × 8 months\nif len(veg_indices_indices) != expected_veg_channels:\n    print(f\"Warning: Expected {expected_veg_channels} vegetation indices channels, got {len(veg_indices_indices)}\")\n    missing_veg_bands = [band for band in veg_indices if not any(col.startswith(band) for col in band_columns)]\n    print(f\"Missing vegetation indices: {missing_veg_bands}\")\n\n# 6. Define CNN Model\ndef build_cnn(input_shape, num_classes):\n    model = models.Sequential([\n        layers.Input(shape=input_shape),\n        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n        layers.BatchNormalization(),\n        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D((2, 2)),\n        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n        layers.BatchNormalization(),\n        layers.Flatten(),\n        layers.Dense(128, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax')\n    ])\n    return model\n\n# 7. Data Augmentation\ndata_augmentation = tf.keras.Sequential([\n    layers.RandomFlip(\"horizontal_and_vertical\"),\n    layers.RandomRotation(0.2),\n])\n\n# 8. Train and Evaluate Model\nprint(f\"\\nTraining model with {description} ({num_channels} channels)\")\n\n# Select feature subset\nX_subset = X[:, :, :, feature_indices]\nprint(f\"Subset shape: {X_subset.shape}\")\n\n# Verify no NaN in subset\nif np.any(np.isnan(X_subset)):\n    print(f\"Warning: NaN values found in {description} subset\")\n\n# Train-test-validation split\nX_train, X_test, y_train, y_test = train_test_split(X_subset, y_onehot, test_size=0.15, random_state=42, stratify=y_onehot)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1765, random_state=42, stratify=y_train)\n\n# Build and compile model\nmodel = build_cnn(input_shape=(5, 5, num_channels), num_classes=num_classes)\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Train model\nhistory = model.fit(\n    data_augmentation(X_train), y_train,\n    validation_data=(X_val, y_val),\n    epochs=50,\n    batch_size=32,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n        tf.keras.callbacks.ModelCheckpoint('best_model.keras', save_best_only=True)\n    ],\n    verbose=1\n)\n\n# Evaluate model\ntest_loss, test_accuracy = model.evaluate(X_test, y_test)\nprint(f\"{description} Test Accuracy: {test_accuracy:.4f}\")\n\n# Compute additional metrics\ny_pred = model.predict(X_test)\ny_pred_classes = np.argmax(y_pred, axis=1)\ny_test_classes = np.argmax(y_test, axis=1)\n\n# Precision, recall, F1-score (macro-averaged)\nprecision, recall, f1, _ = precision_recall_fscore_support(y_test_classes, y_pred_classes, average='macro')\n\n# Per-class accuracy from confusion matrix\ncm = confusion_matrix(y_test_classes, y_pred_classes)\nper_class_accuracy = cm.diagonal() / cm.sum(axis=1)\nper_class_accuracy_dict = {label_encoder.classes_[i]: acc for i, acc in enumerate(per_class_accuracy)}\n\n# Plot confusion matrix\nplt.figure(figsize=(12, 10))\nsns.heatmap(cm, annot=True, fmt='d', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title(f'Confusion Matrix: {description}')\nplt.savefig('confusion_matrix.png')\nplt.close()\n\n# 9. Summarize Metrics\nmetrics_dict = {\n    'description': description,\n    'test_accuracy': test_accuracy,\n    'test_loss': test_loss,\n    'precision': precision,\n    'recall': recall,\n    'f1_score': f1,\n    'per_class_accuracy': per_class_accuracy_dict\n}\nprint(f\"\\nMetrics Summary:\")\nprint(f\"Description: {description}\")\nprint(f\"Test Accuracy: {test_accuracy:.4f}\")\nprint(f\"Test Loss: {test_loss:.4f}\")\nprint(f\"Precision (macro): {precision:.4f}\")\nprint(f\"Recall (macro): {recall:.4f}\")\nprint(f\"F1-Score (macro): {f1:.4f}\")\nprint(f\"Per-Class Accuracy: {per_class_accuracy_dict}\")\n\n# Save metrics to CSV\nmetrics_df = pd.DataFrame([metrics_dict], columns=['description', 'test_accuracy', 'test_loss', 'precision', 'recall', 'f1_score'])\nmetrics_df.to_csv('metrics_summary.csv', index=False)\n\n# 10. Plot Per-Class Accuracies\nplt.figure(figsize=(12, 8))\nplt.plot(list(per_class_accuracy_dict.keys()), list(per_class_accuracy_dict.values()), marker='o', label=description)\nplt.xlabel('Class')\nplt.ylabel('Per-Class Accuracy')\nplt.title('Per-Class Accuracy')\nplt.legend()\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.savefig('per_class_accuracy.png')\nplt.close()\n\n# Save results\nwith open('results_summary.json', 'w') as f:\n    json.dump({k: v for k, v in metrics_dict.items() if k != 'history'}, f, indent=4)\n\n# Save label encoder\njoblib.dump(label_encoder, 'label_encoder.pkl')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T08:57:41.144203Z","iopub.execute_input":"2025-06-26T08:57:41.144929Z","iopub.status.idle":"2025-06-26T08:59:08.603335Z","shell.execute_reply.started":"2025-06-26T08:57:41.144902Z","shell.execute_reply":"2025-06-26T08:59:08.602561Z"}},"outputs":[{"name":"stdout","text":"\nChecking for NaN values...\nFound 0 samples with NaN values\n\nNormalizing data...\nData range after normalization: min=0.0000, max=1.0000\n\nData shape: (26268, 5, 5, 144), Number of classes: 19\n\nDebugging channel indices:\nSpectral indices (96): ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12', 'B1_1', 'B2_1', 'B3_1', 'B4_1', 'B5_1', 'B6_1', 'B7_1', 'B8_1', 'B8A_1', 'B9_1', 'B11_1', 'B12_1', 'B1_2', 'B2_2', 'B3_2', 'B4_2', 'B5_2', 'B6_2', 'B7_2', 'B8_2', 'B8A_2', 'B9_2', 'B11_2', 'B12_2', 'B1_3', 'B2_3', 'B3_3', 'B4_3', 'B5_3', 'B6_3', 'B7_3', 'B8_3', 'B8A_3', 'B9_3', 'B11_3', 'B12_3', 'B1_4', 'B2_4', 'B3_4', 'B4_4', 'B5_4', 'B6_4', 'B7_4', 'B8_4', 'B8A_4', 'B9_4', 'B11_4', 'B12_4', 'B1_5', 'B2_5', 'B3_5', 'B4_5', 'B5_5', 'B6_5', 'B7_5', 'B8_5', 'B8A_5', 'B9_5', 'B11_5', 'B12_5', 'B1_6', 'B2_6', 'B3_6', 'B4_6', 'B5_6', 'B6_6', 'B7_6', 'B8_6', 'B8A_6', 'B9_6', 'B11_6', 'B12_6', 'B1_7', 'B2_7', 'B3_7', 'B4_7', 'B5_7', 'B6_7', 'B7_7', 'B8_7', 'B8A_7', 'B9_7', 'B11_7', 'B12_7']\nVegetation indices (32): ['EVI', 'EVI2', 'NDVI', 'NDWI', 'EVI_1', 'EVI2_1', 'NDVI_1', 'NDWI_1', 'EVI_2', 'EVI2_2', 'NDVI_2', 'NDWI_2', 'EVI_3', 'EVI2_3', 'NDVI_3', 'NDWI_3', 'EVI_4', 'EVI2_4', 'NDVI_4', 'NDWI_4', 'EVI_5', 'EVI2_5', 'NDVI_5', 'NDWI_5', 'EVI_6', 'EVI2_6', 'NDVI_6', 'NDWI_6', 'EVI_7', 'EVI2_7', 'NDVI_7', 'NDWI_7']\nDEM indices (8): ['DEM', 'DEM_1', 'DEM_2', 'DEM_3', 'DEM_4', 'DEM_5', 'DEM_6', 'DEM_7']\nCombined indices (136): ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12', 'B1_1', 'B2_1', 'B3_1', 'B4_1', 'B5_1', 'B6_1', 'B7_1', 'B8_1', 'B8A_1', 'B9_1', 'B11_1', 'B12_1', 'B1_2', 'B2_2', 'B3_2', 'B4_2', 'B5_2', 'B6_2', 'B7_2', 'B8_2', 'B8A_2', 'B9_2', 'B11_2', 'B12_2', 'B1_3', 'B2_3', 'B3_3', 'B4_3', 'B5_3', 'B6_3', 'B7_3', 'B8_3', 'B8A_3', 'B9_3', 'B11_3', 'B12_3', 'B1_4', 'B2_4', 'B3_4', 'B4_4', 'B5_4', 'B6_4', 'B7_4', 'B8_4', 'B8A_4', 'B9_4', 'B11_4', 'B12_4', 'B1_5', 'B2_5', 'B3_5', 'B4_5', 'B5_5', 'B6_5', 'B7_5', 'B8_5', 'B8A_5', 'B9_5', 'B11_5', 'B12_5', 'B1_6', 'B2_6', 'B3_6', 'B4_6', 'B5_6', 'B6_6', 'B7_6', 'B8_6', 'B8A_6', 'B9_6', 'B11_6', 'B12_6', 'B1_7', 'B2_7', 'B3_7', 'B4_7', 'B5_7', 'B6_7', 'B7_7', 'B8_7', 'B8A_7', 'B9_7', 'B11_7', 'B12_7', 'EVI', 'EVI2', 'NDVI', 'NDWI', 'EVI_1', 'EVI2_1', 'NDVI_1', 'NDWI_1', 'EVI_2', 'EVI2_2', 'NDVI_2', 'NDWI_2', 'EVI_3', 'EVI2_3', 'NDVI_3', 'NDWI_3', 'EVI_4', 'EVI2_4', 'NDVI_4', 'NDWI_4', 'EVI_5', 'EVI2_5', 'NDVI_5', 'NDWI_5', 'EVI_6', 'EVI2_6', 'NDVI_6', 'NDWI_6', 'EVI_7', 'EVI2_7', 'NDVI_7', 'NDWI_7', 'DEM', 'DEM_1', 'DEM_2', 'DEM_3', 'DEM_4', 'DEM_5', 'DEM_6', 'DEM_7']\n\nTraining model with Spectral + Selected Indices + DEM (136 channels)\nSubset shape: (26268, 5, 5, 136)\nEpoch 1/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.3362 - loss: 2.2050 - val_accuracy: 0.2403 - val_loss: 2.8641\nEpoch 2/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4587 - loss: 1.7548 - val_accuracy: 0.3088 - val_loss: 2.1098\nEpoch 3/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5034 - loss: 1.5901 - val_accuracy: 0.3979 - val_loss: 1.9382\nEpoch 4/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5415 - loss: 1.4886 - val_accuracy: 0.4938 - val_loss: 1.6648\nEpoch 5/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5567 - loss: 1.4212 - val_accuracy: 0.3705 - val_loss: 3.0800\nEpoch 6/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5728 - loss: 1.3817 - val_accuracy: 0.5105 - val_loss: 1.6570\nEpoch 7/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5906 - loss: 1.3354 - val_accuracy: 0.4859 - val_loss: 1.6502\nEpoch 8/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5961 - loss: 1.3041 - val_accuracy: 0.4930 - val_loss: 1.7815\nEpoch 9/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6188 - loss: 1.2438 - val_accuracy: 0.4430 - val_loss: 2.0165\nEpoch 10/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6092 - loss: 1.2432 - val_accuracy: 0.5440 - val_loss: 1.5225\nEpoch 11/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6394 - loss: 1.1606 - val_accuracy: 0.5872 - val_loss: 1.4243\nEpoch 12/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6575 - loss: 1.1022 - val_accuracy: 0.5049 - val_loss: 1.5221\nEpoch 13/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6825 - loss: 1.0083 - val_accuracy: 0.5197 - val_loss: 1.6378\nEpoch 14/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7104 - loss: 0.9250 - val_accuracy: 0.4994 - val_loss: 1.7567\nEpoch 15/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7181 - loss: 0.8699 - val_accuracy: 0.4760 - val_loss: 3.2365\nEpoch 16/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7333 - loss: 0.8204 - val_accuracy: 0.5329 - val_loss: 1.6554\nEpoch 17/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7440 - loss: 0.7959 - val_accuracy: 0.4798 - val_loss: 2.2952\nEpoch 18/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7519 - loss: 0.7567 - val_accuracy: 0.4732 - val_loss: 2.0366\nEpoch 19/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7595 - loss: 0.7313 - val_accuracy: 0.6148 - val_loss: 1.5055\nEpoch 20/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7633 - loss: 0.7198 - val_accuracy: 0.6191 - val_loss: 1.5083\nEpoch 21/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7669 - loss: 0.7000 - val_accuracy: 0.6912 - val_loss: 0.9415\nEpoch 22/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7655 - loss: 0.6926 - val_accuracy: 0.6511 - val_loss: 1.2025\nEpoch 23/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7708 - loss: 0.6927 - val_accuracy: 0.5867 - val_loss: 1.3088\nEpoch 24/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7669 - loss: 0.6870 - val_accuracy: 0.6394 - val_loss: 1.2168\nEpoch 25/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7775 - loss: 0.6592 - val_accuracy: 0.6207 - val_loss: 1.4152\nEpoch 26/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7569 - loss: 0.7258 - val_accuracy: 0.6600 - val_loss: 1.0609\nEpoch 27/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7552 - loss: 0.7430 - val_accuracy: 0.7409 - val_loss: 0.8213\nEpoch 28/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7759 - loss: 0.6675 - val_accuracy: 0.6777 - val_loss: 1.0266\nEpoch 29/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7716 - loss: 0.6828 - val_accuracy: 0.5590 - val_loss: 1.6287\nEpoch 30/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7796 - loss: 0.6621 - val_accuracy: 0.7216 - val_loss: 0.8639\nEpoch 31/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7782 - loss: 0.6493 - val_accuracy: 0.5633 - val_loss: 2.2813\nEpoch 32/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7867 - loss: 0.6386 - val_accuracy: 0.7084 - val_loss: 0.9523\nEpoch 33/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7918 - loss: 0.6238 - val_accuracy: 0.5801 - val_loss: 1.5942\nEpoch 34/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7879 - loss: 0.6194 - val_accuracy: 0.7039 - val_loss: 0.9376\nEpoch 35/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7920 - loss: 0.6041 - val_accuracy: 0.4443 - val_loss: 3.6438\nEpoch 36/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7968 - loss: 0.5981 - val_accuracy: 0.4329 - val_loss: 3.1246\nEpoch 37/50\n\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8013 - loss: 0.5854 - val_accuracy: 0.4037 - val_loss: 4.2747\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7210 - loss: 0.8501\nSpectral + Selected Indices + DEM Test Accuracy: 0.7300\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","output_type":"stream"},{"name":"stdout","text":"\nMetrics Summary:\nDescription: Spectral + Selected Indices + DEM\nTest Accuracy: 0.7300\nTest Loss: 0.8198\nPrecision (macro): 0.6698\nRecall (macro): 0.5821\nF1-Score (macro): 0.5893\nPer-Class Accuracy: {'alder': 0.8042553191489362, 'birch': 0.5081967213114754, 'black pine': 0.0851063829787234, 'cherry': 0.0, 'douglas fir': 0.8353413654618473, 'english oak': 0.8167202572347267, 'european ash': 0.6171171171171171, 'european beech': 0.890625, 'european larch': 0.6752136752136753, 'japanese larch': 0.5515151515151515, 'linden': 0.10526315789473684, 'norway spruce': 0.8583690987124464, 'poplar': 0.5227272727272727, 'red oak': 0.5209580838323353, 'scots pine': 0.8435054773082942, 'sessile oak': 0.9108910891089109, 'silver fir': 0.8, 'sycamore maple': 0.36633663366336633, 'weymouth pine': 0.3484848484848485}\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"['label_encoder.pkl']"},"metadata":{}}],"execution_count":6}]}