{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12314462,"sourceType":"datasetVersion","datasetId":7762074},{"sourceId":12314475,"sourceType":"datasetVersion","datasetId":7762081},{"sourceId":12314487,"sourceType":"datasetVersion","datasetId":7762088},{"sourceId":12314500,"sourceType":"datasetVersion","datasetId":7762093}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras import layers, models\nimport geopandas as gpd\nimport ast\nimport os\nimport json\nimport joblib\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# 1. Define Data Paths and Parameters\npatch_sizes = [1, 5, 9, 13]\npatch_size_folders = [f\"/kaggle/input/treesatai-patch{p}x{p}\" for p in patch_sizes]\n\n# Define bands (as provided, no monthly suffixes based on GeoJSON sample)\nbands = [\n    'B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12',\n    'NDVI', 'EVI', 'SAVI', 'NDWI', 'DEM'\n]\nband_columns = bands  # 17 bands, no monthly data\n\n# 2. Function to Load Data for a Given Patch Size\ndef load_data_for_patch_size(patch_size, folder_path):\n    all_features = []\n    all_labels = []\n    invalid_samples = []\n    # Verify available columns\n    available_columns = None\n    for file in os.listdir(folder_path):\n        if file.endswith(\".geojson\"):\n            gdf = gpd.read_file(os.path.join(folder_path, file))\n            available_columns = [col for col in band_columns if col in gdf.columns]\n            # Debugging: Print sample data for first few rows\n            print(f\"\\nInspecting first 2 rows of {file}:\")\n            for idx in range(min(2, len(gdf))):\n                print(f\"Row {idx}:\")\n                for col in available_columns:\n                    print(f\"  {col}: {gdf[col].iloc[idx]}\")\n                print(f\"  l3_species: {gdf['l3_species'].iloc[idx]}\")\n            break\n    if not available_columns:\n        raise ValueError(f\"No valid GeoJSON files found in {folder_path}\")\n    print(f\"Patch size {patch_size}: Available columns: {available_columns}\")\n    expected_shape = (patch_size, patch_size, len(available_columns))\n\n    # Load all GeoJSON files\n    for file in os.listdir(folder_path):\n        if file.endswith(\".geojson\"):\n            gdf = gpd.read_file(os.path.join(folder_path, file))\n            for idx, row in gdf.iterrows():\n                try:\n                    if row['l3_species'] is None or not isinstance(row['l3_species'], str):\n                        raise ValueError(f\"Invalid label at row {idx}: {row['l3_species']}\")\n                    patches = []\n                    for col in available_columns:\n                        val = row[col]\n                        if val is None:\n                            raise ValueError(f\"Null value for band {col}\")\n                        if isinstance(val, (list, np.ndarray)):\n                            arr = np.array(val, dtype=np.float32).reshape(patch_size, patch_size)\n                        elif isinstance(val, str):\n                            try:\n                                arr = np.array(json.loads(val), dtype=np.float32).reshape(patch_size, patch_size)\n                            except json.JSONDecodeError:\n                                arr = np.array(ast.literal_eval(val), dtype=np.float32).reshape(patch_size, patch_size)\n                        elif isinstance(val, (float, np.float32, np.float64)):\n                            arr = np.full((patch_size, patch_size), val, dtype=np.float32)\n                        else:\n                            raise ValueError(f\"Unexpected data type for band {col}: {type(val)}\")\n                        patches.append(arr)\n\n                    patch = np.stack(patches, axis=-1)\n                    if patch.shape != expected_shape:\n                        raise ValueError(f\"Unexpected patch shape: {patch.shape}, expected {expected_shape}\")\n                    all_features.append(patch)\n                    all_labels.append(row['l3_species'])\n                except Exception as e:\n                    invalid_samples.append((file, idx, str(e)))\n                    continue\n\n    if invalid_samples:\n        print(f\"\\nPatch size {patch_size}: Skipped {len(invalid_samples)} invalid samples\")\n        for file, idx, error in invalid_samples[:5]:\n            print(f\"File: {file}, Row: {idx}, Error: {error}\")\n        # Save invalid samples to a file for inspection\n        with open(f'invalid_samples_patch_size_{patch_size}.json', 'w') as f:\n            json.dump(invalid_samples, f, indent=4)\n\n    if not all_features:\n        raise ValueError(f\"No valid samples loaded for patch size {patch_size}. Check GeoJSON files.\")\n    X = np.array(all_features, dtype=np.float32)\n    y = np.array(all_labels)\n    print(f\"Patch size {patch_size}: Loaded {len(all_features)} valid samples with shape {X.shape}\")\n    return X, y, invalid_samples, available_columns\n\n# 3. Define CNN Model\ndef build_cnn(input_shape, num_classes):\n    model = models.Sequential([\n        layers.Input(shape=input_shape),\n        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n        layers.BatchNormalization(),\n        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D((2, 2)) if input_shape[0] >= 5 else layers.Lambda(lambda x: x),\n        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n        layers.BatchNormalization(),\n        layers.Flatten(),\n        layers.Dense(128, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax')\n    ])\n    return model\n\n# 4. Data Augmentation\ndef get_data_augmentation(patch_size):\n    if patch_size > 1:\n        return tf.keras.Sequential([\n            layers.RandomFlip(\"horizontal_and_vertical\"),\n            layers.RandomRotation(0.2),\n        ])\n    return lambda x: x  # Identity function for 1x1 patches (no augmentation)\n\n# 5. Train and Evaluate for Each Patch Size\nresults = {}\nlabel_encoder = LabelEncoder()\navailable_columns_dict = {}\n\nfor patch_size, folder_path in zip(patch_sizes, patch_size_folders):\n    print(f\"\\nProcessing patch size: {patch_size}x{patch_size}\")\n    if not os.path.exists(folder_path):\n        print(f\"Folder {folder_path} does not exist.\")\n        continue\n\n    # Load data\n    try:\n        X, y, invalid_samples, available_columns = load_data_for_patch_size(patch_size, folder_path)\n        available_columns_dict[patch_size] = available_columns\n    except Exception as e:\n        print(f\"Error loading data for patch size {patch_size}: {e}\")\n        continue\n\n    # Handle NaN values\n    print(f\"\\nPatch size {patch_size}: Checking for NaN values...\")\n    nan_mask = np.any(np.isnan(X), axis=(1, 2, 3))\n    nan_count = np.sum(nan_mask)\n    if nan_count > 0:\n        print(f\"Patch size {patch_size}: Removing {nan_count} samples with NaN values\")\n        valid_mask = ~nan_mask\n        X = X[valid_mask]\n        y = y[valid_mask]\n        print(f\"Patch size {patch_size}: New data shape after removing NaN: {X.shape}\")\n\n    # Normalize data\n    print(f\"Patch size {patch_size}: Normalizing data...\")\n    X_min = np.nanmin(X, axis=(0, 1, 2), keepdims=True)\n    X_max = np.nanmax(X, axis=(0, 1, 2), keepdims=True)\n    X = (X - X_min) / (X_max - X_min + 1e-6)\n    print(f\"Patch size {patch_size}: Data range after normalization: min={np.nanmin(X):.4f}, max={np.nanmax(X):.4f}\")\n\n    # Encode labels\n    try:\n        if not results:\n            y_encoded = label_encoder.fit_transform(y)\n        else:\n            y_encoded = label_encoder.transform(y)\n        y_onehot = tf.keras.utils.to_categorical(y_encoded)\n        num_classes = len(label_encoder.classes_)\n        print(f\"Patch size {patch_size}: Data shape: {X.shape}, Number of classes: {num_classes}\")\n    except Exception as e:\n        print(f\"Error encoding labels for patch size {patch_size}: {e}\")\n        continue\n\n    # Train-test-validation split\n    try:\n        X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=0.15, random_state=42, stratify=y_onehot)\n        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1765, random_state=42, stratify=y_train)\n        print(f\"Patch size {patch_size}: Train shape: {X_train.shape}, Validation shape: {X_val.shape}, Test shape: {X_test.shape}\")\n    except Exception as e:\n        print(f\"Error splitting data for patch size {patch_size}: {e}\")\n        continue\n\n    # Build and compile model\n    try:\n        model = build_cnn(input_shape=(patch_size, patch_size, len(available_columns)), num_classes=num_classes)\n        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    except Exception as e:\n        print(f\"Error building model for patch size {patch_size}: {e}\")\n        continue\n\n    # Train model\n    try:\n        history = model.fit(\n            get_data_augmentation(patch_size)(X_train), y_train,\n            validation_data=(X_val, y_val),\n            epochs=50,\n            batch_size=16,  # Reduced to mitigate memory issues\n            callbacks=[\n                tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n                tf.keras.callbacks.ModelCheckpoint(f'best_model_patch_size_{patch_size}.keras', save_best_only=True)\n            ],\n            verbose=1\n        )\n    except Exception as e:\n        print(f\"Error training model for patch size {patch_size}: {e}\")\n        continue\n\n    # Evaluate model\n    try:\n        test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n        print(f\"Patch size {patch_size}: Test Accuracy: {test_accuracy:.4f}, Test Loss: {test_loss:.4f}\")\n\n        # Compute additional metrics\n        y_pred = model.predict(X_test, verbose=0)\n        y_pred_classes = np.argmax(y_pred, axis=1)\n        y_test_classes = np.argmax(y_test, axis=1)\n\n        # Classification report (precision, recall, F1-score)\n        class_report = classification_report(y_test_classes, y_pred_classes, target_names=label_encoder.classes_, output_dict=True)\n        print(f\"\\nPatch size {patch_size}: Classification Report:\")\n        print(classification_report(y_test_classes, y_pred_classes, target_names=label_encoder.classes_))\n\n        # Confusion matrix\n        cm = confusion_matrix(y_test_classes, y_pred_classes)\n        plt.figure(figsize=(12, 10))\n        sns.heatmap(cm, annot=True, fmt='d', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n        plt.xlabel('Predicted')\n        plt.ylabel('True')\n        plt.title(f'Confusion Matrix: Patch Size {patch_size}x{patch_size}')\n        plt.savefig(f'confusion_matrix_patch_size_{patch_size}.png')\n        plt.close()\n\n        # Store results\n        results[f'patch_size_{patch_size}'] = {\n            'patch_size': patch_size,\n            'test_accuracy': test_accuracy,\n            'test_loss': test_loss,\n            'classification_report': class_report,\n            'history': history.history\n        }\n    except Exception as e:\n        print(f\"Error evaluating model for patch size {patch_size}: {e}\")\n        continue\n\n# 6. Compare Results\nprint(\"\\nSummary of Results:\")\nfor key, result in results.items():\n    print(f\"\\nPatch Size {result['patch_size']}x{result['patch_size']}:\")\n    print(f\"  Test Accuracy: {result['test_accuracy']:.4f}\")\n    print(f\"  Test Loss: {result['test_loss']:.4f}\")\n    print(f\"  Weighted Precision: {result['classification_report']['weighted avg']['precision']:.4f}\")\n    print(f\"  Weighted Recall: {result['classification_report']['weighted avg']['recall']:.4f}\")\n    print(f\"  Weighted F1-Score: {result['classification_report']['weighted avg']['f1-score']:.4f}\")\n    print(f\"  Macro Precision: {result['classification_report']['macro avg']['precision']:.4f}\")\n    print(f\"  Macro Recall: {result['classification_report']['macro avg']['recall']:.4f}\")\n    print(f\"  Macro F1-Score: {result['classification_report']['macro avg']['f1-score']:.4f}\")\n\n# Plot accuracy comparison\nplt.figure(figsize=(10, 6))\naccuracies = [results[key]['test_accuracy'] for key in results]\npatch_size_labels = [f\"{results[key]['patch_size']}x{results[key]['patch_size']}\" for key in results]\nplt.bar(patch_size_labels, accuracies)\nplt.xlabel('Patch Size')\nplt.ylabel('Test Accuracy')\nplt.title('Test Accuracy by Patch Size')\nplt.tight_layout()\nplt.savefig('accuracy_comparison_patch_sizes.png')\nplt.close()\n\n# Plot weighted F1-score comparison\nplt.figure(figsize=(10, 6))\nf1_scores = [results[key]['classification_report']['weighted avg']['f1-score'] for key in results]\nplt.bar(patch_size_labels, f1_scores)\nplt.xlabel('Patch Size')\nplt.ylabel('Weighted F1-Score')\nplt.title('Weighted F1-Score by Patch Size')\nplt.tight_layout()\nplt.savefig('f1_score_comparison_patch_sizes.png')\nplt.close()\n\n# 7. Save Label Encoder and Results\njoblib.dump(label_encoder, 'label_encoder.pkl')\nwith open('results_summary_patch_sizes.json', 'w') as f:\n    json.dump({k: {kk: vv for kk, vv in v.items() if kk != 'history'} for k, v in results.items()}, f, indent=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-28T21:50:48.317715Z","iopub.execute_input":"2025-06-28T21:50:48.318456Z","iopub.status.idle":"2025-06-28T21:58:25.881454Z","shell.execute_reply.started":"2025-06-28T21:50:48.318429Z","shell.execute_reply":"2025-06-28T21:58:25.880824Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"\nProcessing patch size: 1x1\n\nInspecting first 2 rows of needleleaf_douglas fir_douglas fir_Patch1x1_2022-07.geojson:\nRow 0:\n  B1: None\n  B2: None\n  B3: None\n  B4: None\n  B5: None\n  B6: None\n  B7: None\n  B8: None\n  B8A: None\n  B9: None\n  B11: None\n  B12: None\n  NDVI: None\n  EVI: None\n  SAVI: None\n  NDWI: None\n  DEM: None\n  l3_species: douglas fir\nRow 1:\n  B1: [[0.1298000067472458]]\n  B2: [[0.12809999287128448]]\n  B3: [[0.1462000012397766]]\n  B4: [[0.13349999487400055]]\n  B5: [[0.17399999499320984]]\n  B6: [[0.3084999918937683]]\n  B7: [[0.3635999858379364]]\n  B8: [[0.38960000872612]]\n  B8A: [[0.3939000070095062]]\n  B9: [[0.3813999891281128]]\n  B11: [[0.24650000035762787]]\n  B12: [[0.16859999299049377]]\n  NDVI: [[0.4895813763141632]]\n  EVI: [[0.5205919569583571]]\n  SAVI: [[0.3754765119992361]]\n  NDWI: [[0.22496463358402252]]\n  DEM: [[96.0]]\n  l3_species: douglas fir\nPatch size 1: Available columns: ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12', 'NDVI', 'EVI', 'SAVI', 'NDWI', 'DEM']\n\nPatch size 1: Skipped 25577 invalid samples\nFile: needleleaf_douglas fir_douglas fir_Patch1x1_2022-07.geojson, Row: 0, Error: Null value for band B1\nFile: needleleaf_douglas fir_douglas fir_Patch1x1_2022-07.geojson, Row: 2, Error: Null value for band B1\nFile: needleleaf_douglas fir_douglas fir_Patch1x1_2022-07.geojson, Row: 5, Error: Null value for band B1\nFile: needleleaf_douglas fir_douglas fir_Patch1x1_2022-07.geojson, Row: 6, Error: Null value for band B1\nFile: needleleaf_douglas fir_douglas fir_Patch1x1_2022-07.geojson, Row: 7, Error: Null value for band B1\nPatch size 1: Loaded 12330 valid samples with shape (12330, 1, 1, 17)\n\nPatch size 1: Checking for NaN values...\nPatch size 1: Normalizing data...\nPatch size 1: Data range after normalization: min=0.0000, max=1.0000\nPatch size 1: Data shape: (12330, 1, 1, 17), Number of classes: 19\nPatch size 1: Train shape: (8630, 1, 1, 17), Validation shape: (1850, 1, 1, 17), Test shape: (1850, 1, 1, 17)\nEpoch 1/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.2745 - loss: 2.4883 - val_accuracy: 0.3081 - val_loss: 2.2981\nEpoch 2/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3668 - loss: 2.0325 - val_accuracy: 0.3514 - val_loss: 2.0111\nEpoch 3/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3826 - loss: 1.9502 - val_accuracy: 0.2324 - val_loss: 2.6545\nEpoch 4/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3968 - loss: 1.8741 - val_accuracy: 0.2616 - val_loss: 2.6049\nEpoch 5/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3986 - loss: 1.8807 - val_accuracy: 0.1481 - val_loss: 3.1853\nEpoch 6/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4297 - loss: 1.8076 - val_accuracy: 0.2654 - val_loss: 2.2149\nEpoch 7/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4416 - loss: 1.7724 - val_accuracy: 0.1643 - val_loss: 2.7952\nEpoch 8/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4315 - loss: 1.7821 - val_accuracy: 0.3259 - val_loss: 2.2450\nEpoch 9/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4553 - loss: 1.7348 - val_accuracy: 0.3211 - val_loss: 2.3089\nEpoch 10/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4590 - loss: 1.7086 - val_accuracy: 0.3200 - val_loss: 2.3401\nEpoch 11/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4509 - loss: 1.7224 - val_accuracy: 0.2951 - val_loss: 2.6433\nEpoch 12/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4576 - loss: 1.6875 - val_accuracy: 0.4357 - val_loss: 1.7851\nEpoch 13/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4736 - loss: 1.6733 - val_accuracy: 0.3595 - val_loss: 2.0754\nEpoch 14/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4714 - loss: 1.7017 - val_accuracy: 0.3778 - val_loss: 2.0090\nEpoch 15/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4861 - loss: 1.6571 - val_accuracy: 0.3849 - val_loss: 1.8799\nEpoch 16/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4846 - loss: 1.6341 - val_accuracy: 0.2541 - val_loss: 2.3365\nEpoch 17/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4606 - loss: 1.6729 - val_accuracy: 0.4789 - val_loss: 1.6596\nEpoch 18/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4770 - loss: 1.6611 - val_accuracy: 0.2432 - val_loss: 3.6428\nEpoch 19/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4823 - loss: 1.6262 - val_accuracy: 0.2546 - val_loss: 3.7008\nEpoch 20/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4840 - loss: 1.6282 - val_accuracy: 0.2686 - val_loss: 2.7666\nEpoch 21/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4877 - loss: 1.6270 - val_accuracy: 0.2508 - val_loss: 2.4917\nEpoch 22/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4811 - loss: 1.6306 - val_accuracy: 0.3070 - val_loss: 2.5031\nEpoch 23/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4910 - loss: 1.5971 - val_accuracy: 0.2189 - val_loss: 3.2667\nEpoch 24/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4926 - loss: 1.6145 - val_accuracy: 0.2032 - val_loss: 2.7717\nEpoch 25/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4997 - loss: 1.5889 - val_accuracy: 0.4211 - val_loss: 2.0096\nEpoch 26/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4928 - loss: 1.5913 - val_accuracy: 0.2881 - val_loss: 2.6307\nEpoch 27/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5069 - loss: 1.5663 - val_accuracy: 0.3535 - val_loss: 2.0475\nPatch size 1: Test Accuracy: 0.4714, Test Loss: 1.6745\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"\nPatch size 1: Classification Report:\n                precision    recall  f1-score   support\n\n         alder       0.23      0.21      0.22        77\n         birch       0.21      0.27      0.23       131\n    black pine       0.58      0.62      0.60        34\n        cherry       0.00      0.00      0.00         8\n   douglas fir       0.68      0.57      0.62       188\n   english oak       0.55      0.31      0.39       177\n  european ash       0.33      0.39      0.36        57\neuropean beech       0.39      0.62      0.48       120\neuropean larch       0.17      0.09      0.11        35\njapanese larch       0.35      0.49      0.41       128\n        linden       0.00      0.00      0.00         7\n norway spruce       0.67      0.40      0.50       101\n        poplar       0.00      0.00      0.00        11\n       red oak       0.35      0.63      0.45       124\n    scots pine       0.65      0.76      0.70       423\n   sessile oak       0.60      0.03      0.07        87\n    silver fir       0.62      0.12      0.21        65\nsycamore maple       0.50      0.09      0.15        35\n weymouth pine       0.39      0.57      0.46        42\n\n      accuracy                           0.47      1850\n     macro avg       0.38      0.32      0.31      1850\n  weighted avg       0.50      0.47      0.45      1850\n\n\nProcessing patch size: 5x5\n\nInspecting first 2 rows of broadleaf_long-lived deciduous_european ash_Patch5x5_2022-07.geojson:\nRow 0:\n  B1: None\n  B2: None\n  B3: None\n  B4: None\n  B5: None\n  B6: None\n  B7: None\n  B8: None\n  B8A: None\n  B9: None\n  B11: None\n  B12: None\n  NDVI: None\n  EVI: None\n  SAVI: None\n  NDWI: None\n  DEM: None\n  l3_species: european ash\nRow 1:\n  B1: None\n  B2: None\n  B3: None\n  B4: None\n  B5: None\n  B6: None\n  B7: None\n  B8: None\n  B8A: None\n  B9: None\n  B11: None\n  B12: None\n  NDVI: None\n  EVI: None\n  SAVI: None\n  NDWI: None\n  DEM: None\n  l3_species: european ash\nPatch size 5: Available columns: ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12', 'NDVI', 'EVI', 'SAVI', 'NDWI', 'DEM']\n\nPatch size 5: Skipped 25577 invalid samples\nFile: broadleaf_long-lived deciduous_european ash_Patch5x5_2022-07.geojson, Row: 0, Error: Null value for band B1\nFile: broadleaf_long-lived deciduous_european ash_Patch5x5_2022-07.geojson, Row: 1, Error: Null value for band B1\nFile: broadleaf_long-lived deciduous_european ash_Patch5x5_2022-07.geojson, Row: 2, Error: Null value for band B1\nFile: broadleaf_long-lived deciduous_european ash_Patch5x5_2022-07.geojson, Row: 3, Error: Null value for band B1\nFile: broadleaf_long-lived deciduous_european ash_Patch5x5_2022-07.geojson, Row: 5, Error: Null value for band B1\nPatch size 5: Loaded 12330 valid samples with shape (12330, 5, 5, 17)\n\nPatch size 5: Checking for NaN values...\nPatch size 5: Normalizing data...\nPatch size 5: Data range after normalization: min=0.0000, max=1.0000\nPatch size 5: Data shape: (12330, 5, 5, 17), Number of classes: 19\nPatch size 5: Train shape: (8630, 5, 5, 17), Validation shape: (1850, 5, 5, 17), Test shape: (1850, 5, 5, 17)\nEpoch 1/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.2165 - loss: 2.6106 - val_accuracy: 0.2984 - val_loss: 2.5514\nEpoch 2/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2915 - loss: 2.2776 - val_accuracy: 0.1892 - val_loss: 3.2130\nEpoch 3/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3143 - loss: 2.1505 - val_accuracy: 0.0611 - val_loss: 3.4221\nEpoch 4/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3291 - loss: 2.1276 - val_accuracy: 0.3141 - val_loss: 2.4067\nEpoch 5/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3361 - loss: 2.0904 - val_accuracy: 0.2081 - val_loss: 2.6715\nEpoch 6/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3375 - loss: 2.0768 - val_accuracy: 0.2616 - val_loss: 3.5176\nEpoch 7/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3448 - loss: 2.0660 - val_accuracy: 0.3184 - val_loss: 2.2022\nEpoch 8/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3571 - loss: 2.0298 - val_accuracy: 0.2600 - val_loss: 2.3304\nEpoch 9/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3735 - loss: 1.9723 - val_accuracy: 0.1914 - val_loss: 2.5528\nEpoch 10/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3772 - loss: 1.9756 - val_accuracy: 0.1903 - val_loss: 2.4602\nEpoch 11/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3709 - loss: 1.9724 - val_accuracy: 0.2362 - val_loss: 2.5797\nEpoch 12/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3719 - loss: 1.9511 - val_accuracy: 0.2497 - val_loss: 3.3622\nEpoch 13/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3942 - loss: 1.8864 - val_accuracy: 0.2492 - val_loss: 2.6925\nEpoch 14/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3888 - loss: 1.9119 - val_accuracy: 0.2584 - val_loss: 2.6323\nEpoch 15/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3938 - loss: 1.8989 - val_accuracy: 0.3524 - val_loss: 2.1745\nEpoch 16/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4139 - loss: 1.8383 - val_accuracy: 0.2930 - val_loss: 2.5213\nEpoch 17/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4163 - loss: 1.8425 - val_accuracy: 0.3065 - val_loss: 2.7219\nEpoch 18/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4085 - loss: 1.8404 - val_accuracy: 0.3714 - val_loss: 2.0743\nEpoch 19/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4136 - loss: 1.8185 - val_accuracy: 0.1676 - val_loss: 5.6475\nEpoch 20/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4261 - loss: 1.7951 - val_accuracy: 0.2530 - val_loss: 2.3708\nEpoch 21/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4304 - loss: 1.7884 - val_accuracy: 0.3492 - val_loss: 2.0147\nEpoch 22/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4411 - loss: 1.7669 - val_accuracy: 0.2514 - val_loss: 3.1504\nEpoch 23/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4354 - loss: 1.7782 - val_accuracy: 0.4314 - val_loss: 1.8158\nEpoch 24/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4464 - loss: 1.7242 - val_accuracy: 0.2832 - val_loss: 2.2941\nEpoch 25/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4403 - loss: 1.7234 - val_accuracy: 0.3692 - val_loss: 1.9464\nEpoch 26/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4523 - loss: 1.6919 - val_accuracy: 0.2173 - val_loss: 2.5903\nEpoch 27/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4434 - loss: 1.7213 - val_accuracy: 0.1757 - val_loss: 2.6576\nEpoch 28/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4651 - loss: 1.6720 - val_accuracy: 0.2427 - val_loss: 2.6724\nEpoch 29/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4684 - loss: 1.6753 - val_accuracy: 0.2843 - val_loss: 2.1442\nEpoch 30/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4634 - loss: 1.6548 - val_accuracy: 0.3530 - val_loss: 2.4133\nEpoch 31/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4687 - loss: 1.6310 - val_accuracy: 0.3097 - val_loss: 2.7545\nEpoch 32/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4748 - loss: 1.6229 - val_accuracy: 0.0946 - val_loss: 7.6956\nEpoch 33/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4690 - loss: 1.6385 - val_accuracy: 0.5032 - val_loss: 1.5418\nEpoch 34/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4804 - loss: 1.6004 - val_accuracy: 0.3784 - val_loss: 1.9573\nEpoch 35/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4840 - loss: 1.5973 - val_accuracy: 0.3600 - val_loss: 2.3569\nEpoch 36/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4922 - loss: 1.5865 - val_accuracy: 0.2011 - val_loss: 3.7642\nEpoch 37/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4977 - loss: 1.5785 - val_accuracy: 0.2319 - val_loss: 4.8568\nEpoch 38/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5032 - loss: 1.5615 - val_accuracy: 0.2935 - val_loss: 2.3999\nEpoch 39/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5146 - loss: 1.5149 - val_accuracy: 0.4411 - val_loss: 1.8649\nEpoch 40/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5090 - loss: 1.5418 - val_accuracy: 0.2995 - val_loss: 2.9680\nEpoch 41/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5059 - loss: 1.5182 - val_accuracy: 0.3438 - val_loss: 2.6451\nEpoch 42/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5148 - loss: 1.5183 - val_accuracy: 0.3849 - val_loss: 1.9985\nEpoch 43/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5184 - loss: 1.4742 - val_accuracy: 0.2357 - val_loss: 3.7083\nPatch size 5: Test Accuracy: 0.5081, Test Loss: 1.5577\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"\nPatch size 5: Classification Report:\n                precision    recall  f1-score   support\n\n         alder       0.40      0.03      0.05        77\n         birch       0.21      0.11      0.14       131\n    black pine       0.63      0.56      0.59        34\n        cherry       0.00      0.00      0.00         8\n   douglas fir       0.77      0.59      0.67       188\n   english oak       0.34      0.56      0.43       177\n  european ash       0.57      0.07      0.12        57\neuropean beech       0.38      0.72      0.50       120\neuropean larch       0.44      0.11      0.18        35\njapanese larch       0.39      0.20      0.26       128\n        linden       0.00      0.00      0.00         7\n norway spruce       0.69      0.62      0.66       101\n        poplar       0.00      0.00      0.00        11\n       red oak       0.38      0.59      0.46       124\n    scots pine       0.61      0.89      0.73       423\n   sessile oak       0.54      0.43      0.47        87\n    silver fir       0.43      0.09      0.15        65\nsycamore maple       0.00      0.00      0.00        35\n weymouth pine       0.85      0.40      0.55        42\n\n      accuracy                           0.51      1850\n     macro avg       0.40      0.31      0.31      1850\n  weighted avg       0.49      0.51      0.46      1850\n\n\nProcessing patch size: 9x9\n\nInspecting first 2 rows of needleleaf_fir_silver fir_Patch9x9_2022-07.geojson:\nRow 0:\n  B1: None\n  B2: None\n  B3: None\n  B4: None\n  B5: None\n  B6: None\n  B7: None\n  B8: None\n  B8A: None\n  B9: None\n  B11: None\n  B12: None\n  NDVI: None\n  EVI: None\n  SAVI: None\n  NDWI: None\n  DEM: None\n  l3_species: silver fir\nRow 1:\n  B1: None\n  B2: None\n  B3: None\n  B4: None\n  B5: None\n  B6: None\n  B7: None\n  B8: None\n  B8A: None\n  B9: None\n  B11: None\n  B12: None\n  NDVI: None\n  EVI: None\n  SAVI: None\n  NDWI: None\n  DEM: None\n  l3_species: silver fir\nPatch size 9: Available columns: ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12', 'NDVI', 'EVI', 'SAVI', 'NDWI', 'DEM']\n\nPatch size 9: Skipped 25577 invalid samples\nFile: needleleaf_fir_silver fir_Patch9x9_2022-07.geojson, Row: 0, Error: Null value for band B1\nFile: needleleaf_fir_silver fir_Patch9x9_2022-07.geojson, Row: 1, Error: Null value for band B1\nFile: needleleaf_fir_silver fir_Patch9x9_2022-07.geojson, Row: 2, Error: Null value for band B1\nFile: needleleaf_fir_silver fir_Patch9x9_2022-07.geojson, Row: 3, Error: Null value for band B1\nFile: needleleaf_fir_silver fir_Patch9x9_2022-07.geojson, Row: 4, Error: Null value for band B1\nPatch size 9: Loaded 12330 valid samples with shape (12330, 9, 9, 17)\n\nPatch size 9: Checking for NaN values...\nPatch size 9: Normalizing data...\nPatch size 9: Data range after normalization: min=0.0000, max=1.0000\nPatch size 9: Data shape: (12330, 9, 9, 17), Number of classes: 19\nPatch size 9: Train shape: (8630, 9, 9, 17), Validation shape: (1850, 9, 9, 17), Test shape: (1850, 9, 9, 17)\nEpoch 1/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.2217 - loss: 2.8133 - val_accuracy: 0.2714 - val_loss: 2.3642\nEpoch 2/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2625 - loss: 2.4449 - val_accuracy: 0.0659 - val_loss: 2.8689\nEpoch 3/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2755 - loss: 2.3178 - val_accuracy: 0.2768 - val_loss: 2.3978\nEpoch 4/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2818 - loss: 2.2543 - val_accuracy: 0.2908 - val_loss: 2.3145\nEpoch 5/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2985 - loss: 2.2111 - val_accuracy: 0.0816 - val_loss: 2.7044\nEpoch 6/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3035 - loss: 2.2004 - val_accuracy: 0.1070 - val_loss: 3.0892\nEpoch 7/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3114 - loss: 2.1755 - val_accuracy: 0.2514 - val_loss: 2.3857\nEpoch 8/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3220 - loss: 2.1225 - val_accuracy: 0.0951 - val_loss: 2.9375\nEpoch 9/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3303 - loss: 2.0834 - val_accuracy: 0.1816 - val_loss: 2.4869\nEpoch 10/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3240 - loss: 2.1182 - val_accuracy: 0.0930 - val_loss: 4.1895\nEpoch 11/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3549 - loss: 2.0504 - val_accuracy: 0.2946 - val_loss: 3.3427\nEpoch 12/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3664 - loss: 2.0060 - val_accuracy: 0.0454 - val_loss: 7.1965\nEpoch 13/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3672 - loss: 1.9820 - val_accuracy: 0.3178 - val_loss: 2.2921\nEpoch 14/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3776 - loss: 1.9486 - val_accuracy: 0.1919 - val_loss: 3.5869\nEpoch 15/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3920 - loss: 1.9053 - val_accuracy: 0.2811 - val_loss: 2.5703\nEpoch 16/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3887 - loss: 1.8905 - val_accuracy: 0.3405 - val_loss: 2.0485\nEpoch 17/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4084 - loss: 1.8592 - val_accuracy: 0.1859 - val_loss: 3.1157\nEpoch 18/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3992 - loss: 1.8812 - val_accuracy: 0.1757 - val_loss: 3.6941\nEpoch 19/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4172 - loss: 1.8002 - val_accuracy: 0.2665 - val_loss: 2.4531\nEpoch 20/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4263 - loss: 1.7857 - val_accuracy: 0.1897 - val_loss: 3.2300\nEpoch 21/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4359 - loss: 1.7550 - val_accuracy: 0.3968 - val_loss: 1.9735\nEpoch 22/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4269 - loss: 1.7512 - val_accuracy: 0.3519 - val_loss: 2.4978\nEpoch 23/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4616 - loss: 1.6947 - val_accuracy: 0.3903 - val_loss: 2.0458\nEpoch 24/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4575 - loss: 1.7010 - val_accuracy: 0.4524 - val_loss: 1.8362\nEpoch 25/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4585 - loss: 1.6808 - val_accuracy: 0.2395 - val_loss: 3.6455\nEpoch 26/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4676 - loss: 1.6543 - val_accuracy: 0.4076 - val_loss: 1.9140\nEpoch 27/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4844 - loss: 1.5998 - val_accuracy: 0.3573 - val_loss: 2.3658\nEpoch 28/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4779 - loss: 1.6265 - val_accuracy: 0.2800 - val_loss: 2.6921\nEpoch 29/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4842 - loss: 1.6143 - val_accuracy: 0.1805 - val_loss: 3.3880\nEpoch 30/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5010 - loss: 1.5647 - val_accuracy: 0.3265 - val_loss: 2.9127\nEpoch 31/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5025 - loss: 1.5381 - val_accuracy: 0.2632 - val_loss: 2.5934\nEpoch 32/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5010 - loss: 1.5273 - val_accuracy: 0.1919 - val_loss: 7.7346\nEpoch 33/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5025 - loss: 1.5479 - val_accuracy: 0.4124 - val_loss: 1.9163\nEpoch 34/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5132 - loss: 1.4621 - val_accuracy: 0.3719 - val_loss: 2.3948\nPatch size 9: Test Accuracy: 0.4411, Test Loss: 1.8388\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"\nPatch size 9: Classification Report:\n                precision    recall  f1-score   support\n\n         alder       0.00      0.00      0.00        77\n         birch       0.12      0.22      0.15       131\n    black pine       0.26      0.50      0.34        34\n        cherry       0.60      0.38      0.46         8\n   douglas fir       0.68      0.63      0.65       188\n   english oak       0.40      0.18      0.25       177\n  european ash       0.00      0.00      0.00        57\neuropean beech       0.44      0.51      0.47       120\neuropean larch       0.50      0.03      0.05        35\njapanese larch       0.26      0.05      0.09       128\n        linden       0.00      0.00      0.00         7\n norway spruce       0.70      0.56      0.63       101\n        poplar       0.00      0.00      0.00        11\n       red oak       0.26      0.77      0.39       124\n    scots pine       0.63      0.84      0.72       423\n   sessile oak       0.69      0.10      0.18        87\n    silver fir       0.28      0.26      0.27        65\nsycamore maple       0.00      0.00      0.00        35\n weymouth pine       0.67      0.29      0.40        42\n\n      accuracy                           0.44      1850\n     macro avg       0.34      0.28      0.27      1850\n  weighted avg       0.44      0.44      0.40      1850\n\n\nProcessing patch size: 13x13\n\nInspecting first 2 rows of broadleaf_beech_european beech_Patch13x13_2022-07.geojson:\nRow 0:\n  B1: None\n  B2: None\n  B3: None\n  B4: None\n  B5: None\n  B6: None\n  B7: None\n  B8: None\n  B8A: None\n  B9: None\n  B11: None\n  B12: None\n  NDVI: None\n  EVI: None\n  SAVI: None\n  NDWI: None\n  DEM: None\n  l3_species: european beech\nRow 1:\n  B1: None\n  B2: None\n  B3: None\n  B4: None\n  B5: None\n  B6: None\n  B7: None\n  B8: None\n  B8A: None\n  B9: None\n  B11: None\n  B12: None\n  NDVI: None\n  EVI: None\n  SAVI: None\n  NDWI: None\n  DEM: None\n  l3_species: european beech\nPatch size 13: Available columns: ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12', 'NDVI', 'EVI', 'SAVI', 'NDWI', 'DEM']\n\nPatch size 13: Skipped 25577 invalid samples\nFile: broadleaf_beech_european beech_Patch13x13_2022-07.geojson, Row: 0, Error: Null value for band B1\nFile: broadleaf_beech_european beech_Patch13x13_2022-07.geojson, Row: 1, Error: Null value for band B1\nFile: broadleaf_beech_european beech_Patch13x13_2022-07.geojson, Row: 2, Error: Null value for band B1\nFile: broadleaf_beech_european beech_Patch13x13_2022-07.geojson, Row: 3, Error: Null value for band B1\nFile: broadleaf_beech_european beech_Patch13x13_2022-07.geojson, Row: 4, Error: Null value for band B1\nPatch size 13: Loaded 12330 valid samples with shape (12330, 13, 13, 17)\n\nPatch size 13: Checking for NaN values...\nPatch size 13: Normalizing data...\nPatch size 13: Data range after normalization: min=0.0000, max=1.0000\nPatch size 13: Data shape: (12330, 13, 13, 17), Number of classes: 19\nPatch size 13: Train shape: (8630, 13, 13, 17), Validation shape: (1850, 13, 13, 17), Test shape: (1850, 13, 13, 17)\nEpoch 1/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.2013 - loss: 2.9333 - val_accuracy: 0.2286 - val_loss: 2.5343\nEpoch 2/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2145 - loss: 2.5895 - val_accuracy: 0.2400 - val_loss: 3.1132\nEpoch 3/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2209 - loss: 2.4649 - val_accuracy: 0.0935 - val_loss: 3.9011\nEpoch 4/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2437 - loss: 2.4161 - val_accuracy: 0.2649 - val_loss: 2.5756\nEpoch 5/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2358 - loss: 2.3963 - val_accuracy: 0.2870 - val_loss: 2.4065\nEpoch 6/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2464 - loss: 2.3585 - val_accuracy: 0.2854 - val_loss: 2.2821\nEpoch 7/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2413 - loss: 2.3809 - val_accuracy: 0.2778 - val_loss: 2.3191\nEpoch 8/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2401 - loss: 2.3729 - val_accuracy: 0.2497 - val_loss: 2.3195\nEpoch 9/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2303 - loss: 2.3725 - val_accuracy: 0.1746 - val_loss: 3.4126\nEpoch 10/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2413 - loss: 2.3618 - val_accuracy: 0.2665 - val_loss: 2.3101\nEpoch 11/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2481 - loss: 2.3458 - val_accuracy: 0.2184 - val_loss: 2.5895\nEpoch 12/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2615 - loss: 2.3305 - val_accuracy: 0.0627 - val_loss: 3.0006\nEpoch 13/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2556 - loss: 2.3223 - val_accuracy: 0.2119 - val_loss: 2.5763\nEpoch 14/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2612 - loss: 2.3389 - val_accuracy: 0.2476 - val_loss: 2.5114\nEpoch 15/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2644 - loss: 2.2946 - val_accuracy: 0.2951 - val_loss: 2.3469\nEpoch 16/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2567 - loss: 2.3085 - val_accuracy: 0.3043 - val_loss: 2.1689\nEpoch 17/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2642 - loss: 2.2979 - val_accuracy: 0.2995 - val_loss: 2.2697\nEpoch 18/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2701 - loss: 2.2808 - val_accuracy: 0.2773 - val_loss: 2.3661\nEpoch 19/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2717 - loss: 2.2722 - val_accuracy: 0.2989 - val_loss: 2.2090\nEpoch 20/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2736 - loss: 2.2719 - val_accuracy: 0.2330 - val_loss: 2.5899\nEpoch 21/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2760 - loss: 2.2727 - val_accuracy: 0.0941 - val_loss: 2.8536\nEpoch 22/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2810 - loss: 2.2082 - val_accuracy: 0.2449 - val_loss: 2.4656\nEpoch 23/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2839 - loss: 2.2019 - val_accuracy: 0.3362 - val_loss: 2.0639\nEpoch 24/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2868 - loss: 2.1856 - val_accuracy: 0.2373 - val_loss: 2.4385\nEpoch 25/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2973 - loss: 2.1530 - val_accuracy: 0.2492 - val_loss: 2.4428\nEpoch 26/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2952 - loss: 2.1669 - val_accuracy: 0.2805 - val_loss: 2.2572\nEpoch 27/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3140 - loss: 2.1391 - val_accuracy: 0.2746 - val_loss: 2.6218\nEpoch 28/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3122 - loss: 2.0834 - val_accuracy: 0.1184 - val_loss: 4.4864\nEpoch 29/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3186 - loss: 2.0871 - val_accuracy: 0.2876 - val_loss: 2.6786\nEpoch 30/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3352 - loss: 2.0483 - val_accuracy: 0.2946 - val_loss: 2.3060\nEpoch 31/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3300 - loss: 2.0437 - val_accuracy: 0.3319 - val_loss: 2.1297\nEpoch 32/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3489 - loss: 2.0190 - val_accuracy: 0.2670 - val_loss: 2.2514\nEpoch 33/50\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3705 - loss: 1.9565 - val_accuracy: 0.3189 - val_loss: 2.1587\nPatch size 13: Test Accuracy: 0.3341, Test Loss: 2.0620\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"\nPatch size 13: Classification Report:\n                precision    recall  f1-score   support\n\n         alder       0.00      0.00      0.00        77\n         birch       0.00      0.00      0.00       131\n    black pine       0.00      0.00      0.00        34\n        cherry       0.00      0.00      0.00         8\n   douglas fir       0.71      0.41      0.52       188\n   english oak       0.17      0.83      0.29       177\n  european ash       0.00      0.00      0.00        57\neuropean beech       0.00      0.00      0.00       120\neuropean larch       0.00      0.00      0.00        35\njapanese larch       0.00      0.00      0.00       128\n        linden       0.00      0.00      0.00         7\n norway spruce       0.00      0.00      0.00       101\n        poplar       0.00      0.00      0.00        11\n       red oak       1.00      0.01      0.02       124\n    scots pine       0.44      0.93      0.60       423\n   sessile oak       0.00      0.00      0.00        87\n    silver fir       0.00      0.00      0.00        65\nsycamore maple       0.00      0.00      0.00        35\n weymouth pine       0.00      0.00      0.00        42\n\n      accuracy                           0.33      1850\n     macro avg       0.12      0.11      0.07      1850\n  weighted avg       0.26      0.33      0.22      1850\n\n\nSummary of Results:\n\nPatch Size 1x1:\n  Test Accuracy: 0.4714\n  Test Loss: 1.6745\n  Weighted Precision: 0.4954\n  Weighted Recall: 0.4714\n  Weighted F1-Score: 0.4501\n  Macro Precision: 0.3820\n  Macro Recall: 0.3238\n  Macro F1-Score: 0.3131\n\nPatch Size 5x5:\n  Test Accuracy: 0.5081\n  Test Loss: 1.5577\n  Weighted Precision: 0.4945\n  Weighted Recall: 0.5081\n  Weighted F1-Score: 0.4623\n  Macro Precision: 0.4021\n  Macro Recall: 0.3148\n  Macro F1-Score: 0.3139\n\nPatch Size 9x9:\n  Test Accuracy: 0.4411\n  Test Loss: 1.8388\n  Weighted Precision: 0.4357\n  Weighted Recall: 0.4411\n  Weighted F1-Score: 0.3991\n  Macro Precision: 0.3415\n  Macro Recall: 0.2805\n  Macro F1-Score: 0.2665\n\nPatch Size 13x13:\n  Test Accuracy: 0.3341\n  Test Loss: 2.0620\n  Weighted Precision: 0.2562\n  Weighted Recall: 0.3341\n  Weighted F1-Score: 0.2181\n  Macro Precision: 0.1222\n  Macro Recall: 0.1147\n  Macro F1-Score: 0.0749\n","output_type":"stream"}],"execution_count":2}]}