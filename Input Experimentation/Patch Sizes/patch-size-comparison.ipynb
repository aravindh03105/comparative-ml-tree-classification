{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f29b2118",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T22:05:25.335634Z",
     "iopub.status.busy": "2025-06-28T22:05:25.335334Z",
     "iopub.status.idle": "2025-06-28T22:11:59.015161Z",
     "shell.execute_reply": "2025-06-28T22:11:59.014357Z"
    },
    "papermill": {
     "duration": 393.684638,
     "end_time": "2025-06-28T22:11:59.016504",
     "exception": false,
     "start_time": "2025-06-28T22:05:25.331866",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-28 22:05:28.383382: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751148328.605797      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751148328.661387      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing patch size: 1x1\n",
      "\n",
      "Inspecting first 2 rows of needleleaf_douglas fir_douglas fir_Patch1x1_2022-07.geojson:\n",
      "Row 0:\n",
      "  B1: None\n",
      "  B2: None\n",
      "  B3: None\n",
      "  B4: None\n",
      "  B5: None\n",
      "  B6: None\n",
      "  B7: None\n",
      "  B8: None\n",
      "  B8A: None\n",
      "  B9: None\n",
      "  B11: None\n",
      "  B12: None\n",
      "  NDVI: None\n",
      "  EVI: None\n",
      "  SAVI: None\n",
      "  NDWI: None\n",
      "  DEM: None\n",
      "  l3_species: douglas fir\n",
      "Row 1:\n",
      "  B1: [[0.1298000067472458]]\n",
      "  B2: [[0.12809999287128448]]\n",
      "  B3: [[0.1462000012397766]]\n",
      "  B4: [[0.13349999487400055]]\n",
      "  B5: [[0.17399999499320984]]\n",
      "  B6: [[0.3084999918937683]]\n",
      "  B7: [[0.3635999858379364]]\n",
      "  B8: [[0.38960000872612]]\n",
      "  B8A: [[0.3939000070095062]]\n",
      "  B9: [[0.3813999891281128]]\n",
      "  B11: [[0.24650000035762787]]\n",
      "  B12: [[0.16859999299049377]]\n",
      "  NDVI: [[0.4895813763141632]]\n",
      "  EVI: [[0.5205919569583571]]\n",
      "  SAVI: [[0.3754765119992361]]\n",
      "  NDWI: [[0.22496463358402252]]\n",
      "  DEM: [[96.0]]\n",
      "  l3_species: douglas fir\n",
      "Patch size 1: Available columns: ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12', 'NDVI', 'EVI', 'SAVI', 'NDWI', 'DEM']\n",
      "\n",
      "Patch size 1: Skipped 25577 invalid samples\n",
      "File: needleleaf_douglas fir_douglas fir_Patch1x1_2022-07.geojson, Row: 0, Error: Null value for band B1\n",
      "File: needleleaf_douglas fir_douglas fir_Patch1x1_2022-07.geojson, Row: 2, Error: Null value for band B1\n",
      "File: needleleaf_douglas fir_douglas fir_Patch1x1_2022-07.geojson, Row: 5, Error: Null value for band B1\n",
      "File: needleleaf_douglas fir_douglas fir_Patch1x1_2022-07.geojson, Row: 6, Error: Null value for band B1\n",
      "File: needleleaf_douglas fir_douglas fir_Patch1x1_2022-07.geojson, Row: 7, Error: Null value for band B1\n",
      "Patch size 1: Loaded 12330 valid samples with shape (12330, 1, 1, 17)\n",
      "\n",
      "Patch size 1: Checking for NaN values...\n",
      "Patch size 1: Normalizing data...\n",
      "Patch size 1: Data range after normalization: min=0.0000, max=1.0000\n",
      "Patch size 1: Data shape: (12330, 1, 1, 17), Number of classes: 19\n",
      "Patch size 1: Train shape: (8630, 1, 1, 17), Validation shape: (1850, 1, 1, 17), Test shape: (1850, 1, 1, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1751148355.797002      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1751148360.848372      59 service.cc:148] XLA service 0x17e8a6e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1751148360.848923      59 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "I0000 00:00:1751148361.270926      59 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 60/540\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1951 - loss: 2.8541"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1751148363.729644      59 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.2864 - loss: 2.4342 - val_accuracy: 0.2049 - val_loss: 2.5325\n",
      "Epoch 2/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3613 - loss: 2.0423 - val_accuracy: 0.2486 - val_loss: 2.4581\n",
      "Epoch 3/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3734 - loss: 1.9567 - val_accuracy: 0.3281 - val_loss: 2.4015\n",
      "Epoch 4/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4038 - loss: 1.8961 - val_accuracy: 0.2941 - val_loss: 2.2671\n",
      "Epoch 5/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4390 - loss: 1.7791 - val_accuracy: 0.1535 - val_loss: 2.7960\n",
      "Epoch 6/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4307 - loss: 1.8068 - val_accuracy: 0.3649 - val_loss: 1.9388\n",
      "Epoch 7/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4435 - loss: 1.7665 - val_accuracy: 0.4714 - val_loss: 1.6922\n",
      "Epoch 8/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4458 - loss: 1.7489 - val_accuracy: 0.2924 - val_loss: 2.1834\n",
      "Epoch 9/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4409 - loss: 1.7499 - val_accuracy: 0.2076 - val_loss: 2.5762\n",
      "Epoch 10/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4636 - loss: 1.7050 - val_accuracy: 0.2946 - val_loss: 2.2936\n",
      "Epoch 11/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4486 - loss: 1.7469 - val_accuracy: 0.4000 - val_loss: 1.8335\n",
      "Epoch 12/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4706 - loss: 1.6914 - val_accuracy: 0.2708 - val_loss: 2.4992\n",
      "Epoch 13/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4675 - loss: 1.6792 - val_accuracy: 0.3470 - val_loss: 2.0342\n",
      "Epoch 14/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4851 - loss: 1.6504 - val_accuracy: 0.2924 - val_loss: 2.4086\n",
      "Epoch 15/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4727 - loss: 1.6640 - val_accuracy: 0.3519 - val_loss: 2.1586\n",
      "Epoch 16/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4834 - loss: 1.6344 - val_accuracy: 0.2541 - val_loss: 2.5104\n",
      "Epoch 17/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4745 - loss: 1.6446 - val_accuracy: 0.2470 - val_loss: 3.6466\n",
      "Patch size 1: Test Accuracy: 0.4595, Test Loss: 1.7019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Patch size 1: Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "         alder       0.39      0.12      0.18        77\n",
      "         birch       0.17      0.23      0.20       131\n",
      "    black pine       0.56      0.59      0.57        34\n",
      "        cherry       0.00      0.00      0.00         8\n",
      "   douglas fir       0.75      0.42      0.54       188\n",
      "   english oak       0.40      0.33      0.36       177\n",
      "  european ash       0.33      0.23      0.27        57\n",
      "european beech       0.34      0.70      0.46       120\n",
      "european larch       0.00      0.00      0.00        35\n",
      "japanese larch       0.40      0.41      0.40       128\n",
      "        linden       0.00      0.00      0.00         7\n",
      " norway spruce       0.62      0.42      0.50       101\n",
      "        poplar       0.00      0.00      0.00        11\n",
      "       red oak       0.33      0.69      0.45       124\n",
      "    scots pine       0.61      0.83      0.70       423\n",
      "   sessile oak       0.50      0.07      0.12        87\n",
      "    silver fir       0.58      0.11      0.18        65\n",
      "sycamore maple       0.00      0.00      0.00        35\n",
      " weymouth pine       0.68      0.31      0.43        42\n",
      "\n",
      "      accuracy                           0.46      1850\n",
      "     macro avg       0.35      0.29      0.28      1850\n",
      "  weighted avg       0.47      0.46      0.43      1850\n",
      "\n",
      "\n",
      "Processing patch size: 5x5\n",
      "\n",
      "Inspecting first 2 rows of broadleaf_long-lived deciduous_european ash_Patch5x5_2022-07.geojson:\n",
      "Row 0:\n",
      "  B1: None\n",
      "  B2: None\n",
      "  B3: None\n",
      "  B4: None\n",
      "  B5: None\n",
      "  B6: None\n",
      "  B7: None\n",
      "  B8: None\n",
      "  B8A: None\n",
      "  B9: None\n",
      "  B11: None\n",
      "  B12: None\n",
      "  NDVI: None\n",
      "  EVI: None\n",
      "  SAVI: None\n",
      "  NDWI: None\n",
      "  DEM: None\n",
      "  l3_species: european ash\n",
      "Row 1:\n",
      "  B1: None\n",
      "  B2: None\n",
      "  B3: None\n",
      "  B4: None\n",
      "  B5: None\n",
      "  B6: None\n",
      "  B7: None\n",
      "  B8: None\n",
      "  B8A: None\n",
      "  B9: None\n",
      "  B11: None\n",
      "  B12: None\n",
      "  NDVI: None\n",
      "  EVI: None\n",
      "  SAVI: None\n",
      "  NDWI: None\n",
      "  DEM: None\n",
      "  l3_species: european ash\n",
      "Patch size 5: Available columns: ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12', 'NDVI', 'EVI', 'SAVI', 'NDWI', 'DEM']\n",
      "\n",
      "Patch size 5: Skipped 25577 invalid samples\n",
      "File: broadleaf_long-lived deciduous_european ash_Patch5x5_2022-07.geojson, Row: 0, Error: Null value for band B1\n",
      "File: broadleaf_long-lived deciduous_european ash_Patch5x5_2022-07.geojson, Row: 1, Error: Null value for band B1\n",
      "File: broadleaf_long-lived deciduous_european ash_Patch5x5_2022-07.geojson, Row: 2, Error: Null value for band B1\n",
      "File: broadleaf_long-lived deciduous_european ash_Patch5x5_2022-07.geojson, Row: 3, Error: Null value for band B1\n",
      "File: broadleaf_long-lived deciduous_european ash_Patch5x5_2022-07.geojson, Row: 5, Error: Null value for band B1\n",
      "Patch size 5: Loaded 12330 valid samples with shape (12330, 5, 5, 17)\n",
      "\n",
      "Patch size 5: Checking for NaN values...\n",
      "Patch size 5: Normalizing data...\n",
      "Patch size 5: Data range after normalization: min=0.0000, max=1.0000\n",
      "Patch size 5: Data shape: (12330, 5, 5, 17), Number of classes: 19\n",
      "Patch size 5: Train shape: (8630, 5, 5, 17), Validation shape: (1850, 5, 5, 17), Test shape: (1850, 5, 5, 17)\n",
      "Epoch 1/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.2438 - loss: 2.5672 - val_accuracy: 0.2632 - val_loss: 2.5264\n",
      "Epoch 2/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3070 - loss: 2.2166 - val_accuracy: 0.1784 - val_loss: 2.6321\n",
      "Epoch 3/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3293 - loss: 2.1400 - val_accuracy: 0.2546 - val_loss: 3.4069\n",
      "Epoch 4/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3352 - loss: 2.1023 - val_accuracy: 0.2508 - val_loss: 2.5352\n",
      "Epoch 5/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3488 - loss: 2.0606 - val_accuracy: 0.1600 - val_loss: 3.7075\n",
      "Epoch 6/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3503 - loss: 2.0293 - val_accuracy: 0.2822 - val_loss: 2.5795\n",
      "Epoch 7/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3598 - loss: 2.0146 - val_accuracy: 0.2957 - val_loss: 2.3434\n",
      "Epoch 8/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3732 - loss: 1.9629 - val_accuracy: 0.3800 - val_loss: 1.9597\n",
      "Epoch 9/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3801 - loss: 1.9264 - val_accuracy: 0.1903 - val_loss: 2.8811\n",
      "Epoch 10/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3844 - loss: 1.9121 - val_accuracy: 0.2573 - val_loss: 2.3557\n",
      "Epoch 11/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4027 - loss: 1.8542 - val_accuracy: 0.3843 - val_loss: 2.2811\n",
      "Epoch 12/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4106 - loss: 1.8396 - val_accuracy: 0.3562 - val_loss: 2.2226\n",
      "Epoch 13/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4123 - loss: 1.8560 - val_accuracy: 0.3600 - val_loss: 2.0027\n",
      "Epoch 14/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4099 - loss: 1.8591 - val_accuracy: 0.1886 - val_loss: 4.4126\n",
      "Epoch 15/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4259 - loss: 1.7803 - val_accuracy: 0.3443 - val_loss: 2.0405\n",
      "Epoch 16/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4242 - loss: 1.7741 - val_accuracy: 0.2222 - val_loss: 2.5662\n",
      "Epoch 17/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4299 - loss: 1.7776 - val_accuracy: 0.1605 - val_loss: 2.7406\n",
      "Epoch 18/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4431 - loss: 1.7315 - val_accuracy: 0.3935 - val_loss: 1.8784\n",
      "Epoch 19/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4500 - loss: 1.7116 - val_accuracy: 0.0924 - val_loss: 6.3398\n",
      "Epoch 20/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4580 - loss: 1.6769 - val_accuracy: 0.3897 - val_loss: 2.0015\n",
      "Epoch 21/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4606 - loss: 1.6739 - val_accuracy: 0.3427 - val_loss: 2.0327\n",
      "Epoch 22/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4728 - loss: 1.6372 - val_accuracy: 0.2146 - val_loss: 3.9355\n",
      "Epoch 23/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4915 - loss: 1.6175 - val_accuracy: 0.4378 - val_loss: 1.8245\n",
      "Epoch 24/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4777 - loss: 1.6379 - val_accuracy: 0.2184 - val_loss: 5.8915\n",
      "Epoch 25/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4830 - loss: 1.6088 - val_accuracy: 0.2719 - val_loss: 2.3833\n",
      "Epoch 26/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4865 - loss: 1.5987 - val_accuracy: 0.4022 - val_loss: 1.9104\n",
      "Epoch 27/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4918 - loss: 1.6020 - val_accuracy: 0.3422 - val_loss: 2.1346\n",
      "Epoch 28/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5123 - loss: 1.5656 - val_accuracy: 0.1957 - val_loss: 2.8945\n",
      "Epoch 29/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5077 - loss: 1.5551 - val_accuracy: 0.2573 - val_loss: 3.0076\n",
      "Epoch 30/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5082 - loss: 1.5486 - val_accuracy: 0.3270 - val_loss: 2.1974\n",
      "Epoch 31/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5098 - loss: 1.5446 - val_accuracy: 0.3924 - val_loss: 2.0174\n",
      "Epoch 32/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5193 - loss: 1.5154 - val_accuracy: 0.2573 - val_loss: 2.6092\n",
      "Epoch 33/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5178 - loss: 1.4963 - val_accuracy: 0.0903 - val_loss: 8.0008\n",
      "Patch size 5: Test Accuracy: 0.4432, Test Loss: 1.7905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Patch size 5: Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "         alder       0.00      0.00      0.00        77\n",
      "         birch       0.16      0.20      0.18       131\n",
      "    black pine       0.40      0.71      0.51        34\n",
      "        cherry       0.00      0.00      0.00         8\n",
      "   douglas fir       0.92      0.32      0.48       188\n",
      "   english oak       0.31      0.50      0.38       177\n",
      "  european ash       0.40      0.07      0.12        57\n",
      "european beech       0.46      0.50      0.48       120\n",
      "european larch       0.38      0.09      0.14        35\n",
      "japanese larch       0.25      0.19      0.21       128\n",
      "        linden       0.00      0.00      0.00         7\n",
      " norway spruce       0.41      0.80      0.55       101\n",
      "        poplar       0.00      0.00      0.00        11\n",
      "       red oak       0.57      0.40      0.47       124\n",
      "    scots pine       0.61      0.80      0.69       423\n",
      "   sessile oak       0.61      0.13      0.21        87\n",
      "    silver fir       0.28      0.29      0.29        65\n",
      "sycamore maple       0.00      0.00      0.00        35\n",
      " weymouth pine       0.29      0.71      0.41        42\n",
      "\n",
      "      accuracy                           0.44      1850\n",
      "     macro avg       0.32      0.30      0.27      1850\n",
      "  weighted avg       0.45      0.44      0.41      1850\n",
      "\n",
      "\n",
      "Processing patch size: 9x9\n",
      "\n",
      "Inspecting first 2 rows of needleleaf_fir_silver fir_Patch9x9_2022-07.geojson:\n",
      "Row 0:\n",
      "  B1: None\n",
      "  B2: None\n",
      "  B3: None\n",
      "  B4: None\n",
      "  B5: None\n",
      "  B6: None\n",
      "  B7: None\n",
      "  B8: None\n",
      "  B8A: None\n",
      "  B9: None\n",
      "  B11: None\n",
      "  B12: None\n",
      "  NDVI: None\n",
      "  EVI: None\n",
      "  SAVI: None\n",
      "  NDWI: None\n",
      "  DEM: None\n",
      "  l3_species: silver fir\n",
      "Row 1:\n",
      "  B1: None\n",
      "  B2: None\n",
      "  B3: None\n",
      "  B4: None\n",
      "  B5: None\n",
      "  B6: None\n",
      "  B7: None\n",
      "  B8: None\n",
      "  B8A: None\n",
      "  B9: None\n",
      "  B11: None\n",
      "  B12: None\n",
      "  NDVI: None\n",
      "  EVI: None\n",
      "  SAVI: None\n",
      "  NDWI: None\n",
      "  DEM: None\n",
      "  l3_species: silver fir\n",
      "Patch size 9: Available columns: ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12', 'NDVI', 'EVI', 'SAVI', 'NDWI', 'DEM']\n",
      "\n",
      "Patch size 9: Skipped 25577 invalid samples\n",
      "File: needleleaf_fir_silver fir_Patch9x9_2022-07.geojson, Row: 0, Error: Null value for band B1\n",
      "File: needleleaf_fir_silver fir_Patch9x9_2022-07.geojson, Row: 1, Error: Null value for band B1\n",
      "File: needleleaf_fir_silver fir_Patch9x9_2022-07.geojson, Row: 2, Error: Null value for band B1\n",
      "File: needleleaf_fir_silver fir_Patch9x9_2022-07.geojson, Row: 3, Error: Null value for band B1\n",
      "File: needleleaf_fir_silver fir_Patch9x9_2022-07.geojson, Row: 4, Error: Null value for band B1\n",
      "Patch size 9: Loaded 12330 valid samples with shape (12330, 9, 9, 17)\n",
      "\n",
      "Patch size 9: Checking for NaN values...\n",
      "Patch size 9: Normalizing data...\n",
      "Patch size 9: Data range after normalization: min=0.0000, max=1.0000\n",
      "Patch size 9: Data shape: (12330, 9, 9, 17), Number of classes: 19\n",
      "Patch size 9: Train shape: (8630, 9, 9, 17), Validation shape: (1850, 9, 9, 17), Test shape: (1850, 9, 9, 17)\n",
      "Epoch 1/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.2056 - loss: 2.7908 - val_accuracy: 0.2389 - val_loss: 2.3912\n",
      "Epoch 2/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2280 - loss: 2.4876 - val_accuracy: 0.2746 - val_loss: 2.3894\n",
      "Epoch 3/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2564 - loss: 2.3999 - val_accuracy: 0.2308 - val_loss: 3.0989\n",
      "Epoch 4/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2591 - loss: 2.3547 - val_accuracy: 0.2957 - val_loss: 2.2233\n",
      "Epoch 5/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2764 - loss: 2.3115 - val_accuracy: 0.2362 - val_loss: 2.4733\n",
      "Epoch 6/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2713 - loss: 2.3060 - val_accuracy: 0.2843 - val_loss: 2.2491\n",
      "Epoch 7/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2671 - loss: 2.2678 - val_accuracy: 0.2865 - val_loss: 2.2899\n",
      "Epoch 8/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2744 - loss: 2.2709 - val_accuracy: 0.3065 - val_loss: 2.2155\n",
      "Epoch 9/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2814 - loss: 2.2533 - val_accuracy: 0.3011 - val_loss: 2.2512\n",
      "Epoch 10/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2869 - loss: 2.2316 - val_accuracy: 0.3038 - val_loss: 2.2545\n",
      "Epoch 11/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3003 - loss: 2.2052 - val_accuracy: 0.3092 - val_loss: 2.1991\n",
      "Epoch 12/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3207 - loss: 2.1722 - val_accuracy: 0.3216 - val_loss: 2.3600\n",
      "Epoch 13/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3367 - loss: 2.1045 - val_accuracy: 0.1043 - val_loss: 2.7326\n",
      "Epoch 14/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3248 - loss: 2.1220 - val_accuracy: 0.1092 - val_loss: 2.6189\n",
      "Epoch 15/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3390 - loss: 2.0813 - val_accuracy: 0.1151 - val_loss: 11.4073\n",
      "Epoch 16/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3458 - loss: 2.0542 - val_accuracy: 0.1751 - val_loss: 4.3888\n",
      "Epoch 17/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3575 - loss: 2.0088 - val_accuracy: 0.3016 - val_loss: 2.2927\n",
      "Epoch 18/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3703 - loss: 1.9681 - val_accuracy: 0.2103 - val_loss: 2.5075\n",
      "Epoch 19/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3630 - loss: 1.9747 - val_accuracy: 0.2324 - val_loss: 2.4774\n",
      "Epoch 20/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3838 - loss: 1.9098 - val_accuracy: 0.1778 - val_loss: 3.0415\n",
      "Epoch 21/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3823 - loss: 1.9080 - val_accuracy: 0.1005 - val_loss: 2.7872\n",
      "Patch size 9: Test Accuracy: 0.3141, Test Loss: 2.2234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Patch size 9: Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "         alder       0.00      0.00      0.00        77\n",
      "         birch       0.00      0.00      0.00       131\n",
      "    black pine       0.00      0.00      0.00        34\n",
      "        cherry       0.00      0.00      0.00         8\n",
      "   douglas fir       0.17      0.01      0.02       188\n",
      "   english oak       0.17      0.74      0.28       177\n",
      "  european ash       0.00      0.00      0.00        57\n",
      "european beech       0.00      0.00      0.00       120\n",
      "european larch       0.00      0.00      0.00        35\n",
      "japanese larch       0.00      0.00      0.00       128\n",
      "        linden       0.00      0.00      0.00         7\n",
      " norway spruce       0.63      0.49      0.55       101\n",
      "        poplar       0.00      0.00      0.00        11\n",
      "       red oak       0.00      0.00      0.00       124\n",
      "    scots pine       0.40      0.94      0.57       423\n",
      "   sessile oak       0.00      0.00      0.00        87\n",
      "    silver fir       0.00      0.00      0.00        65\n",
      "sycamore maple       0.00      0.00      0.00        35\n",
      " weymouth pine       0.00      0.00      0.00        42\n",
      "\n",
      "      accuracy                           0.31      1850\n",
      "     macro avg       0.07      0.11      0.07      1850\n",
      "  weighted avg       0.16      0.31      0.19      1850\n",
      "\n",
      "\n",
      "Processing patch size: 13x13\n",
      "\n",
      "Inspecting first 2 rows of broadleaf_beech_european beech_Patch13x13_2022-07.geojson:\n",
      "Row 0:\n",
      "  B1: None\n",
      "  B2: None\n",
      "  B3: None\n",
      "  B4: None\n",
      "  B5: None\n",
      "  B6: None\n",
      "  B7: None\n",
      "  B8: None\n",
      "  B8A: None\n",
      "  B9: None\n",
      "  B11: None\n",
      "  B12: None\n",
      "  NDVI: None\n",
      "  EVI: None\n",
      "  SAVI: None\n",
      "  NDWI: None\n",
      "  DEM: None\n",
      "  l3_species: european beech\n",
      "Row 1:\n",
      "  B1: None\n",
      "  B2: None\n",
      "  B3: None\n",
      "  B4: None\n",
      "  B5: None\n",
      "  B6: None\n",
      "  B7: None\n",
      "  B8: None\n",
      "  B8A: None\n",
      "  B9: None\n",
      "  B11: None\n",
      "  B12: None\n",
      "  NDVI: None\n",
      "  EVI: None\n",
      "  SAVI: None\n",
      "  NDWI: None\n",
      "  DEM: None\n",
      "  l3_species: european beech\n",
      "Patch size 13: Available columns: ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12', 'NDVI', 'EVI', 'SAVI', 'NDWI', 'DEM']\n",
      "\n",
      "Patch size 13: Skipped 25577 invalid samples\n",
      "File: broadleaf_beech_european beech_Patch13x13_2022-07.geojson, Row: 0, Error: Null value for band B1\n",
      "File: broadleaf_beech_european beech_Patch13x13_2022-07.geojson, Row: 1, Error: Null value for band B1\n",
      "File: broadleaf_beech_european beech_Patch13x13_2022-07.geojson, Row: 2, Error: Null value for band B1\n",
      "File: broadleaf_beech_european beech_Patch13x13_2022-07.geojson, Row: 3, Error: Null value for band B1\n",
      "File: broadleaf_beech_european beech_Patch13x13_2022-07.geojson, Row: 4, Error: Null value for band B1\n",
      "Patch size 13: Loaded 12330 valid samples with shape (12330, 13, 13, 17)\n",
      "\n",
      "Patch size 13: Checking for NaN values...\n",
      "Patch size 13: Normalizing data...\n",
      "Patch size 13: Data range after normalization: min=0.0000, max=1.0000\n",
      "Patch size 13: Data shape: (12330, 13, 13, 17), Number of classes: 19\n",
      "Patch size 13: Train shape: (8630, 13, 13, 17), Validation shape: (1850, 13, 13, 17), Test shape: (1850, 13, 13, 17)\n",
      "Epoch 1/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.2030 - loss: 2.8610 - val_accuracy: 0.2438 - val_loss: 2.3727\n",
      "Epoch 2/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2503 - loss: 2.4487 - val_accuracy: 0.2935 - val_loss: 2.2491\n",
      "Epoch 3/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2643 - loss: 2.4016 - val_accuracy: 0.2778 - val_loss: 2.3888\n",
      "Epoch 4/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2649 - loss: 2.3760 - val_accuracy: 0.0481 - val_loss: 3.5768\n",
      "Epoch 5/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2643 - loss: 2.3425 - val_accuracy: 0.2627 - val_loss: 2.4223\n",
      "Epoch 6/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2778 - loss: 2.3020 - val_accuracy: 0.2049 - val_loss: 2.5102\n",
      "Epoch 7/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2676 - loss: 2.2871 - val_accuracy: 0.2946 - val_loss: 2.4761\n",
      "Epoch 8/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2716 - loss: 2.2981 - val_accuracy: 0.2989 - val_loss: 2.3673\n",
      "Epoch 9/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2748 - loss: 2.2481 - val_accuracy: 0.2265 - val_loss: 2.2927\n",
      "Epoch 10/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2820 - loss: 2.2445 - val_accuracy: 0.1319 - val_loss: 3.0941\n",
      "Epoch 11/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2864 - loss: 2.2097 - val_accuracy: 0.1119 - val_loss: 5.3503\n",
      "Epoch 12/50\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2925 - loss: 2.1995 - val_accuracy: 0.2195 - val_loss: 3.2194\n",
      "Patch size 13: Test Accuracy: 0.2892, Test Loss: 2.2464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Patch size 13: Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "         alder       0.00      0.00      0.00        77\n",
      "         birch       0.00      0.00      0.00       131\n",
      "    black pine       0.00      0.00      0.00        34\n",
      "        cherry       0.00      0.00      0.00         8\n",
      "   douglas fir       0.00      0.00      0.00       188\n",
      "   english oak       0.16      0.75      0.27       177\n",
      "  european ash       0.00      0.00      0.00        57\n",
      "european beech       0.00      0.00      0.00       120\n",
      "european larch       0.00      0.00      0.00        35\n",
      "japanese larch       0.00      0.00      0.00       128\n",
      "        linden       0.00      0.00      0.00         7\n",
      " norway spruce       0.00      0.00      0.00       101\n",
      "        poplar       0.00      0.00      0.00        11\n",
      "       red oak       0.00      0.00      0.00       124\n",
      "    scots pine       0.39      0.95      0.55       423\n",
      "   sessile oak       0.00      0.00      0.00        87\n",
      "    silver fir       0.00      0.00      0.00        65\n",
      "sycamore maple       0.00      0.00      0.00        35\n",
      " weymouth pine       0.00      0.00      0.00        42\n",
      "\n",
      "      accuracy                           0.29      1850\n",
      "     macro avg       0.03      0.09      0.04      1850\n",
      "  weighted avg       0.10      0.29      0.15      1850\n",
      "\n",
      "\n",
      "Summary of Results:\n",
      "\n",
      "Patch Size 1x1:\n",
      "  Test Accuracy: 0.4595\n",
      "  Test Loss: 1.7019\n",
      "  Weighted Precision: 0.4678\n",
      "  Weighted Recall: 0.4595\n",
      "  Weighted F1-Score: 0.4268\n",
      "  Macro Precision: 0.3508\n",
      "  Macro Recall: 0.2866\n",
      "  Macro F1-Score: 0.2820\n",
      "\n",
      "Patch Size 5x5:\n",
      "  Test Accuracy: 0.4432\n",
      "  Test Loss: 1.7905\n",
      "  Weighted Precision: 0.4533\n",
      "  Weighted Recall: 0.4432\n",
      "  Weighted F1-Score: 0.4080\n",
      "  Macro Precision: 0.3184\n",
      "  Macro Recall: 0.3006\n",
      "  Macro F1-Score: 0.2695\n",
      "\n",
      "Patch Size 9x9:\n",
      "  Test Accuracy: 0.3141\n",
      "  Test Loss: 2.2234\n",
      "  Weighted Precision: 0.1602\n",
      "  Weighted Recall: 0.3141\n",
      "  Weighted F1-Score: 0.1881\n",
      "  Macro Precision: 0.0722\n",
      "  Macro Recall: 0.1147\n",
      "  Macro F1-Score: 0.0744\n",
      "\n",
      "Patch Size 13x13:\n",
      "  Test Accuracy: 0.2892\n",
      "  Test Loss: 2.2464\n",
      "  Weighted Precision: 0.1048\n",
      "  Weighted Recall: 0.2892\n",
      "  Weighted F1-Score: 0.1521\n",
      "  Macro Precision: 0.0291\n",
      "  Macro Recall: 0.0894\n",
      "  Macro F1-Score: 0.0431\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import layers, models\n",
    "import geopandas as gpd\n",
    "import ast\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Define Data Paths and Parameters\n",
    "patch_sizes = [1, 5, 9, 13]\n",
    "patch_size_folders = [f\"/kaggle/input/treesatai-patch{p}x{p}\" for p in patch_sizes]\n",
    "\n",
    "# Define bands (as provided, no monthly suffixes based on GeoJSON sample)\n",
    "bands = [\n",
    "    'B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12',\n",
    "    'NDVI', 'EVI', 'SAVI', 'NDWI', 'DEM'\n",
    "]\n",
    "band_columns = bands  # 17 bands, no monthly data\n",
    "\n",
    "# 2. Function to Load Data for a Given Patch Size\n",
    "def load_data_for_patch_size(patch_size, folder_path):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    invalid_samples = []\n",
    "    # Verify available columns\n",
    "    available_columns = None\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith(\".geojson\"):\n",
    "            gdf = gpd.read_file(os.path.join(folder_path, file))\n",
    "            available_columns = [col for col in band_columns if col in gdf.columns]\n",
    "            # Debugging: Print sample data for first few rows\n",
    "            print(f\"\\nInspecting first 2 rows of {file}:\")\n",
    "            for idx in range(min(2, len(gdf))):\n",
    "                print(f\"Row {idx}:\")\n",
    "                for col in available_columns:\n",
    "                    print(f\"  {col}: {gdf[col].iloc[idx]}\")\n",
    "                print(f\"  l3_species: {gdf['l3_species'].iloc[idx]}\")\n",
    "            break\n",
    "    if not available_columns:\n",
    "        raise ValueError(f\"No valid GeoJSON files found in {folder_path}\")\n",
    "    print(f\"Patch size {patch_size}: Available columns: {available_columns}\")\n",
    "    expected_shape = (patch_size, patch_size, len(available_columns))\n",
    "\n",
    "    # Load all GeoJSON files\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith(\".geojson\"):\n",
    "            gdf = gpd.read_file(os.path.join(folder_path, file))\n",
    "            for idx, row in gdf.iterrows():\n",
    "                try:\n",
    "                    if row['l3_species'] is None or not isinstance(row['l3_species'], str):\n",
    "                        raise ValueError(f\"Invalid label at row {idx}: {row['l3_species']}\")\n",
    "                    patches = []\n",
    "                    for col in available_columns:\n",
    "                        val = row[col]\n",
    "                        if val is None:\n",
    "                            raise ValueError(f\"Null value for band {col}\")\n",
    "                        if isinstance(val, (list, np.ndarray)):\n",
    "                            arr = np.array(val, dtype=np.float32).reshape(patch_size, patch_size)\n",
    "                        elif isinstance(val, str):\n",
    "                            try:\n",
    "                                arr = np.array(json.loads(val), dtype=np.float32).reshape(patch_size, patch_size)\n",
    "                            except json.JSONDecodeError:\n",
    "                                arr = np.array(ast.literal_eval(val), dtype=np.float32).reshape(patch_size, patch_size)\n",
    "                        elif isinstance(val, (float, np.float32, np.float64)):\n",
    "                            arr = np.full((patch_size, patch_size), val, dtype=np.float32)\n",
    "                        else:\n",
    "                            raise ValueError(f\"Unexpected data type for band {col}: {type(val)}\")\n",
    "                        patches.append(arr)\n",
    "\n",
    "                    patch = np.stack(patches, axis=-1)\n",
    "                    if patch.shape != expected_shape:\n",
    "                        raise ValueError(f\"Unexpected patch shape: {patch.shape}, expected {expected_shape}\")\n",
    "                    all_features.append(patch)\n",
    "                    all_labels.append(row['l3_species'])\n",
    "                except Exception as e:\n",
    "                    invalid_samples.append((file, idx, str(e)))\n",
    "                    continue\n",
    "\n",
    "    if invalid_samples:\n",
    "        print(f\"\\nPatch size {patch_size}: Skipped {len(invalid_samples)} invalid samples\")\n",
    "        for file, idx, error in invalid_samples[:5]:\n",
    "            print(f\"File: {file}, Row: {idx}, Error: {error}\")\n",
    "        # Save invalid samples to a file for inspection\n",
    "        with open(f'invalid_samples_patch_size_{patch_size}.json', 'w') as f:\n",
    "            json.dump(invalid_samples, f, indent=4)\n",
    "\n",
    "    if not all_features:\n",
    "        raise ValueError(f\"No valid samples loaded for patch size {patch_size}. Check GeoJSON files.\")\n",
    "    X = np.array(all_features, dtype=np.float32)\n",
    "    y = np.array(all_labels)\n",
    "    print(f\"Patch size {patch_size}: Loaded {len(all_features)} valid samples with shape {X.shape}\")\n",
    "    return X, y, invalid_samples, available_columns\n",
    "\n",
    "# 3. Define CNN Model\n",
    "def build_cnn(input_shape, num_classes):\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)) if input_shape[0] >= 5 else layers.Lambda(lambda x: x),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# 4. Data Augmentation\n",
    "def get_data_augmentation(patch_size):\n",
    "    if patch_size > 1:\n",
    "        return tf.keras.Sequential([\n",
    "            layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "            layers.RandomRotation(0.2),\n",
    "        ])\n",
    "    return lambda x: x  # Identity function for 1x1 patches (no augmentation)\n",
    "\n",
    "# 5. Train and Evaluate for Each Patch Size\n",
    "results = {}\n",
    "label_encoder = LabelEncoder()\n",
    "available_columns_dict = {}\n",
    "\n",
    "for patch_size, folder_path in zip(patch_sizes, patch_size_folders):\n",
    "    print(f\"\\nProcessing patch size: {patch_size}x{patch_size}\")\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Folder {folder_path} does not exist.\")\n",
    "        continue\n",
    "\n",
    "    # Load data\n",
    "    try:\n",
    "        X, y, invalid_samples, available_columns = load_data_for_patch_size(patch_size, folder_path)\n",
    "        available_columns_dict[patch_size] = available_columns\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data for patch size {patch_size}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Handle NaN values\n",
    "    print(f\"\\nPatch size {patch_size}: Checking for NaN values...\")\n",
    "    nan_mask = np.any(np.isnan(X), axis=(1, 2, 3))\n",
    "    nan_count = np.sum(nan_mask)\n",
    "    if nan_count > 0:\n",
    "        print(f\"Patch size {patch_size}: Removing {nan_count} samples with NaN values\")\n",
    "        valid_mask = ~nan_mask\n",
    "        X = X[valid_mask]\n",
    "        y = y[valid_mask]\n",
    "        print(f\"Patch size {patch_size}: New data shape after removing NaN: {X.shape}\")\n",
    "\n",
    "    # Normalize data\n",
    "    print(f\"Patch size {patch_size}: Normalizing data...\")\n",
    "    X_min = np.nanmin(X, axis=(0, 1, 2), keepdims=True)\n",
    "    X_max = np.nanmax(X, axis=(0, 1, 2), keepdims=True)\n",
    "    X = (X - X_min) / (X_max - X_min + 1e-6)\n",
    "    print(f\"Patch size {patch_size}: Data range after normalization: min={np.nanmin(X):.4f}, max={np.nanmax(X):.4f}\")\n",
    "\n",
    "    # Encode labels\n",
    "    try:\n",
    "        if not results:\n",
    "            y_encoded = label_encoder.fit_transform(y)\n",
    "        else:\n",
    "            y_encoded = label_encoder.transform(y)\n",
    "        y_onehot = tf.keras.utils.to_categorical(y_encoded)\n",
    "        num_classes = len(label_encoder.classes_)\n",
    "        print(f\"Patch size {patch_size}: Data shape: {X.shape}, Number of classes: {num_classes}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error encoding labels for patch size {patch_size}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Train-test-validation split\n",
    "    try:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=0.15, random_state=42, stratify=y_onehot)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1765, random_state=42, stratify=y_train)\n",
    "        print(f\"Patch size {patch_size}: Train shape: {X_train.shape}, Validation shape: {X_val.shape}, Test shape: {X_test.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error splitting data for patch size {patch_size}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Build and compile model\n",
    "    try:\n",
    "        model = build_cnn(input_shape=(patch_size, patch_size, len(available_columns)), num_classes=num_classes)\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    except Exception as e:\n",
    "        print(f\"Error building model for patch size {patch_size}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Train model\n",
    "    try:\n",
    "        history = model.fit(\n",
    "            get_data_augmentation(patch_size)(X_train), y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=50,\n",
    "            batch_size=16,  # Reduced to mitigate memory issues\n",
    "            callbacks=[\n",
    "                tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
    "                tf.keras.callbacks.ModelCheckpoint(f'best_model_patch_size_{patch_size}.keras', save_best_only=True)\n",
    "            ],\n",
    "            verbose=1\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error training model for patch size {patch_size}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Evaluate model\n",
    "    try:\n",
    "        test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "        print(f\"Patch size {patch_size}: Test Accuracy: {test_accuracy:.4f}, Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "        # Compute additional metrics\n",
    "        y_pred = model.predict(X_test, verbose=0)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "        y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "        # Classification report (precision, recall, F1-score)\n",
    "        class_report = classification_report(y_test_classes, y_pred_classes, target_names=label_encoder.classes_, output_dict=True)\n",
    "        print(f\"\\nPatch size {patch_size}: Classification Report:\")\n",
    "        print(classification_report(y_test_classes, y_pred_classes, target_names=label_encoder.classes_))\n",
    "\n",
    "        # Confusion matrix\n",
    "        cm = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.title(f'Confusion Matrix: Patch Size {patch_size}x{patch_size}')\n",
    "        plt.savefig(f'confusion_matrix_patch_size_{patch_size}.png')\n",
    "        plt.close()\n",
    "\n",
    "        # Store results\n",
    "        results[f'patch_size_{patch_size}'] = {\n",
    "            'patch_size': patch_size,\n",
    "            'test_accuracy': test_accuracy,\n",
    "            'test_loss': test_loss,\n",
    "            'classification_report': class_report,\n",
    "            'history': history.history\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating model for patch size {patch_size}: {e}\")\n",
    "        continue\n",
    "\n",
    "# 6. Compare Results\n",
    "print(\"\\nSummary of Results:\")\n",
    "for key, result in results.items():\n",
    "    print(f\"\\nPatch Size {result['patch_size']}x{result['patch_size']}:\")\n",
    "    print(f\"  Test Accuracy: {result['test_accuracy']:.4f}\")\n",
    "    print(f\"  Test Loss: {result['test_loss']:.4f}\")\n",
    "    print(f\"  Weighted Precision: {result['classification_report']['weighted avg']['precision']:.4f}\")\n",
    "    print(f\"  Weighted Recall: {result['classification_report']['weighted avg']['recall']:.4f}\")\n",
    "    print(f\"  Weighted F1-Score: {result['classification_report']['weighted avg']['f1-score']:.4f}\")\n",
    "    print(f\"  Macro Precision: {result['classification_report']['macro avg']['precision']:.4f}\")\n",
    "    print(f\"  Macro Recall: {result['classification_report']['macro avg']['recall']:.4f}\")\n",
    "    print(f\"  Macro F1-Score: {result['classification_report']['macro avg']['f1-score']:.4f}\")\n",
    "\n",
    "# Plot accuracy comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "accuracies = [results[key]['test_accuracy'] for key in results]\n",
    "patch_size_labels = [f\"{results[key]['patch_size']}x{results[key]['patch_size']}\" for key in results]\n",
    "plt.bar(patch_size_labels, accuracies)\n",
    "plt.xlabel('Patch Size')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.title('Test Accuracy by Patch Size')\n",
    "plt.tight_layout()\n",
    "plt.savefig('accuracy_comparison_patch_sizes.png')\n",
    "plt.close()\n",
    "\n",
    "# Plot weighted F1-score comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "f1_scores = [results[key]['classification_report']['weighted avg']['f1-score'] for key in results]\n",
    "plt.bar(patch_size_labels, f1_scores)\n",
    "plt.xlabel('Patch Size')\n",
    "plt.ylabel('Weighted F1-Score')\n",
    "plt.title('Weighted F1-Score by Patch Size')\n",
    "plt.tight_layout()\n",
    "plt.savefig('f1_score_comparison_patch_sizes.png')\n",
    "plt.close()\n",
    "\n",
    "# 7. Save Label Encoder and Results\n",
    "joblib.dump(label_encoder, 'label_encoder.pkl')\n",
    "with open('results_summary_patch_sizes.json', 'w') as f:\n",
    "    json.dump({k: {kk: vv for kk, vv in v.items() if kk != 'history'} for k, v in results.items()}, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7762074,
     "sourceId": 12314462,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7762081,
     "sourceId": 12314475,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7762088,
     "sourceId": 12314487,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7762093,
     "sourceId": 12314500,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 401.384506,
   "end_time": "2025-06-28T22:12:02.566324",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-28T22:05:21.181818",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
